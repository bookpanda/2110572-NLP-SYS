{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30887,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q  transformers==4.30.1 datasets evaluate thaixtransformers\n!pip install peft==0.10.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T17:07:37.611196Z","iopub.execute_input":"2025-02-11T17:07:37.611549Z","iopub.status.idle":"2025-02-11T17:07:55.816510Z","shell.execute_reply.started":"2025-02-11T17:07:37.611501Z","shell.execute_reply":"2025-02-11T17:07:55.815527Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.6/113.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.9/17.9 MB\u001b[0m \u001b[31m77.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m93.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nkaggle-environments 1.16.11 requires transformers>=4.33.1, but you have transformers 4.30.1 which is incompatible.\nsentence-transformers 3.3.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.30.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mCollecting peft==0.10.0\n  Downloading peft-0.10.0-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft==0.10.0) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.10.0) (24.2)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft==0.10.0) (5.9.5)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft==0.10.0) (6.0.2)\nRequirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.10.0) (2.5.1+cu121)\nRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft==0.10.0) (4.30.1)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft==0.10.0) (4.67.1)\nRequirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.10.0) (1.2.1)\nRequirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft==0.10.0) (0.4.5)\nRequirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.10.0) (0.28.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft==0.10.0) (3.17.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft==0.10.0) (2024.9.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft==0.10.0) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft==0.10.0) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->peft==0.10.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->peft==0.10.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->peft==0.10.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->peft==0.10.0) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->peft==0.10.0) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->peft==0.10.0) (2.4.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.10.0) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.10.0) (3.1.4)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.10.0) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft==0.10.0) (1.3.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft==0.10.0) (2024.11.6)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers->peft==0.10.0) (0.13.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft==0.10.0) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->peft==0.10.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->peft==0.10.0) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->peft==0.10.0) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->peft==0.10.0) (2024.2.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.10.0) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.10.0) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.10.0) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.10.0) (2025.1.31)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->peft==0.10.0) (2024.2.0)\nDownloading peft-0.10.0-py3-none-any.whl (199 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: peft\n  Attempting uninstall: peft\n    Found existing installation: peft 0.14.0\n    Uninstalling peft-0.14.0:\n      Successfully uninstalled peft-0.14.0\nSuccessfully installed peft-0.10.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!wget --no-check-certificate https://www.dropbox.com/s/37u83g55p19kvrl/clean-phone-data-for-students.csv","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T17:08:27.332298Z","iopub.execute_input":"2025-02-11T17:08:27.332718Z","iopub.status.idle":"2025-02-11T17:08:28.885234Z","shell.execute_reply.started":"2025-02-11T17:08:27.332688Z","shell.execute_reply":"2025-02-11T17:08:28.884317Z"}},"outputs":[{"name":"stdout","text":"--2025-02-11 17:08:27--  https://www.dropbox.com/s/37u83g55p19kvrl/clean-phone-data-for-students.csv\nResolving www.dropbox.com (www.dropbox.com)... 162.125.9.18, 2620:100:601f:18::a27d:912\nConnecting to www.dropbox.com (www.dropbox.com)|162.125.9.18|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://www.dropbox.com/scl/fi/8h8hvsw9uj6o0524lfe4i/clean-phone-data-for-students.csv?rlkey=lwv5xbf16jerehnv3lfgq5ue6 [following]\n--2025-02-11 17:08:27--  https://www.dropbox.com/scl/fi/8h8hvsw9uj6o0524lfe4i/clean-phone-data-for-students.csv?rlkey=lwv5xbf16jerehnv3lfgq5ue6\nReusing existing connection to www.dropbox.com:443.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://ucd755b735ab178bf1caa9240762.dl.dropboxusercontent.com/cd/0/inline/Cj7jouAiyLz1lOCxz62FjnDIrnUosmOSjDw63Y3D-JSHsS2DIlvXq13G0YGqmChz575h4ZODT69e2HPvNdI0xOYeU6MYdpRDekm1OK6_6D6HAbpiOYGIdwYmsQlQSUPJrxg/file# [following]\n--2025-02-11 17:08:28--  https://ucd755b735ab178bf1caa9240762.dl.dropboxusercontent.com/cd/0/inline/Cj7jouAiyLz1lOCxz62FjnDIrnUosmOSjDw63Y3D-JSHsS2DIlvXq13G0YGqmChz575h4ZODT69e2HPvNdI0xOYeU6MYdpRDekm1OK6_6D6HAbpiOYGIdwYmsQlQSUPJrxg/file\nResolving ucd755b735ab178bf1caa9240762.dl.dropboxusercontent.com (ucd755b735ab178bf1caa9240762.dl.dropboxusercontent.com)... 162.125.9.15, 2620:100:601f:15::a27d:90f\nConnecting to ucd755b735ab178bf1caa9240762.dl.dropboxusercontent.com (ucd755b735ab178bf1caa9240762.dl.dropboxusercontent.com)|162.125.9.15|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 2518977 (2.4M) [text/plain]\nSaving to: ‘clean-phone-data-for-students.csv’\n\nclean-phone-data-fo 100%[===================>]   2.40M  --.-KB/s    in 0.09s   \n\n2025-02-11 17:08:28 (26.4 MB/s) - ‘clean-phone-data-for-students.csv’ saved [2518977/2518977]\n\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"%matplotlib inline\nimport pandas\nimport sklearn\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\nfrom torch.utils.data import Dataset\nfrom IPython.display import display\nfrom collections import defaultdict\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T17:10:23.519176Z","iopub.execute_input":"2025-02-11T17:10:23.519606Z","iopub.status.idle":"2025-02-11T17:10:23.526215Z","shell.execute_reply.started":"2025-02-11T17:10:23.519574Z","shell.execute_reply":"2025-02-11T17:10:23.525590Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\nnotebook_login()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T17:09:11.931938Z","iopub.execute_input":"2025-02-11T17:09:11.932222Z","iopub.status.idle":"2025-02-11T17:09:12.313384Z","shell.execute_reply.started":"2025-02-11T17:09:11.932200Z","shell.execute_reply":"2025-02-11T17:09:12.312531Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b15da3353ff4285906d5effcbda47c8"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"data_df = pd.read_csv('clean-phone-data-for-students.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T17:40:09.074052Z","iopub.execute_input":"2025-02-11T17:40:09.074387Z","iopub.status.idle":"2025-02-11T17:40:09.129197Z","shell.execute_reply.started":"2025-02-11T17:40:09.074348Z","shell.execute_reply":"2025-02-11T17:40:09.128484Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"display(data_df.head())\ndata_df.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T17:40:09.230574Z","iopub.execute_input":"2025-02-11T17:40:09.230821Z","iopub.status.idle":"2025-02-11T17:40:09.263472Z","shell.execute_reply.started":"2025-02-11T17:40:09.230800Z","shell.execute_reply":"2025-02-11T17:40:09.262683Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"                                  Sentence Utterance   Action        Object\n0   <PHONE_NUMBER_REMOVED> ผมไปจ่ายเงินที่ Counte...  enquire       payment\n1               internet ยังความเร็วอยุ่เท่าไหร ครับ  enquire       package\n2   ตะกี้ไปชำระค่าบริการไปแล้ว แต่ยังใช้งานไม่ได้...   report       suspend\n3   พี่ค่ะยังใช้ internet ไม่ได้เลยค่ะ เป็นเครื่อ...  enquire      internet\n4   ฮาโหล คะ พอดีว่าเมื่อวานเปิดซิมทรูมูฟ แต่มันโ...   report  phone_issues","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sentence Utterance</th>\n      <th>Action</th>\n      <th>Object</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>&lt;PHONE_NUMBER_REMOVED&gt; ผมไปจ่ายเงินที่ Counte...</td>\n      <td>enquire</td>\n      <td>payment</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>internet ยังความเร็วอยุ่เท่าไหร ครับ</td>\n      <td>enquire</td>\n      <td>package</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ตะกี้ไปชำระค่าบริการไปแล้ว แต่ยังใช้งานไม่ได้...</td>\n      <td>report</td>\n      <td>suspend</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>พี่ค่ะยังใช้ internet ไม่ได้เลยค่ะ เป็นเครื่อ...</td>\n      <td>enquire</td>\n      <td>internet</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ฮาโหล คะ พอดีว่าเมื่อวานเปิดซิมทรูมูฟ แต่มันโ...</td>\n      <td>report</td>\n      <td>phone_issues</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"       Sentence Utterance   Action   Object\ncount               16175    16175    16175\nunique              13389       10       33\ntop           บริการอื่นๆ  enquire  service\nfreq                   97    10377     2525","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sentence Utterance</th>\n      <th>Action</th>\n      <th>Object</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>16175</td>\n      <td>16175</td>\n      <td>16175</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>13389</td>\n      <td>10</td>\n      <td>33</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>บริการอื่นๆ</td>\n      <td>enquire</td>\n      <td>service</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>97</td>\n      <td>10377</td>\n      <td>2525</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":38},{"cell_type":"code","source":"data_df = data_df[[\"Sentence Utterance\", \"Object\"]]\ndata_df.columns = ['input', 'raw_label']\ndisplay(data_df.describe())\ndisplay(data_df.raw_label.unique())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T17:40:09.390292Z","iopub.execute_input":"2025-02-11T17:40:09.390609Z","iopub.status.idle":"2025-02-11T17:40:09.414924Z","shell.execute_reply.started":"2025-02-11T17:40:09.390584Z","shell.execute_reply":"2025-02-11T17:40:09.414112Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"              input raw_label\ncount         16175     16175\nunique        13389        33\ntop     บริการอื่นๆ   service\nfreq             97      2525","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>input</th>\n      <th>raw_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>16175</td>\n      <td>16175</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>13389</td>\n      <td>33</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>บริการอื่นๆ</td>\n      <td>service</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>97</td>\n      <td>2525</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"array(['payment', 'package', 'suspend', 'internet', 'phone_issues',\n       'service', 'nonTrueMove', 'balance', 'detail', 'bill', 'credit',\n       'promotion', 'mobile_setting', 'iservice', 'roaming', 'truemoney',\n       'information', 'lost_stolen', 'balance_minutes', 'idd',\n       'TrueMoney', 'garbage', 'Payment', 'IDD', 'ringtone', 'Idd',\n       'rate', 'loyalty_card', 'contact', 'officer', 'Balance', 'Service',\n       'Loyalty_card'], dtype=object)"},"metadata":{}}],"execution_count":39},{"cell_type":"code","source":"data_df['clean_label']=data_df['raw_label'].str.lower().copy()\ndata_df.drop('raw_label', axis=1, inplace=True)\ndisplay(data_df.describe())\ndisplay(data_df.clean_label.unique())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T17:40:09.538508Z","iopub.execute_input":"2025-02-11T17:40:09.538739Z","iopub.status.idle":"2025-02-11T17:40:09.567311Z","shell.execute_reply.started":"2025-02-11T17:40:09.538719Z","shell.execute_reply":"2025-02-11T17:40:09.566676Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"              input clean_label\ncount         16175       16175\nunique        13389          26\ntop     บริการอื่นๆ     service\nfreq             97        2528","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>input</th>\n      <th>clean_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>16175</td>\n      <td>16175</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>13389</td>\n      <td>26</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>บริการอื่นๆ</td>\n      <td>service</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>97</td>\n      <td>2528</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"array(['payment', 'package', 'suspend', 'internet', 'phone_issues',\n       'service', 'nontruemove', 'balance', 'detail', 'bill', 'credit',\n       'promotion', 'mobile_setting', 'iservice', 'roaming', 'truemoney',\n       'information', 'lost_stolen', 'balance_minutes', 'idd', 'garbage',\n       'ringtone', 'rate', 'loyalty_card', 'contact', 'officer'],\n      dtype=object)"},"metadata":{}}],"execution_count":40},{"cell_type":"code","source":"data_df = data_df.drop_duplicates(\"input\", keep=\"first\")\ndata_df = data_df.reset_index(drop=True)\ndisplay(data_df.describe())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T17:40:09.693757Z","iopub.execute_input":"2025-02-11T17:40:09.693968Z","iopub.status.idle":"2025-02-11T17:40:09.716070Z","shell.execute_reply.started":"2025-02-11T17:40:09.693949Z","shell.execute_reply":"2025-02-11T17:40:09.715337Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"                                       input clean_label\ncount                                  13389       13389\nunique                                 13389          26\ntop     สอบถามโปรโมชั่นปัจจุบันที่ใช้อยู่ค่ะ     service\nfreq                                       1        2111","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>input</th>\n      <th>clean_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>13389</td>\n      <td>13389</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>13389</td>\n      <td>26</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>สอบถามโปรโมชั่นปัจจุบันที่ใช้อยู่ค่ะ</td>\n      <td>service</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>1</td>\n      <td>2111</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":41},{"cell_type":"code","source":"# remove class `contact` as it has only 4 sample (cannot do train 80 val 10 test 10)\ndata_df = data_df[data_df.clean_label != 'contact']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T17:40:09.823861Z","iopub.execute_input":"2025-02-11T17:40:09.824084Z","iopub.status.idle":"2025-02-11T17:40:09.829696Z","shell.execute_reply.started":"2025-02-11T17:40:09.824064Z","shell.execute_reply":"2025-02-11T17:40:09.828863Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"data = data_df.copy().to_numpy()\n\nunique_label = data_df.clean_label.unique()\n\nlabel_2_num_map = dict(zip(unique_label, range(len(unique_label))))\nnum_2_label_map = dict(zip(range(len(unique_label)), unique_label))\n\nprint(\"Create Mappings\")\ndisplay(num_2_label_map)\ndisplay(label_2_num_map)\n\n# print(\"Before Mappings\")\n# display(data[:, 1])\ndata[:,1] = np.vectorize(label_2_num_map.get)(data[:,1])\n# print(\"After Mappings\")\n# display(data[:, 1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T17:40:11.919167Z","iopub.execute_input":"2025-02-11T17:40:11.919501Z","iopub.status.idle":"2025-02-11T17:40:11.933175Z","shell.execute_reply.started":"2025-02-11T17:40:11.919466Z","shell.execute_reply":"2025-02-11T17:40:11.932377Z"}},"outputs":[{"name":"stdout","text":"Create Mappings\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"{0: 'payment',\n 1: 'package',\n 2: 'suspend',\n 3: 'internet',\n 4: 'phone_issues',\n 5: 'service',\n 6: 'nontruemove',\n 7: 'balance',\n 8: 'detail',\n 9: 'bill',\n 10: 'credit',\n 11: 'promotion',\n 12: 'mobile_setting',\n 13: 'iservice',\n 14: 'roaming',\n 15: 'truemoney',\n 16: 'information',\n 17: 'lost_stolen',\n 18: 'balance_minutes',\n 19: 'idd',\n 20: 'garbage',\n 21: 'ringtone',\n 22: 'rate',\n 23: 'loyalty_card',\n 24: 'officer'}"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"{'payment': 0,\n 'package': 1,\n 'suspend': 2,\n 'internet': 3,\n 'phone_issues': 4,\n 'service': 5,\n 'nontruemove': 6,\n 'balance': 7,\n 'detail': 8,\n 'bill': 9,\n 'credit': 10,\n 'promotion': 11,\n 'mobile_setting': 12,\n 'iservice': 13,\n 'roaming': 14,\n 'truemoney': 15,\n 'information': 16,\n 'lost_stolen': 17,\n 'balance_minutes': 18,\n 'idd': 19,\n 'garbage': 20,\n 'ringtone': 21,\n 'rate': 22,\n 'loyalty_card': 23,\n 'officer': 24}"},"metadata":{}}],"execution_count":43},{"cell_type":"code","source":"def strip_str(string):\n    return string.strip()\n     \n# print(\"Before\")\n# print(data)\ndata[:,0] = np.vectorize(strip_str)(data[:,0])\n# print(\"After\")\n# print(data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T17:40:12.110207Z","iopub.execute_input":"2025-02-11T17:40:12.110483Z","iopub.status.idle":"2025-02-11T17:40:12.143070Z","shell.execute_reply.started":"2025-02-11T17:40:12.110426Z","shell.execute_reply":"2025-02-11T17:40:12.142360Z"}},"outputs":[],"execution_count":44},{"cell_type":"markdown","source":"# Model 3 WangchanBERTa\n\nWe ask you to train a WangchanBERTa-based model.\n\nWe recommend you use the thaixtransformers fork (which we used in the PoS homework).\nhttps://github.com/PyThaiNLP/thaixtransformers\n\nThe structure of the code will be very similar to the PoS homework. You will also find the huggingface [tutorial](https://huggingface.co/docs/transformers/en/tasks/sequence_classification) useful. Or you can also add a softmax layer by yourself just like in the previous homework.\n\nWhich WangchanBERTa model will you use? Why? (Don't forget to clean your text accordingly).\n\n**Ans:**\n`airesearch/wangchanberta-base-att-spm-uncased` because it is suitable for text classification. It was train on these datasets for Multiclass text classification:\n- `wisesight_sentiment`: 4-class text classification task (positive, neutral, negative, and question) based on social media posts and tweets\n- `wongnai_reivews`: Users' review rating classification task (scale is ranging from 1 to 5)\n- `generated_reviews_enth`: Generated users' review rating classification task (scale is ranging from 1 to 5)","metadata":{}},{"cell_type":"code","source":"import time\nimport torch\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer, pipeline, DataCollatorWithPadding, AutoModel\nfrom tqdm import tqdm\nfrom torch.utils.data import DataLoader\nimport pytorch_lightning as pl\nfrom pytorch_lightning import LightningModule, Trainer\nfrom torchmetrics import Accuracy\n\nfrom thaixtransformers import Tokenizer\nfrom torch import nn\nimport torch.nn.functional as F","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T17:59:18.117771Z","iopub.execute_input":"2025-02-11T17:59:18.118086Z","iopub.status.idle":"2025-02-11T17:59:18.122708Z","shell.execute_reply.started":"2025-02-11T17:59:18.118065Z","shell.execute_reply":"2025-02-11T17:59:18.121859Z"}},"outputs":[],"execution_count":72},{"cell_type":"code","source":"# tokenizer = AutoTokenizer.from_pretrained(\"airesearch/wangchanberta-base-att-spm-uncased\")\ntokenizer = Tokenizer(\"airesearch/wangchanberta-base-att-spm-uncased\")\n# model = AutoModelForSequenceClassification.from_pretrained(\"airesearch/wangchanberta-base-att-spm-uncased\")\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T17:49:00.937771Z","iopub.execute_input":"2025-02-11T17:49:00.938124Z","iopub.status.idle":"2025-02-11T17:49:01.101305Z","shell.execute_reply.started":"2025-02-11T17:49:00.938096Z","shell.execute_reply":"2025-02-11T17:49:01.100362Z"}},"outputs":[{"name":"stderr","text":"The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \nThe tokenizer class you load from this checkpoint is 'CamembertTokenizer'. \nThe class this function is called from is 'WangchanbertaTokenizer'.\n","output_type":"stream"}],"execution_count":58},{"cell_type":"code","source":"tokenizer(data[0,0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T17:40:18.606194Z","iopub.execute_input":"2025-02-11T17:40:18.606764Z","iopub.status.idle":"2025-02-11T17:40:18.613475Z","shell.execute_reply.started":"2025-02-11T17:40:18.606726Z","shell.execute_reply":"2025-02-11T17:40:18.612523Z"}},"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [5, 10, 2856, 3, 265, 3, 265, 3, 1992, 8, 330, 28, 2753, 12, 8, 10, 3, 743, 2508, 3441, 8, 10, 3, 1276, 714, 8321, 110, 8, 3310, 2148, 14999, 8, 10, 1836, 4813, 11, 570, 8, 10, 177, 8, 9484, 2301, 2390, 5824, 204, 11545, 8, 10, 313, 2801, 11, 4573, 8, 10, 177, 6], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"},"metadata":{}}],"execution_count":46},{"cell_type":"code","source":"for i, sample in tqdm(enumerate(data)):\n    cleaned_sentence = sample[0].replace('ํา', \"ำ\") # only cleaning needed for WangchanBERTa\n    data[i, 0] = tokenizer(cleaned_sentence) # no padding as we will use DataCollatorWithPadding to pad within batch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T17:40:21.220170Z","iopub.execute_input":"2025-02-11T17:40:21.220547Z","iopub.status.idle":"2025-02-11T17:40:23.523880Z","shell.execute_reply.started":"2025-02-11T17:40:21.220517Z","shell.execute_reply":"2025-02-11T17:40:23.522926Z"}},"outputs":[{"name":"stderr","text":"13385it [00:02, 5829.12it/s]\n","output_type":"stream"}],"execution_count":47},{"cell_type":"code","source":"X = data[:, 0]\ny = data[:, 1]\n\nX.shape, y.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T17:40:24.384788Z","iopub.execute_input":"2025-02-11T17:40:24.385070Z","iopub.status.idle":"2025-02-11T17:40:24.390951Z","shell.execute_reply.started":"2025-02-11T17:40:24.385049Z","shell.execute_reply":"2025-02-11T17:40:24.390012Z"}},"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"((13385,), (13385,))"},"metadata":{}}],"execution_count":48},{"cell_type":"code","source":"X[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T17:40:24.568697Z","iopub.execute_input":"2025-02-11T17:40:24.568933Z","iopub.status.idle":"2025-02-11T17:40:24.574189Z","shell.execute_reply.started":"2025-02-11T17:40:24.568913Z","shell.execute_reply":"2025-02-11T17:40:24.573469Z"}},"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [5, 10, 2856, 3, 265, 3, 265, 3, 1992, 8, 330, 28, 2753, 12, 8, 10, 3, 743, 2508, 3441, 8, 10, 3, 1276, 714, 8321, 110, 8, 3310, 2148, 14999, 8, 10, 1836, 4813, 11, 570, 8, 10, 177, 8, 9484, 2301, 2390, 5824, 204, 11545, 8, 10, 313, 2801, 11, 4573, 8, 10, 177, 6], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"},"metadata":{}}],"execution_count":49},{"cell_type":"code","source":"X_train: np.ndarray\ny_train: np.ndarray\nX_val: np.ndarray\ny_val: np.ndarray\nX_test: np.ndarray\ny_test: np.ndarray\n\nX_train, X_temp, y_train, y_temp = train_test_split(X, y, stratify=y, test_size=0.2,random_state=42)\nX_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, stratify=y_temp, test_size=0.5, random_state=42)\nprint(X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T17:40:25.809647Z","iopub.execute_input":"2025-02-11T17:40:25.809932Z","iopub.status.idle":"2025-02-11T17:40:25.833882Z","shell.execute_reply.started":"2025-02-11T17:40:25.809911Z","shell.execute_reply":"2025-02-11T17:40:25.833094Z"}},"outputs":[{"name":"stdout","text":"(10708,) (10708,) (1338,) (1338,) (1339,) (1339,)\n","output_type":"stream"}],"execution_count":50},{"cell_type":"code","source":"class CallCenterDataset(torch.utils.data.Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {\n            key: torch.tensor(val) for key, val in self.encodings[idx].items()\n            if key in ['input_ids', 'attention_mask'] # take only input_ids and attention_mask fields\n        }\n        item['labels'] = torch.tensor(self.labels[idx])\n        return item\n\n    def __len__(self):\n        return len(self.labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T17:40:38.752923Z","iopub.execute_input":"2025-02-11T17:40:38.753236Z","iopub.status.idle":"2025-02-11T17:40:38.758751Z","shell.execute_reply.started":"2025-02-11T17:40:38.753214Z","shell.execute_reply":"2025-02-11T17:40:38.757684Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"train_dataset = CallCenterDataset(X_train, y_train)\nval_dataset = CallCenterDataset(X_val, y_val)\ntest_dataset = CallCenterDataset(X_test, y_test)\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=data_collator)\nval_loader = DataLoader(val_dataset, batch_size=32, collate_fn=data_collator)\ntest_loader = DataLoader(test_dataset, batch_size=32, collate_fn=data_collator)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T18:00:02.308133Z","iopub.execute_input":"2025-02-11T18:00:02.308472Z","iopub.status.idle":"2025-02-11T18:00:02.313469Z","shell.execute_reply.started":"2025-02-11T18:00:02.308447Z","shell.execute_reply":"2025-02-11T18:00:02.312406Z"}},"outputs":[],"execution_count":76},{"cell_type":"code","source":"train_loader.dataset[0]['input_ids']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T18:05:22.110363Z","iopub.execute_input":"2025-02-11T18:05:22.110755Z","iopub.status.idle":"2025-02-11T18:05:22.117144Z","shell.execute_reply.started":"2025-02-11T18:05:22.110726Z","shell.execute_reply":"2025-02-11T18:05:22.116193Z"}},"outputs":[{"execution_count":83,"output_type":"execute_result","data":{"text/plain":"tensor([   5,   10, 4811,    8,   10, 3240,    8,   10,  177, 7268, 4090,  879,\n           6])"},"metadata":{}}],"execution_count":83},{"cell_type":"code","source":"train_loader.dataset[0]['labels']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T18:05:23.196395Z","iopub.execute_input":"2025-02-11T18:05:23.196708Z","iopub.status.idle":"2025-02-11T18:05:23.203198Z","shell.execute_reply.started":"2025-02-11T18:05:23.196686Z","shell.execute_reply":"2025-02-11T18:05:23.202223Z"}},"outputs":[{"execution_count":84,"output_type":"execute_result","data":{"text/plain":"tensor(1)"},"metadata":{}}],"execution_count":84},{"cell_type":"code","source":"class BaseModel(LightningModule):\n    def __init__(\n          self,\n          model_name: str = 'airesearch/wangchanberta-base-att-spm-uncased',\n          learning_rate: float = 2e-5\n    ):\n        super().__init__()\n        self.save_hyperparameters()\n\n        self.encoder = AutoModel.from_pretrained(model_name)\n        self.learning_rate = learning_rate\n\n    def get_embeddings(self, input_ids, attention_mask):\n        outputs = self.encoder(input_ids, attention_mask)\n        hidden_states = outputs.last_hidden_state\n\n        # [CLS] token is the first token in the sequence (index 0)\n        cls_embeddings = hidden_states[:, 0, :]  # [batch_size, hidden_size]\n        \n        return cls_embeddings\n\n    def configure_optimizers(self):\n        optimizer = torch.optim.AdamW(self.parameters(), lr=self.learning_rate)\n        return optimizer\n\n    def forward(self, input_ids, attention_mask):\n        return self.get_embeddings(input_ids, attention_mask)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T18:00:08.376469Z","iopub.execute_input":"2025-02-11T18:00:08.376798Z","iopub.status.idle":"2025-02-11T18:00:08.383044Z","shell.execute_reply.started":"2025-02-11T18:00:08.376775Z","shell.execute_reply":"2025-02-11T18:00:08.382007Z"}},"outputs":[],"execution_count":78},{"cell_type":"code","source":"class LMWithLinearClassfier(BaseModel):\n    def __init__(\n          self,\n          model_name: str = 'airesearch/wangchanberta-base-att-spm-uncased',\n          ckpt_path: str = None,\n          learning_rate: float = 2e-5,\n          freeze_encoder_weights: bool = False\n    ):\n        super().__init__(\n            model_name,\n            learning_rate\n        )\n        self.save_hyperparameters()\n\n        if ckpt_path:\n            checkpoint = torch.load(ckpt_path)\n            encoder_state_dict = {k.replace(\"encoder.\", \"\"): v for k, v in checkpoint[\"state_dict\"].items() if k.startswith(\"encoder.\")}\n            self.encoder.load_state_dict(encoder_state_dict)\n\n        self.linear_layer = nn.Linear(768, 25)\n\n        if freeze_encoder_weights:\n          self.freeze_weights(self.encoder)  # Freeze model\n\n        self.accuracy = Accuracy(task='multiclass', num_classes=25)\n\n    def freeze_weights(self, model):\n        for param in model.parameters():\n                param.requires_grad = False\n\n    def forward(self, input_ids, attention_mask):\n        cls_embeddings = self.get_embeddings(input_ids, attention_mask)\n        logits = self.linear_layer(cls_embeddings)\n        return logits\n\n    def training_step(self, batch, batch_idx):\n        input_ids = batch['input_ids']\n        attention_mask = batch['attention_mask']\n        labels = batch['labels']\n        logits = self.forward(input_ids, attention_mask)\n\n        loss = F.cross_entropy(logits, labels)\n        self.log('train_loss', loss, prog_bar=True)\n\n        acc = self.accuracy(logits, labels)\n        self.log('train_acc', acc, prog_bar=True)\n\n        return loss\n\n    def validation_step(self, batch, batch_idx):\n        input_ids = batch['input_ids']\n        attention_mask = batch['attention_mask']\n        labels = batch['labels']\n        logits = self.forward(input_ids, attention_mask)\n\n        loss = F.cross_entropy(logits, labels)\n        self.log('val_loss', loss, prog_bar=True)\n\n        acc = self.accuracy(logits, labels)\n        self.log('val_acc', acc, prog_bar=True)\n\n        return loss\n    \n    def test_step(self, batch, batch_idx):\n        input_ids = batch['input_ids']\n        attention_mask = batch['attention_mask']\n        labels = batch['labels']\n        logits = self.forward(input_ids, attention_mask)\n\n        loss = F.cross_entropy(logits, labels)\n        self.log('test_loss', loss, prog_bar=True)\n\n        acc = self.accuracy(logits, labels)\n        self.log('test_acc', acc, prog_bar=True)\n\n        return loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T18:06:25.741874Z","iopub.execute_input":"2025-02-11T18:06:25.742175Z","iopub.status.idle":"2025-02-11T18:06:25.753015Z","shell.execute_reply.started":"2025-02-11T18:06:25.742152Z","shell.execute_reply":"2025-02-11T18:06:25.752116Z"}},"outputs":[],"execution_count":87},{"cell_type":"code","source":"model = LMWithLinearClassfier(\n    'airesearch/wangchanberta-base-att-spm-uncased',\n    ckpt_path=None,\n    freeze_encoder_weights=False\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T18:59:27.283548Z","iopub.execute_input":"2025-02-11T18:59:27.283891Z","iopub.status.idle":"2025-02-11T18:59:28.511453Z","shell.execute_reply.started":"2025-02-11T18:59:27.283857Z","shell.execute_reply":"2025-02-11T18:59:28.510775Z"}},"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at airesearch/wangchanberta-base-att-spm-uncased were not used when initializing CamembertModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n- This IS expected if you are initializing CamembertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing CamembertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"}],"execution_count":92},{"cell_type":"code","source":"checkpoint_callback = pl.callbacks.ModelCheckpoint(\n    monitor=\"val_acc\",  # Metric to monitor\n    mode=\"max\",  # \"min\" for loss, \"max\" for accuracy\n    save_top_k=1,  # Save only the best model(s)\n    save_weights_only=True, # Saves only weights, not the entire model\n    dirpath=\"./checkpoints/\", # Path where the checkpoints will be saved\n    filename=\"best_pretrained_w_linear_model-{epoch}-{val_acc:.2f}\", # Customized name for the checkpoint\n    verbose=True,\n)\n\nlinear_trainer = Trainer(\n    max_epochs=5,\n    accelerator='auto',\n    callbacks=[checkpoint_callback], # Add the ModelCheckpoint callback\n    gradient_clip_val=1.0,\n    precision=16, # Mixed precision training\n    devices=1,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T18:59:30.458210Z","iopub.execute_input":"2025-02-11T18:59:30.458573Z","iopub.status.idle":"2025-02-11T18:59:30.504866Z","shell.execute_reply.started":"2025-02-11T18:59:30.458525Z","shell.execute_reply":"2025-02-11T18:59:30.504146Z"}},"outputs":[],"execution_count":93},{"cell_type":"code","source":"start_time = time.time()\n# Train the model\nlinear_trainer.fit(model, train_loader, val_loader)\nend_time = time.time()\n\nprint(f\"Total time: {end_time - start_time}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T18:59:34.253290Z","iopub.execute_input":"2025-02-11T18:59:34.253638Z","iopub.status.idle":"2025-02-11T19:03:04.460041Z","shell.execute_reply.started":"2025-02-11T18:59:34.253609Z","shell.execute_reply":"2025-02-11T19:03:04.459239Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/checkpoints exists and is not empty.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Sanity Checking: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"983b508e22d345c9bb3dd7093309c2a6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Total time: 210.2021267414093\n","output_type":"stream"}],"execution_count":94},{"cell_type":"code","source":"start_time = time.time()\nresult = linear_trainer.test(model, test_loader)\nend_time = time.time()\n\nprint(f\"Total time: {end_time - start_time}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T19:09:07.967132Z","iopub.execute_input":"2025-02-11T19:09:07.967475Z","iopub.status.idle":"2025-02-11T19:09:09.746040Z","shell.execute_reply.started":"2025-02-11T19:09:07.967418Z","shell.execute_reply":"2025-02-11T19:09:09.745165Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Testing: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c78ea3a0032423ea600438799872963"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6818521022796631    \u001b[0m\u001b[35m \u001b[0m│\n│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    1.19138503074646     \u001b[0m\u001b[35m \u001b[0m│\n└───────────────────────────┴───────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6818521022796631     </span>│\n│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     1.19138503074646      </span>│\n└───────────────────────────┴───────────────────────────┘\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Total time: 1.7742555141448975\n","output_type":"stream"}],"execution_count":96},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from IPython.display import display\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv('clean-phone-data-for-students.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence Utterance</th>\n",
       "      <th>Action</th>\n",
       "      <th>Object</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;PHONE_NUMBER_REMOVED&gt; ผมไปจ่ายเงินที่ Counte...</td>\n",
       "      <td>enquire</td>\n",
       "      <td>payment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>internet ยังความเร็วอยุ่เท่าไหร ครับ</td>\n",
       "      <td>enquire</td>\n",
       "      <td>package</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ตะกี้ไปชำระค่าบริการไปแล้ว แต่ยังใช้งานไม่ได้...</td>\n",
       "      <td>report</td>\n",
       "      <td>suspend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>พี่ค่ะยังใช้ internet ไม่ได้เลยค่ะ เป็นเครื่อ...</td>\n",
       "      <td>enquire</td>\n",
       "      <td>internet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ฮาโหล คะ พอดีว่าเมื่อวานเปิดซิมทรูมูฟ แต่มันโ...</td>\n",
       "      <td>report</td>\n",
       "      <td>phone_issues</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Sentence Utterance   Action        Object\n",
       "0   <PHONE_NUMBER_REMOVED> ผมไปจ่ายเงินที่ Counte...  enquire       payment\n",
       "1               internet ยังความเร็วอยุ่เท่าไหร ครับ  enquire       package\n",
       "2   ตะกี้ไปชำระค่าบริการไปแล้ว แต่ยังใช้งานไม่ได้...   report       suspend\n",
       "3   พี่ค่ะยังใช้ internet ไม่ได้เลยค่ะ เป็นเครื่อ...  enquire      internet\n",
       "4   ฮาโหล คะ พอดีว่าเมื่อวานเปิดซิมทรูมูฟ แต่มันโ...   report  phone_issues"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence Utterance</th>\n",
       "      <th>Action</th>\n",
       "      <th>Object</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>16175</td>\n",
       "      <td>16175</td>\n",
       "      <td>16175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>13389</td>\n",
       "      <td>10</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>บริการอื่นๆ</td>\n",
       "      <td>enquire</td>\n",
       "      <td>service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>97</td>\n",
       "      <td>10377</td>\n",
       "      <td>2525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sentence Utterance   Action   Object\n",
       "count               16175    16175    16175\n",
       "unique              13389       10       33\n",
       "top           บริการอื่นๆ  enquire  service\n",
       "freq                   97    10377     2525"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(data_df.head())\n",
    "data_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>raw_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>16175</td>\n",
       "      <td>16175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>13389</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>บริการอื่นๆ</td>\n",
       "      <td>service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>97</td>\n",
       "      <td>2525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              input raw_label\n",
       "count         16175     16175\n",
       "unique        13389        33\n",
       "top     บริการอื่นๆ   service\n",
       "freq             97      2525"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['payment', 'package', 'suspend', 'internet', 'phone_issues',\n",
       "       'service', 'nonTrueMove', 'balance', 'detail', 'bill', 'credit',\n",
       "       'promotion', 'mobile_setting', 'iservice', 'roaming', 'truemoney',\n",
       "       'information', 'lost_stolen', 'balance_minutes', 'idd',\n",
       "       'TrueMoney', 'garbage', 'Payment', 'IDD', 'ringtone', 'Idd',\n",
       "       'rate', 'loyalty_card', 'contact', 'officer', 'Balance', 'Service',\n",
       "       'Loyalty_card'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_df = data_df[[\"Sentence Utterance\", \"Object\"]]\n",
    "data_df.columns = ['input', 'raw_label']\n",
    "display(data_df.describe())\n",
    "display(data_df.raw_label.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>clean_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>16175</td>\n",
       "      <td>16175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>13389</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>บริการอื่นๆ</td>\n",
       "      <td>service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>97</td>\n",
       "      <td>2528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              input clean_label\n",
       "count         16175       16175\n",
       "unique        13389          26\n",
       "top     บริการอื่นๆ     service\n",
       "freq             97        2528"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['payment', 'package', 'suspend', 'internet', 'phone_issues',\n",
       "       'service', 'nontruemove', 'balance', 'detail', 'bill', 'credit',\n",
       "       'promotion', 'mobile_setting', 'iservice', 'roaming', 'truemoney',\n",
       "       'information', 'lost_stolen', 'balance_minutes', 'idd', 'garbage',\n",
       "       'ringtone', 'rate', 'loyalty_card', 'contact', 'officer'],\n",
       "      dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_df['clean_label']=data_df['raw_label'].str.lower().copy()\n",
    "data_df.drop('raw_label', axis=1, inplace=True)\n",
    "display(data_df.describe())\n",
    "display(data_df.clean_label.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>clean_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13389</td>\n",
       "      <td>13389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>13389</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>&lt;PHONE_NUMBER_REMOVED&gt; ผมไปจ่ายเงินที่ Counte...</td>\n",
       "      <td>service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>2111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    input clean_label\n",
       "count                                               13389       13389\n",
       "unique                                              13389          26\n",
       "top      <PHONE_NUMBER_REMOVED> ผมไปจ่ายเงินที่ Counte...     service\n",
       "freq                                                    1        2111"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_df = data_df.drop_duplicates(\"input\", keep=\"first\")\n",
    "data_df = data_df.reset_index(drop=True)\n",
    "display(data_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clean_label\n",
       "service            2111\n",
       "package            1797\n",
       "internet           1790\n",
       "balance            1482\n",
       "promotion          1145\n",
       "suspend             730\n",
       "payment             641\n",
       "phone_issues        581\n",
       "bill                540\n",
       "detail              327\n",
       "information         297\n",
       "mobile_setting      281\n",
       "truemoney           248\n",
       "nontruemove         246\n",
       "roaming             246\n",
       "lost_stolen         231\n",
       "idd                 206\n",
       "credit              173\n",
       "ringtone             79\n",
       "loyalty_card         67\n",
       "balance_minutes      50\n",
       "garbage              49\n",
       "rate                 36\n",
       "iservice             22\n",
       "officer              10\n",
       "contact               4\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df['clean_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove class `contact` as it has only 4 sample (cannot do train 80 val 10 test 10)\n",
    "data_df = data_df[data_df.clean_label != 'contact']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1 TF-IDF\n",
    "\n",
    "Build a model to train a tf-idf text classifier. Use a simple logistic regression model for the classifier.\n",
    "\n",
    "For this part, you may find this [tutorial](https://scikit-learn.org/stable/auto_examples/text/plot_document_classification_20newsgroups.html#sphx-glr-auto-examples-text-plot-document-classification-20newsgroups-py) helpful.\n",
    "\n",
    "Below are some design choices you need to consider to accomplish this task. Be sure to answer them when you submit your model.\n",
    "\n",
    "What tokenizer will you use? Why?\n",
    "\n",
    "**Ans:**\n",
    "`attacut`, because it is fast and accurate for Thai text. Although it is not the best tokenizer for Thai text, it is good enough for this task. The code below show comparison in time between `attacut` vs `deepcut` tokenizers. `deepcut` is the \"best\" tokenizer for Thai text, but it is a lot slower than `attacut`.\n",
    "\n",
    "Will you ignore some stop words (a, an, the, to, etc. for English) in your tf-idf? Is it important?\n",
    "PythaiNLP provides a list of stopwords if you want to use (https://pythainlp.org/docs/2.0/api/corpus.html#pythainlp.corpus.common.thai_stopwords)\n",
    "\n",
    "**Ans:**\n",
    "From my experiment:\n",
    "- Accuracy on test set including stop words: 65.273%, time used for inference: 0.472s\n",
    "- Accuracy on test set excluding stop words: 60.119%, time used for inference: 0.730s\n",
    "\n",
    "> Note that the stop words used are sole from `pythainlp.corpus.common.thai_stopwords`. `PHONE_NUMBER_REMOVED` was NOT added to the stop words list as it occurred only 401 times from 13389 samples (it must have some correlation to label class).\n",
    "\n",
    "The dictionary of TF-IDF is usually based on the training data. How many words in the test set are OOVs?\n",
    "\n",
    "**Ans:**\n",
    "- 751 words in the test set are OOVs (not found in the training set's vocabulary)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepcut\n",
    "import attacut\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import pythainlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Total time: 17.082552909851074\n"
     ]
    }
   ],
   "source": [
    "# 19 secs for 100 samples\n",
    "# 13389 samples = 42 mins; ain't nobody got time for that\n",
    "start_time = time.time()\n",
    "for i in range(100):\n",
    "    # print(f\"original: {data_df['input'][i]}\")\n",
    "    # print(deepcut.tokenize(data_df['input'][i]))\n",
    "    deepcut.tokenize(data_df['input'][i])\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Total time: {end_time - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages/attacut/models/__init__.py:60: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=\"cpu\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 3.103543996810913\n"
     ]
    }
   ],
   "source": [
    "# 2.25 secs for 100 samples\n",
    "# 13389 samples = 5 mins; now we're talking\n",
    "start_time = time.time()\n",
    "for i in range(100):\n",
    "    attacut.tokenize(data_df['input'][0])\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Total time: {end_time - start_time}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create Mappings\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 'payment',\n",
       " 1: 'package',\n",
       " 2: 'suspend',\n",
       " 3: 'internet',\n",
       " 4: 'phone_issues',\n",
       " 5: 'service',\n",
       " 6: 'nontruemove',\n",
       " 7: 'balance',\n",
       " 8: 'detail',\n",
       " 9: 'bill',\n",
       " 10: 'credit',\n",
       " 11: 'promotion',\n",
       " 12: 'mobile_setting',\n",
       " 13: 'iservice',\n",
       " 14: 'roaming',\n",
       " 15: 'truemoney',\n",
       " 16: 'information',\n",
       " 17: 'lost_stolen',\n",
       " 18: 'balance_minutes',\n",
       " 19: 'idd',\n",
       " 20: 'garbage',\n",
       " 21: 'ringtone',\n",
       " 22: 'rate',\n",
       " 23: 'loyalty_card',\n",
       " 24: 'officer'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'payment': 0,\n",
       " 'package': 1,\n",
       " 'suspend': 2,\n",
       " 'internet': 3,\n",
       " 'phone_issues': 4,\n",
       " 'service': 5,\n",
       " 'nontruemove': 6,\n",
       " 'balance': 7,\n",
       " 'detail': 8,\n",
       " 'bill': 9,\n",
       " 'credit': 10,\n",
       " 'promotion': 11,\n",
       " 'mobile_setting': 12,\n",
       " 'iservice': 13,\n",
       " 'roaming': 14,\n",
       " 'truemoney': 15,\n",
       " 'information': 16,\n",
       " 'lost_stolen': 17,\n",
       " 'balance_minutes': 18,\n",
       " 'idd': 19,\n",
       " 'garbage': 20,\n",
       " 'ringtone': 21,\n",
       " 'rate': 22,\n",
       " 'loyalty_card': 23,\n",
       " 'officer': 24}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = data_df.copy().to_numpy()\n",
    "\n",
    "unique_label = data_df.clean_label.unique()\n",
    "\n",
    "label_2_num_map = dict(zip(unique_label, range(len(unique_label))))\n",
    "num_2_label_map = dict(zip(range(len(unique_label)), unique_label))\n",
    "\n",
    "print(\"Create Mappings\")\n",
    "display(num_2_label_map)\n",
    "display(label_2_num_map)\n",
    "\n",
    "# print(\"Before Mappings\")\n",
    "# display(data[:, 1])\n",
    "data[:,1] = np.vectorize(label_2_num_map.get)(data[:,1])\n",
    "# print(\"After Mappings\")\n",
    "# display(data[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_str(string):\n",
    "    return string.strip()\n",
    "     \n",
    "# print(\"Before\")\n",
    "# print(data)\n",
    "data[:,0] = np.vectorize(strip_str)(data[:,0])\n",
    "# print(\"After\")\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['<PHONE_NUMBER_REMOVED> ผมไปจ่ายเงินที่ Counter Services เค้าเช็ต 3276.25 บาท เมื่อวานที่ผมเช็คที่ศูนย์บอกมียอด 3057.79 บาท',\n",
       "        0],\n",
       "       ['internet ยังความเร็วอยุ่เท่าไหร ครับ', 1],\n",
       "       ['ตะกี้ไปชำระค่าบริการไปแล้ว แต่ยังใช้งานไม่ได้ ค่ะ', 2],\n",
       "       ...,\n",
       "       ['ยอดเงินเหลือเท่าไหร่ค่ะ', 7],\n",
       "       ['ยอดเงินในระบบ', 7],\n",
       "       ['สอบถามโปรโมชั่นปัจจุบันที่ใช้อยู่ค่ะ', 1]], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13385,) (13385,)\n"
     ]
    }
   ],
   "source": [
    "x = data[:, 0]\n",
    "y = data[:, 1]\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10708,) (10708,) (1338,) (1338,) (1339,) (1339,)\n"
     ]
    }
   ],
   "source": [
    "X_train: np.ndarray\n",
    "y_train: np.ndarray\n",
    "X_val: np.ndarray\n",
    "y_val: np.ndarray\n",
    "X_test: np.ndarray\n",
    "y_test: np.ndarray\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(x, y, stratify=y, test_size=0.2,random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, stratify=y_temp, test_size=0.5, random_state=42)\n",
    "print(X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10708/10708 [04:26<00:00, 40.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vocab = defaultdict(lambda: len(vocab))\n",
    "vocab[\"<UNK>\"] = 0\n",
    "\n",
    "token_count = defaultdict(int)\n",
    "\n",
    "for i in tqdm(range(len(X_train))):\n",
    "    tokens = attacut.tokenize(X_train[i])\n",
    "    for token in tokens:\n",
    "        vocab[token]\n",
    "        token_count[token] += 1\n",
    "    \n",
    "# 4728 unique tokens in training set (+ 1 from UNK)\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13389/13389 [04:25<00:00, 50.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vocab_ = defaultdict(lambda: len(vocab_))\n",
    "for i in tqdm(range(len(data))):\n",
    "    tokens = attacut.tokenize(data[i][0])\n",
    "    for token in tokens:\n",
    "        vocab_[token]\n",
    "# 5447 unique tokens in entire dataset\n",
    "print(len(vocab_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1339 [00:00<?, ?it/s]/Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages/attacut/models/__init__.py:60: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=\"cpu\"))\n",
      "100%|██████████| 1339/1339 [00:32<00:00, 41.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "oov_count = 0\n",
    "for i in tqdm(range(len(X_test))):\n",
    "    tokens = attacut.tokenize(X_test[i])\n",
    "    for token in tokens:\n",
    "        token_count[token] += 1\n",
    "        if token not in vocab:\n",
    "            oov_count += 1\n",
    "\n",
    "# 373 unique tokens in test set but not in training set (OOV)\n",
    "print(oov_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' ', 27095),\n",
       " ('ค่ะ', 6699),\n",
       " ('จะ', 6019),\n",
       " ('ครับ', 5646),\n",
       " ('ได้', 4253),\n",
       " ('ไม่', 4023),\n",
       " ('ใช้', 3735),\n",
       " ('สอบถาม', 3532),\n",
       " ('ผม', 3045),\n",
       " ('ว่า', 3034),\n",
       " ('แล้ว', 2744),\n",
       " ('ที่', 2567),\n",
       " ('ไป', 2476),\n",
       " ('นี้', 2440),\n",
       " ('อยาก', 2307),\n",
       " ('มา', 2079),\n",
       " ('มัน', 2053),\n",
       " ('เบอร์', 1974),\n",
       " ('ค่า', 1927),\n",
       " ('มี', 1901),\n",
       " ('บริการ', 1880),\n",
       " ('คะ', 1834),\n",
       " ('โทร', 1746),\n",
       " ('เงิน', 1685),\n",
       " ('ยัง', 1642),\n",
       " ('ของ', 1621),\n",
       " ('ให้', 1551),\n",
       " ('สมัคร', 1532),\n",
       " ('พอดี', 1508),\n",
       " ('เปิด', 1399),\n",
       " ('ขอ', 1302),\n",
       " ('พี่', 1292),\n",
       " ('ยอด', 1283),\n",
       " ('เป็น', 1251),\n",
       " ('โปรโมชั่น', 1177),\n",
       " ('งาน', 1172),\n",
       " ('การ', 1171),\n",
       " ('ยกเลิก', 1171),\n",
       " ('ชำระ', 1150),\n",
       " ('หน่อย', 1145),\n",
       " ('ต้องการ', 1116),\n",
       " ('อะไร', 1074),\n",
       " ('สัญญาณ', 1058),\n",
       " ('โทรศัพท์', 1058),\n",
       " ('คือ', 1042),\n",
       " ('ทราบ', 1040),\n",
       " ('แต่', 1027),\n",
       " ('อินเตอร์เน็ต', 1003),\n",
       " ('อ่ะ', 987),\n",
       " ('เลย', 986),\n",
       " ('เติม', 943),\n",
       " ('เรื่อง', 930),\n",
       " ('เปลี่ยน', 929),\n",
       " ('เข้า', 927),\n",
       " ('อยู่', 883),\n",
       " ('ต้อง', 881),\n",
       " ('เดือน', 852),\n",
       " ('กับ', 842),\n",
       " ('ตอน', 811),\n",
       " ('วัน', 801),\n",
       " ('แจ้ง', 778),\n",
       " ('ทำ', 738),\n",
       " ('หรือ', 707),\n",
       " ('ซิม', 681),\n",
       " ('ทรูมูฟ', 671),\n",
       " ('ไง', 669),\n",
       " ('เช็ค', 621),\n",
       " ('จ่าย', 611),\n",
       " ('นะ', 606),\n",
       " ('ซื้อ', 597),\n",
       " ('เล่น', 572),\n",
       " ('เน็ต', 572),\n",
       " ('ทำไม', 570),\n",
       " ('เมื่อ', 565),\n",
       " ('เครื่อง', 550),\n",
       " ('บ้าง', 545),\n",
       " ('ระงับ', 544),\n",
       " ('ถาม', 543),\n",
       " ('ข้อความ', 540),\n",
       " ('เท่า', 530),\n",
       " ('ไหม', 521),\n",
       " ('บาท', 507),\n",
       " ('สวัสดี', 495),\n",
       " ('ราย', 485),\n",
       " ('ตัด', 483),\n",
       " ('เกี่ยว', 480),\n",
       " ('<', 475),\n",
       " ('มั้ย', 470),\n",
       " ('>', 468),\n",
       " ('จาก', 460),\n",
       " ('ออก', 452),\n",
       " ('ไหร่', 452),\n",
       " ('รบกวน', 446),\n",
       " ('ถ้า', 442),\n",
       " ('โปร', 441),\n",
       " ('PHONE_NUMBER_REMOVED', 436),\n",
       " ('ค้าง', 430),\n",
       " ('ถูก', 424),\n",
       " ('ใน', 413),\n",
       " ('ส่ง', 405)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort by frequency\n",
    "sorted_token_count = sorted(token_count.items(), key=lambda x: x[1], reverse=True)\n",
    "sorted_token_count[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythainlp.corpus.common import thai_stopwords\n",
    "\n",
    "stopwords = thai_stopwords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_token_ids(X: np.ndarray):\n",
    "    new_X = np.zeros(X.shape, dtype=object)\n",
    "    for i in tqdm(range(len(X))):\n",
    "        token_ids = []\n",
    "        tokens = attacut.tokenize(X[i])\n",
    "        # should we remove any tokens?\n",
    "        # this line later added to test if removing stopwords is necessary\n",
    "        tokens = [token for token in tokens if token not in stopwords]\n",
    "\n",
    "        for token in tokens:\n",
    "            if token in vocab:\n",
    "                token_ids.append(vocab[token])\n",
    "            else:\n",
    "                token_ids.append(vocab[\"<UNK>\"])\n",
    "        \n",
    "        new_X[i] = token_ids\n",
    "    \n",
    "    return new_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "เดือนละ 150 บาทเล่นได้ทั้งวันหรือเปล่า\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10708/10708 [04:05<00:00, 43.56it/s]\n",
      "100%|██████████| 1339/1339 [00:34<00:00, 38.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 4, 3, 5, 6, 11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])\n",
    "X_train = string_to_token_ids(X_train)\n",
    "X_test = string_to_token_ids(X_test)\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10708/10708 [00:00<00:00, 148213.71it/s]\n"
     ]
    }
   ],
   "source": [
    "num_docs_with_w = defaultdict(int)\n",
    "for i in tqdm(range(len(X_train))):\n",
    "    unique_tokens = set(X_train[i])\n",
    "    \n",
    "    for token in unique_tokens:\n",
    "        num_docs_with_w[token] += 1\n",
    "# sort token idx\n",
    "num_docs_with_w = dict(sorted(num_docs_with_w.items(), key=lambda x: x[0]))\n",
    "\n",
    "idf = np.log(len(X_train) / np.array(list(num_docs_with_w.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4456"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 597,\n",
       " 3: 6921,\n",
       " 4: 25,\n",
       " 5: 344,\n",
       " 6: 369,\n",
       " 11: 271,\n",
       " 15: 794,\n",
       " 16: 1307,\n",
       " 17: 1278,\n",
       " 20: 156,\n",
       " 21: 717,\n",
       " 24: 404,\n",
       " 25: 443,\n",
       " 30: 19,\n",
       " 31: 168,\n",
       " 32: 269,\n",
       " 38: 57,\n",
       " 39: 1575,\n",
       " 40: 1115,\n",
       " 41: 534,\n",
       " 42: 656,\n",
       " 43: 724,\n",
       " 44: 62,\n",
       " 46: 15,\n",
       " 48: 389,\n",
       " 50: 549,\n",
       " 53: 1,\n",
       " 54: 4,\n",
       " 55: 795,\n",
       " 57: 838,\n",
       " 59: 100,\n",
       " 61: 151,\n",
       " 62: 1010,\n",
       " 66: 564,\n",
       " 67: 1060,\n",
       " 77: 9,\n",
       " 79: 206,\n",
       " 81: 395,\n",
       " 83: 327,\n",
       " 84: 426,\n",
       " 85: 13,\n",
       " 87: 52,\n",
       " 88: 1,\n",
       " 89: 172,\n",
       " 90: 146,\n",
       " 92: 368,\n",
       " 93: 6,\n",
       " 95: 3,\n",
       " 96: 68,\n",
       " 98: 265,\n",
       " 101: 151,\n",
       " 102: 13,\n",
       " 103: 17,\n",
       " 104: 277,\n",
       " 106: 531,\n",
       " 108: 10,\n",
       " 111: 830,\n",
       " 112: 438,\n",
       " 115: 9,\n",
       " 117: 2,\n",
       " 118: 1,\n",
       " 120: 732,\n",
       " 121: 18,\n",
       " 122: 3,\n",
       " 124: 724,\n",
       " 126: 233,\n",
       " 127: 303,\n",
       " 128: 41,\n",
       " 129: 125,\n",
       " 130: 20,\n",
       " 131: 1,\n",
       " 132: 377,\n",
       " 134: 244,\n",
       " 136: 79,\n",
       " 137: 2,\n",
       " 138: 14,\n",
       " 141: 88,\n",
       " 142: 166,\n",
       " 143: 5,\n",
       " 144: 1,\n",
       " 145: 6,\n",
       " 148: 18,\n",
       " 149: 1,\n",
       " 150: 183,\n",
       " 151: 320,\n",
       " 152: 6,\n",
       " 154: 668,\n",
       " 155: 138,\n",
       " 157: 2524,\n",
       " 159: 15,\n",
       " 161: 58,\n",
       " 162: 4,\n",
       " 163: 2,\n",
       " 166: 205,\n",
       " 167: 1,\n",
       " 168: 40,\n",
       " 169: 338,\n",
       " 171: 91,\n",
       " 172: 390,\n",
       " 174: 4,\n",
       " 175: 1,\n",
       " 176: 1,\n",
       " 177: 2,\n",
       " 178: 12,\n",
       " 179: 111,\n",
       " 182: 826,\n",
       " 183: 3,\n",
       " 184: 120,\n",
       " 185: 136,\n",
       " 186: 1318,\n",
       " 187: 62,\n",
       " 188: 9,\n",
       " 189: 184,\n",
       " 190: 206,\n",
       " 191: 53,\n",
       " 192: 27,\n",
       " 193: 3,\n",
       " 195: 94,\n",
       " 196: 61,\n",
       " 197: 6,\n",
       " 198: 1,\n",
       " 200: 432,\n",
       " 202: 154,\n",
       " 203: 184,\n",
       " 204: 227,\n",
       " 205: 367,\n",
       " 207: 34,\n",
       " 209: 150,\n",
       " 210: 735,\n",
       " 212: 2,\n",
       " 213: 57,\n",
       " 214: 45,\n",
       " 215: 109,\n",
       " 217: 1,\n",
       " 218: 55,\n",
       " 219: 113,\n",
       " 220: 79,\n",
       " 223: 840,\n",
       " 224: 316,\n",
       " 226: 155,\n",
       " 232: 4,\n",
       " 233: 160,\n",
       " 234: 1,\n",
       " 235: 17,\n",
       " 236: 233,\n",
       " 237: 1,\n",
       " 238: 108,\n",
       " 239: 103,\n",
       " 241: 22,\n",
       " 243: 2,\n",
       " 244: 52,\n",
       " 245: 334,\n",
       " 246: 311,\n",
       " 247: 329,\n",
       " 248: 15,\n",
       " 249: 127,\n",
       " 250: 16,\n",
       " 252: 41,\n",
       " 253: 15,\n",
       " 254: 1,\n",
       " 255: 363,\n",
       " 257: 37,\n",
       " 258: 40,\n",
       " 259: 26,\n",
       " 260: 44,\n",
       " 261: 7,\n",
       " 263: 1,\n",
       " 264: 7,\n",
       " 265: 35,\n",
       " 267: 15,\n",
       " 269: 14,\n",
       " 270: 77,\n",
       " 272: 4,\n",
       " 273: 27,\n",
       " 274: 1,\n",
       " 275: 1,\n",
       " 276: 11,\n",
       " 277: 1,\n",
       " 278: 12,\n",
       " 279: 92,\n",
       " 280: 10,\n",
       " 281: 6,\n",
       " 282: 255,\n",
       " 283: 94,\n",
       " 285: 321,\n",
       " 286: 8,\n",
       " 287: 1,\n",
       " 289: 18,\n",
       " 290: 1,\n",
       " 291: 15,\n",
       " 293: 8,\n",
       " 294: 15,\n",
       " 295: 7,\n",
       " 296: 12,\n",
       " 297: 7,\n",
       " 298: 10,\n",
       " 299: 8,\n",
       " 300: 21,\n",
       " 301: 1,\n",
       " 302: 69,\n",
       " 303: 79,\n",
       " 305: 60,\n",
       " 306: 2,\n",
       " 307: 5,\n",
       " 308: 4,\n",
       " 309: 43,\n",
       " 310: 33,\n",
       " 311: 23,\n",
       " 312: 22,\n",
       " 313: 132,\n",
       " 314: 178,\n",
       " 315: 38,\n",
       " 316: 170,\n",
       " 317: 29,\n",
       " 318: 16,\n",
       " 319: 48,\n",
       " 320: 114,\n",
       " 321: 239,\n",
       " 323: 86,\n",
       " 324: 7,\n",
       " 325: 2,\n",
       " 326: 2,\n",
       " 327: 3,\n",
       " 328: 121,\n",
       " 329: 16,\n",
       " 330: 95,\n",
       " 332: 7,\n",
       " 333: 9,\n",
       " 335: 118,\n",
       " 336: 65,\n",
       " 337: 3,\n",
       " 339: 39,\n",
       " 340: 20,\n",
       " 341: 34,\n",
       " 343: 52,\n",
       " 344: 183,\n",
       " 345: 83,\n",
       " 346: 44,\n",
       " 347: 33,\n",
       " 348: 30,\n",
       " 349: 1,\n",
       " 350: 2,\n",
       " 351: 2,\n",
       " 354: 16,\n",
       " 355: 67,\n",
       " 357: 102,\n",
       " 358: 9,\n",
       " 359: 3,\n",
       " 360: 1,\n",
       " 361: 10,\n",
       " 362: 4,\n",
       " 363: 31,\n",
       " 364: 3,\n",
       " 365: 24,\n",
       " 366: 10,\n",
       " 367: 9,\n",
       " 368: 36,\n",
       " 369: 11,\n",
       " 370: 39,\n",
       " 371: 41,\n",
       " 374: 87,\n",
       " 375: 2,\n",
       " 376: 5,\n",
       " 377: 8,\n",
       " 378: 33,\n",
       " 379: 37,\n",
       " 381: 142,\n",
       " 382: 110,\n",
       " 383: 1,\n",
       " 384: 83,\n",
       " 385: 103,\n",
       " 386: 14,\n",
       " 387: 14,\n",
       " 389: 75,\n",
       " 390: 16,\n",
       " 391: 100,\n",
       " 392: 1,\n",
       " 394: 25,\n",
       " 395: 11,\n",
       " 396: 9,\n",
       " 397: 17,\n",
       " 398: 11,\n",
       " 400: 2,\n",
       " 401: 7,\n",
       " 402: 14,\n",
       " 403: 31,\n",
       " 405: 4,\n",
       " 406: 1,\n",
       " 407: 17,\n",
       " 408: 245,\n",
       " 409: 26,\n",
       " 410: 4,\n",
       " 411: 2,\n",
       " 412: 100,\n",
       " 413: 27,\n",
       " 414: 116,\n",
       " 415: 129,\n",
       " 416: 56,\n",
       " 417: 2,\n",
       " 418: 34,\n",
       " 419: 17,\n",
       " 421: 9,\n",
       " 422: 6,\n",
       " 423: 3,\n",
       " 424: 2,\n",
       " 425: 8,\n",
       " 426: 10,\n",
       " 427: 7,\n",
       " 428: 8,\n",
       " 429: 63,\n",
       " 430: 20,\n",
       " 432: 7,\n",
       " 433: 38,\n",
       " 434: 14,\n",
       " 435: 5,\n",
       " 436: 1,\n",
       " 437: 2,\n",
       " 438: 40,\n",
       " 439: 5,\n",
       " 440: 1,\n",
       " 441: 4,\n",
       " 443: 1,\n",
       " 444: 1,\n",
       " 445: 43,\n",
       " 446: 1,\n",
       " 447: 101,\n",
       " 448: 4,\n",
       " 449: 52,\n",
       " 450: 6,\n",
       " 451: 21,\n",
       " 452: 32,\n",
       " 456: 15,\n",
       " 457: 20,\n",
       " 459: 1,\n",
       " 462: 1,\n",
       " 463: 3,\n",
       " 464: 6,\n",
       " 465: 1,\n",
       " 467: 1,\n",
       " 468: 10,\n",
       " 469: 1,\n",
       " 471: 7,\n",
       " 472: 32,\n",
       " 473: 11,\n",
       " 474: 2,\n",
       " 475: 25,\n",
       " 476: 1,\n",
       " 477: 27,\n",
       " 478: 9,\n",
       " 479: 113,\n",
       " 481: 10,\n",
       " 482: 2,\n",
       " 483: 2,\n",
       " 484: 16,\n",
       " 485: 3,\n",
       " 486: 4,\n",
       " 488: 16,\n",
       " 489: 44,\n",
       " 490: 26,\n",
       " 491: 18,\n",
       " 492: 1,\n",
       " 493: 2,\n",
       " 494: 5,\n",
       " 496: 7,\n",
       " 497: 1,\n",
       " 498: 3,\n",
       " 499: 1,\n",
       " 500: 15,\n",
       " 501: 7,\n",
       " 502: 5,\n",
       " 503: 15,\n",
       " 504: 2,\n",
       " 505: 3,\n",
       " 507: 5,\n",
       " 508: 65,\n",
       " 509: 1,\n",
       " 510: 80,\n",
       " 511: 6,\n",
       " 512: 1,\n",
       " 513: 3,\n",
       " 514: 3,\n",
       " 515: 14,\n",
       " 516: 12,\n",
       " 517: 1,\n",
       " 518: 2,\n",
       " 519: 1,\n",
       " 521: 17,\n",
       " 522: 3,\n",
       " 524: 2,\n",
       " 525: 37,\n",
       " 526: 2,\n",
       " 527: 3,\n",
       " 528: 1,\n",
       " 529: 1,\n",
       " 530: 11,\n",
       " 531: 1,\n",
       " 532: 35,\n",
       " 533: 24,\n",
       " 534: 2,\n",
       " 535: 13,\n",
       " 536: 12,\n",
       " 537: 54,\n",
       " 539: 29,\n",
       " 540: 3,\n",
       " 542: 11,\n",
       " 543: 20,\n",
       " 544: 1,\n",
       " 545: 3,\n",
       " 546: 41,\n",
       " 547: 1,\n",
       " 548: 30,\n",
       " 549: 1,\n",
       " 550: 3,\n",
       " 551: 2,\n",
       " 552: 1,\n",
       " 553: 10,\n",
       " 555: 1,\n",
       " 556: 17,\n",
       " 557: 37,\n",
       " 558: 1,\n",
       " 559: 1,\n",
       " 560: 5,\n",
       " 561: 7,\n",
       " 562: 15,\n",
       " 564: 2,\n",
       " 565: 21,\n",
       " 566: 7,\n",
       " 567: 1,\n",
       " 568: 1,\n",
       " 569: 3,\n",
       " 570: 15,\n",
       " 571: 8,\n",
       " 572: 1,\n",
       " 573: 6,\n",
       " 574: 49,\n",
       " 576: 7,\n",
       " 577: 16,\n",
       " 581: 30,\n",
       " 582: 35,\n",
       " 583: 3,\n",
       " 584: 8,\n",
       " 585: 10,\n",
       " 586: 2,\n",
       " 587: 1,\n",
       " 588: 1,\n",
       " 589: 28,\n",
       " 590: 1,\n",
       " 591: 28,\n",
       " 592: 21,\n",
       " 593: 52,\n",
       " 594: 2,\n",
       " 596: 2,\n",
       " 598: 1,\n",
       " 600: 18,\n",
       " 601: 15,\n",
       " 602: 3,\n",
       " 605: 70,\n",
       " 606: 11,\n",
       " 607: 1,\n",
       " 608: 9,\n",
       " 609: 2,\n",
       " 610: 2,\n",
       " 612: 8,\n",
       " 613: 3,\n",
       " 614: 17,\n",
       " 615: 1,\n",
       " 616: 15,\n",
       " 617: 3,\n",
       " 619: 1,\n",
       " 620: 18,\n",
       " 621: 4,\n",
       " 623: 1,\n",
       " 624: 2,\n",
       " 625: 3,\n",
       " 626: 3,\n",
       " 628: 5,\n",
       " 629: 2,\n",
       " 630: 1,\n",
       " 631: 54,\n",
       " 632: 10,\n",
       " 633: 1,\n",
       " 634: 8,\n",
       " 635: 80,\n",
       " 636: 16,\n",
       " 637: 2,\n",
       " 638: 101,\n",
       " 639: 6,\n",
       " 641: 77,\n",
       " 642: 5,\n",
       " 643: 3,\n",
       " 644: 18,\n",
       " 645: 1,\n",
       " 646: 1,\n",
       " 647: 1,\n",
       " 648: 1,\n",
       " 649: 11,\n",
       " 650: 1,\n",
       " 652: 1,\n",
       " 653: 33,\n",
       " 654: 8,\n",
       " 655: 11,\n",
       " 656: 6,\n",
       " 657: 23,\n",
       " 658: 2,\n",
       " 659: 1,\n",
       " 660: 106,\n",
       " 661: 1,\n",
       " 662: 11,\n",
       " 663: 1,\n",
       " 664: 65,\n",
       " 665: 1,\n",
       " 666: 15,\n",
       " 667: 1,\n",
       " 668: 85,\n",
       " 670: 3,\n",
       " 671: 38,\n",
       " 672: 7,\n",
       " 673: 3,\n",
       " 674: 31,\n",
       " 675: 1,\n",
       " 676: 6,\n",
       " 677: 1,\n",
       " 679: 17,\n",
       " 680: 5,\n",
       " 681: 1,\n",
       " 682: 7,\n",
       " 683: 4,\n",
       " 684: 4,\n",
       " 685: 1,\n",
       " 686: 1,\n",
       " 687: 10,\n",
       " 689: 11,\n",
       " 690: 37,\n",
       " 691: 11,\n",
       " 692: 2,\n",
       " 693: 1,\n",
       " 694: 15,\n",
       " 695: 39,\n",
       " 696: 4,\n",
       " 697: 2,\n",
       " 698: 7,\n",
       " 699: 13,\n",
       " 700: 44,\n",
       " 701: 4,\n",
       " 702: 15,\n",
       " 703: 12,\n",
       " 704: 10,\n",
       " 705: 23,\n",
       " 706: 1,\n",
       " 707: 1,\n",
       " 708: 1,\n",
       " 709: 79,\n",
       " 710: 22,\n",
       " 711: 5,\n",
       " 712: 7,\n",
       " 713: 1,\n",
       " 714: 1,\n",
       " 716: 26,\n",
       " 717: 10,\n",
       " 718: 1,\n",
       " 719: 16,\n",
       " 720: 26,\n",
       " 721: 1,\n",
       " 723: 8,\n",
       " 724: 3,\n",
       " 725: 4,\n",
       " 726: 5,\n",
       " 727: 2,\n",
       " 728: 2,\n",
       " 730: 21,\n",
       " 731: 23,\n",
       " 732: 1,\n",
       " 733: 15,\n",
       " 734: 6,\n",
       " 735: 26,\n",
       " 736: 1,\n",
       " 737: 9,\n",
       " 738: 4,\n",
       " 739: 4,\n",
       " 740: 10,\n",
       " 741: 11,\n",
       " 742: 12,\n",
       " 743: 2,\n",
       " 745: 20,\n",
       " 748: 22,\n",
       " 749: 4,\n",
       " 751: 5,\n",
       " 752: 15,\n",
       " 754: 3,\n",
       " 755: 3,\n",
       " 756: 1,\n",
       " 757: 1,\n",
       " 758: 2,\n",
       " 759: 9,\n",
       " 760: 1,\n",
       " 761: 3,\n",
       " 762: 2,\n",
       " 764: 24,\n",
       " 765: 26,\n",
       " 766: 3,\n",
       " 767: 18,\n",
       " 768: 3,\n",
       " 769: 1,\n",
       " 771: 3,\n",
       " 772: 2,\n",
       " 773: 1,\n",
       " 774: 3,\n",
       " 775: 19,\n",
       " 776: 17,\n",
       " 777: 19,\n",
       " 778: 6,\n",
       " 780: 35,\n",
       " 781: 14,\n",
       " 782: 1,\n",
       " 783: 3,\n",
       " 784: 16,\n",
       " 785: 1,\n",
       " 786: 4,\n",
       " 787: 2,\n",
       " 788: 8,\n",
       " 789: 15,\n",
       " 790: 4,\n",
       " 791: 1,\n",
       " 792: 1,\n",
       " 793: 18,\n",
       " 794: 22,\n",
       " 795: 5,\n",
       " 797: 4,\n",
       " 798: 9,\n",
       " 799: 6,\n",
       " 800: 10,\n",
       " 801: 1,\n",
       " 802: 12,\n",
       " 803: 1,\n",
       " 804: 20,\n",
       " 805: 1,\n",
       " 806: 1,\n",
       " 808: 3,\n",
       " 809: 1,\n",
       " 810: 31,\n",
       " 812: 6,\n",
       " 813: 1,\n",
       " 815: 17,\n",
       " 816: 1,\n",
       " 818: 11,\n",
       " 819: 4,\n",
       " 820: 1,\n",
       " 821: 1,\n",
       " 822: 6,\n",
       " 823: 1,\n",
       " 824: 3,\n",
       " 825: 3,\n",
       " 826: 15,\n",
       " 827: 2,\n",
       " 828: 7,\n",
       " 829: 1,\n",
       " 830: 1,\n",
       " 831: 1,\n",
       " 832: 1,\n",
       " 833: 5,\n",
       " 834: 9,\n",
       " 835: 14,\n",
       " 836: 28,\n",
       " 837: 16,\n",
       " 838: 4,\n",
       " 839: 14,\n",
       " 840: 1,\n",
       " 842: 1,\n",
       " 843: 4,\n",
       " 844: 4,\n",
       " 845: 3,\n",
       " 846: 7,\n",
       " 847: 1,\n",
       " 848: 6,\n",
       " 849: 1,\n",
       " 850: 32,\n",
       " 852: 18,\n",
       " 853: 2,\n",
       " 854: 1,\n",
       " 855: 4,\n",
       " 856: 5,\n",
       " 857: 3,\n",
       " 858: 7,\n",
       " 859: 10,\n",
       " 860: 22,\n",
       " 861: 44,\n",
       " 862: 15,\n",
       " 863: 19,\n",
       " 864: 1,\n",
       " 865: 2,\n",
       " 866: 7,\n",
       " 867: 1,\n",
       " 868: 1,\n",
       " 869: 57,\n",
       " 871: 1,\n",
       " 872: 3,\n",
       " 873: 2,\n",
       " 874: 5,\n",
       " 875: 18,\n",
       " 876: 1,\n",
       " 877: 19,\n",
       " 878: 1,\n",
       " 879: 45,\n",
       " 880: 9,\n",
       " 881: 3,\n",
       " 882: 4,\n",
       " 883: 8,\n",
       " 884: 4,\n",
       " 885: 1,\n",
       " 886: 28,\n",
       " 887: 11,\n",
       " 888: 1,\n",
       " 889: 4,\n",
       " 890: 8,\n",
       " 891: 1,\n",
       " 892: 8,\n",
       " 893: 2,\n",
       " 894: 19,\n",
       " 895: 18,\n",
       " 896: 18,\n",
       " 897: 1,\n",
       " 898: 9,\n",
       " 899: 2,\n",
       " 900: 28,\n",
       " 901: 35,\n",
       " 902: 1,\n",
       " 903: 2,\n",
       " 904: 1,\n",
       " 905: 10,\n",
       " 906: 6,\n",
       " 907: 1,\n",
       " 908: 1,\n",
       " 909: 1,\n",
       " 910: 1,\n",
       " 911: 3,\n",
       " 913: 1,\n",
       " 914: 1,\n",
       " 915: 1,\n",
       " 916: 10,\n",
       " 917: 18,\n",
       " 918: 1,\n",
       " 919: 1,\n",
       " 920: 2,\n",
       " 921: 14,\n",
       " 923: 16,\n",
       " 924: 1,\n",
       " 925: 3,\n",
       " 926: 2,\n",
       " 927: 3,\n",
       " 928: 3,\n",
       " 929: 1,\n",
       " 930: 1,\n",
       " 931: 20,\n",
       " 932: 6,\n",
       " 933: 1,\n",
       " 934: 1,\n",
       " 935: 15,\n",
       " 936: 25,\n",
       " 937: 51,\n",
       " 938: 1,\n",
       " 939: 13,\n",
       " 940: 12,\n",
       " 943: 1,\n",
       " 944: 1,\n",
       " 945: 3,\n",
       " 946: 4,\n",
       " 947: 5,\n",
       " 948: 1,\n",
       " 949: 3,\n",
       " 950: 5,\n",
       " 951: 16,\n",
       " 952: 1,\n",
       " 953: 3,\n",
       " 954: 1,\n",
       " 955: 1,\n",
       " 956: 1,\n",
       " 957: 8,\n",
       " 958: 1,\n",
       " 959: 1,\n",
       " 960: 1,\n",
       " 961: 4,\n",
       " 962: 7,\n",
       " 963: 3,\n",
       " 965: 1,\n",
       " 966: 15,\n",
       " 967: 5,\n",
       " 968: 28,\n",
       " 969: 4,\n",
       " 970: 12,\n",
       " 972: 8,\n",
       " 973: 4,\n",
       " 974: 5,\n",
       " 975: 4,\n",
       " 976: 1,\n",
       " 977: 8,\n",
       " 978: 7,\n",
       " 980: 11,\n",
       " 981: 3,\n",
       " 982: 5,\n",
       " 983: 5,\n",
       " 984: 7,\n",
       " 986: 4,\n",
       " 988: 11,\n",
       " 989: 1,\n",
       " 990: 7,\n",
       " 991: 1,\n",
       " 992: 1,\n",
       " 993: 3,\n",
       " 994: 6,\n",
       " 996: 1,\n",
       " 998: 26,\n",
       " 999: 2,\n",
       " 1000: 7,\n",
       " 1001: 1,\n",
       " 1002: 1,\n",
       " 1003: 7,\n",
       " 1004: 21,\n",
       " 1005: 3,\n",
       " 1006: 1,\n",
       " 1007: 1,\n",
       " 1008: 12,\n",
       " 1009: 1,\n",
       " 1010: 1,\n",
       " 1011: 5,\n",
       " 1012: 3,\n",
       " 1013: 1,\n",
       " 1014: 1,\n",
       " 1015: 6,\n",
       " 1016: 52,\n",
       " 1017: 6,\n",
       " 1018: 1,\n",
       " 1019: 1,\n",
       " 1020: 3,\n",
       " 1021: 4,\n",
       " 1022: 2,\n",
       " 1023: 2,\n",
       " 1024: 1,\n",
       " 1025: 7,\n",
       " 1026: 3,\n",
       " 1027: 2,\n",
       " 1028: 41,\n",
       " 1029: 2,\n",
       " 1030: 1,\n",
       " 1031: 1,\n",
       " 1032: 6,\n",
       " 1033: 1,\n",
       " 1034: 1,\n",
       " 1035: 12,\n",
       " 1036: 2,\n",
       " 1038: 2,\n",
       " 1039: 4,\n",
       " 1040: 2,\n",
       " 1041: 1,\n",
       " 1042: 9,\n",
       " 1043: 44,\n",
       " 1044: 5,\n",
       " 1045: 10,\n",
       " 1046: 4,\n",
       " 1047: 1,\n",
       " 1048: 1,\n",
       " 1049: 3,\n",
       " 1050: 2,\n",
       " 1051: 1,\n",
       " 1052: 5,\n",
       " 1053: 4,\n",
       " 1054: 4,\n",
       " 1055: 3,\n",
       " 1057: 2,\n",
       " 1058: 6,\n",
       " 1059: 3,\n",
       " 1060: 1,\n",
       " 1061: 3,\n",
       " 1062: 5,\n",
       " 1063: 1,\n",
       " 1064: 2,\n",
       " 1065: 1,\n",
       " 1066: 2,\n",
       " 1067: 17,\n",
       " 1068: 16,\n",
       " 1069: 1,\n",
       " 1070: 26,\n",
       " 1071: 2,\n",
       " 1072: 7,\n",
       " 1073: 15,\n",
       " 1074: 1,\n",
       " 1075: 4,\n",
       " 1076: 1,\n",
       " 1077: 4,\n",
       " 1078: 6,\n",
       " 1079: 1,\n",
       " 1080: 6,\n",
       " 1081: 1,\n",
       " 1082: 1,\n",
       " 1083: 1,\n",
       " 1084: 2,\n",
       " 1085: 5,\n",
       " 1086: 6,\n",
       " 1087: 1,\n",
       " 1088: 3,\n",
       " 1089: 1,\n",
       " 1090: 3,\n",
       " 1092: 3,\n",
       " 1093: 1,\n",
       " 1094: 1,\n",
       " 1095: 1,\n",
       " 1096: 2,\n",
       " 1097: 20,\n",
       " 1098: 1,\n",
       " 1099: 5,\n",
       " 1100: 1,\n",
       " 1101: 6,\n",
       " 1103: 35,\n",
       " 1104: 21,\n",
       " 1105: 1,\n",
       " 1106: 3,\n",
       " 1107: 4,\n",
       " 1108: 4,\n",
       " 1109: 10,\n",
       " 1110: 3,\n",
       " 1111: 1,\n",
       " 1112: 12,\n",
       " 1113: 9,\n",
       " 1114: 4,\n",
       " 1115: 4,\n",
       " 1116: 2,\n",
       " 1117: 5,\n",
       " 1118: 2,\n",
       " 1119: 2,\n",
       " 1120: 4,\n",
       " 1121: 1,\n",
       " 1122: 31,\n",
       " 1123: 1,\n",
       " 1124: 1,\n",
       " 1125: 1,\n",
       " 1127: 15,\n",
       " 1128: 8,\n",
       " 1129: 1,\n",
       " 1130: 19,\n",
       " 1132: 26,\n",
       " 1133: 2,\n",
       " 1134: 2,\n",
       " 1135: 1,\n",
       " 1136: 1,\n",
       " 1137: 1,\n",
       " 1138: 1,\n",
       " 1139: 1,\n",
       " 1140: 3,\n",
       " 1141: 1,\n",
       " 1142: 2,\n",
       " 1143: 5,\n",
       " 1144: 7,\n",
       " 1145: 7,\n",
       " 1146: 4,\n",
       " 1147: 12,\n",
       " 1148: 4,\n",
       " 1149: 36,\n",
       " 1150: 11,\n",
       " 1151: 2,\n",
       " 1152: 1,\n",
       " 1153: 3,\n",
       " 1154: 15,\n",
       " 1155: 4,\n",
       " 1157: 11,\n",
       " 1158: 3,\n",
       " 1159: 1,\n",
       " 1160: 1,\n",
       " 1161: 1,\n",
       " 1162: 1,\n",
       " 1163: 7,\n",
       " 1164: 30,\n",
       " 1165: 10,\n",
       " 1166: 1,\n",
       " 1167: 1,\n",
       " 1168: 4,\n",
       " 1169: 1,\n",
       " 1170: 3,\n",
       " 1171: 8,\n",
       " 1172: 15,\n",
       " 1173: 2,\n",
       " 1174: 1,\n",
       " 1175: 4,\n",
       " 1176: 2,\n",
       " 1177: 2,\n",
       " 1178: 13,\n",
       " 1179: 5,\n",
       " 1180: 3,\n",
       " 1181: 1,\n",
       " 1182: 14,\n",
       " 1183: 1,\n",
       " 1184: 4,\n",
       " 1185: 3,\n",
       " 1187: 2,\n",
       " 1188: 5,\n",
       " 1189: 2,\n",
       " 1190: 3,\n",
       " 1191: 1,\n",
       " 1192: 4,\n",
       " 1193: 1,\n",
       " 1194: 3,\n",
       " 1195: 4,\n",
       " ...}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_docs_with_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.88682929, 0.43643086, 6.05987058, ..., 9.2787464 , 9.2787464 ,\n",
       "       9.2787464 ])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_tf_idf_for_sample(sample: list[int]):\n",
    "    N = len(sample)\n",
    "    tf = defaultdict(int)\n",
    "    for token in sample:\n",
    "        tf[token] += 1\n",
    "    for token in tf:\n",
    "        tf[token] = tf[token] / N\n",
    "    \n",
    "    tf_idf = np.zeros(len(vocab)) # vocab from only training set\n",
    "    for token in tf:\n",
    "        if token < len(idf)-1:\n",
    "            tf_idf[token] = tf[token] * idf[token]\n",
    "    \n",
    "    return tf_idf\n",
    "\n",
    "def gen_tf_idf(X: np.ndarray):\n",
    "    new_X = np.zeros((X.shape[0], len(vocab)))\n",
    "    for i, sample in enumerate(X):\n",
    "        new_X[i] = gen_tf_idf_for_sample(sample)\n",
    "    \n",
    "    return new_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10708,) (1339,) (10708,) (1339,) 4728\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape, len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = gen_tf_idf(X_train)\n",
    "X_test = gen_tf_idf(X_test)\n",
    "y_train = y_train.copy().astype(int)\n",
    "y_test = y_test.copy().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10708, 4728) (1339, 4728) (10708,) (1339,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, random_state=2025)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, random_state=2025)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(class_weight='balanced', random_state=2025)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 100 max epochs took 2m 1s\n",
    "# 100 max epochs with ignoring stop words took 2m 20s\n",
    "logmodel = LogisticRegression(class_weight='balanced', max_iter=100, random_state=2025)\n",
    "logmodel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 0.47194814682006836\n"
     ]
    }
   ],
   "source": [
    "# 0.472s\n",
    "start_time = time.time()\n",
    "predictions = logmodel.predict(X_test)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Total time: {end_time - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 0.7300021648406982\n"
     ]
    }
   ],
   "source": [
    "# ignoring stop words 0.730s\n",
    "start_time = time.time()\n",
    "predictions = logmodel.predict(X_test)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Total time: {end_time - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Acc. on test data 65.272591%\n"
     ]
    }
   ],
   "source": [
    "# 100 max epochs: acc 65.273% \n",
    "print(\"Model Acc. on test data %f%%\"\n",
    "       % ((y_test == predictions).sum() / y_test.shape[0] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Acc. on test data 60.119492%\n"
     ]
    }
   ],
   "source": [
    "# 100 max epochs with ignoring stop words: acc 60.119%\n",
    "print(\"Model Acc. on test data %f%%\"\n",
    "       % ((y_test == predictions).sum() / y_test.shape[0] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.572289156626506,\n",
       "  'recall': 0.7421875,\n",
       "  'f1-score': 0.6462585034013606,\n",
       "  'support': 128.0},\n",
       " '1': {'precision': 0.7096774193548387,\n",
       "  'recall': 0.55,\n",
       "  'f1-score': 0.6197183098591549,\n",
       "  'support': 360.0},\n",
       " '2': {'precision': 0.7295597484276729,\n",
       "  'recall': 0.7945205479452054,\n",
       "  'f1-score': 0.760655737704918,\n",
       "  'support': 146.0},\n",
       " '3': {'precision': 0.6873065015479877,\n",
       "  'recall': 0.6201117318435754,\n",
       "  'f1-score': 0.6519823788546255,\n",
       "  'support': 358.0},\n",
       " '4': {'precision': 0.5029239766081871,\n",
       "  'recall': 0.7413793103448276,\n",
       "  'f1-score': 0.5993031358885017,\n",
       "  'support': 116.0},\n",
       " '5': {'precision': 0.8379310344827586,\n",
       "  'recall': 0.5758293838862559,\n",
       "  'f1-score': 0.6825842696629213,\n",
       "  'support': 422.0},\n",
       " '6': {'precision': 0.359375,\n",
       "  'recall': 0.46938775510204084,\n",
       "  'f1-score': 0.40707964601769914,\n",
       "  'support': 49.0},\n",
       " '7': {'precision': 0.8857142857142857,\n",
       "  'recall': 0.7306397306397306,\n",
       "  'f1-score': 0.8007380073800738,\n",
       "  'support': 297.0},\n",
       " '8': {'precision': 0.23015873015873015,\n",
       "  'recall': 0.4393939393939394,\n",
       "  'f1-score': 0.3020833333333333,\n",
       "  'support': 66.0},\n",
       " '9': {'precision': 0.6974789915966386,\n",
       "  'recall': 0.7685185185185185,\n",
       "  'f1-score': 0.7312775330396476,\n",
       "  'support': 108.0},\n",
       " '10': {'precision': 0.7,\n",
       "  'recall': 0.8,\n",
       "  'f1-score': 0.7466666666666667,\n",
       "  'support': 35.0},\n",
       " '11': {'precision': 0.6294642857142857,\n",
       "  'recall': 0.6157205240174672,\n",
       "  'f1-score': 0.6225165562913907,\n",
       "  'support': 229.0},\n",
       " '12': {'precision': 0.4307692307692308,\n",
       "  'recall': 0.5,\n",
       "  'f1-score': 0.4628099173553719,\n",
       "  'support': 56.0},\n",
       " '13': {'precision': 0.25, 'recall': 0.75, 'f1-score': 0.375, 'support': 4.0},\n",
       " '14': {'precision': 0.6666666666666666,\n",
       "  'recall': 0.7755102040816326,\n",
       "  'f1-score': 0.7169811320754716,\n",
       "  'support': 49.0},\n",
       " '15': {'precision': 0.8181818181818182,\n",
       "  'recall': 0.72,\n",
       "  'f1-score': 0.7659574468085106,\n",
       "  'support': 50.0},\n",
       " '16': {'precision': 0.3924050632911392,\n",
       "  'recall': 0.5254237288135594,\n",
       "  'f1-score': 0.4492753623188406,\n",
       "  'support': 59.0},\n",
       " '17': {'precision': 0.8367346938775511,\n",
       "  'recall': 0.8913043478260869,\n",
       "  'f1-score': 0.8631578947368421,\n",
       "  'support': 46.0},\n",
       " '18': {'precision': 0.35,\n",
       "  'recall': 0.7,\n",
       "  'f1-score': 0.4666666666666667,\n",
       "  'support': 10.0},\n",
       " '19': {'precision': 0.7560975609756098,\n",
       "  'recall': 0.7560975609756098,\n",
       "  'f1-score': 0.7560975609756098,\n",
       "  'support': 41.0},\n",
       " '20': {'precision': 0.03333333333333333,\n",
       "  'recall': 0.1,\n",
       "  'f1-score': 0.05,\n",
       "  'support': 10.0},\n",
       " '21': {'precision': 0.41935483870967744,\n",
       "  'recall': 0.8125,\n",
       "  'f1-score': 0.5531914893617021,\n",
       "  'support': 16.0},\n",
       " '22': {'precision': 0.11764705882352941,\n",
       "  'recall': 0.2857142857142857,\n",
       "  'f1-score': 0.16666666666666666,\n",
       "  'support': 7.0},\n",
       " '23': {'precision': 0.44,\n",
       "  'recall': 0.8461538461538461,\n",
       "  'f1-score': 0.5789473684210527,\n",
       "  'support': 13.0},\n",
       " '24': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1.0},\n",
       " '25': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 2.0},\n",
       " 'accuracy': 0.6441374159820762,\n",
       " 'macro avg': {'precision': 0.5405026690330941,\n",
       "  'recall': 0.6350151121252531,\n",
       "  'f1-score': 0.5682929070571934,\n",
       "  'support': 2678.0},\n",
       " 'weighted avg': {'precision': 0.6883919072305033,\n",
       "  'recall': 0.6441374159820762,\n",
       "  'f1-score': 0.6557119304297164,\n",
       "  'support': 2678.0}}"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report = classification_report(y_test, predictions, output_dict=True, digits=2)\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

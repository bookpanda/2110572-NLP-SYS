{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from IPython.display import display\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv('clean-phone-data-for-students.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence Utterance</th>\n",
       "      <th>Action</th>\n",
       "      <th>Object</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;PHONE_NUMBER_REMOVED&gt; ผมไปจ่ายเงินที่ Counte...</td>\n",
       "      <td>enquire</td>\n",
       "      <td>payment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>internet ยังความเร็วอยุ่เท่าไหร ครับ</td>\n",
       "      <td>enquire</td>\n",
       "      <td>package</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ตะกี้ไปชำระค่าบริการไปแล้ว แต่ยังใช้งานไม่ได้...</td>\n",
       "      <td>report</td>\n",
       "      <td>suspend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>พี่ค่ะยังใช้ internet ไม่ได้เลยค่ะ เป็นเครื่อ...</td>\n",
       "      <td>enquire</td>\n",
       "      <td>internet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ฮาโหล คะ พอดีว่าเมื่อวานเปิดซิมทรูมูฟ แต่มันโ...</td>\n",
       "      <td>report</td>\n",
       "      <td>phone_issues</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Sentence Utterance   Action        Object\n",
       "0   <PHONE_NUMBER_REMOVED> ผมไปจ่ายเงินที่ Counte...  enquire       payment\n",
       "1               internet ยังความเร็วอยุ่เท่าไหร ครับ  enquire       package\n",
       "2   ตะกี้ไปชำระค่าบริการไปแล้ว แต่ยังใช้งานไม่ได้...   report       suspend\n",
       "3   พี่ค่ะยังใช้ internet ไม่ได้เลยค่ะ เป็นเครื่อ...  enquire      internet\n",
       "4   ฮาโหล คะ พอดีว่าเมื่อวานเปิดซิมทรูมูฟ แต่มันโ...   report  phone_issues"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence Utterance</th>\n",
       "      <th>Action</th>\n",
       "      <th>Object</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>16175</td>\n",
       "      <td>16175</td>\n",
       "      <td>16175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>13389</td>\n",
       "      <td>10</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>บริการอื่นๆ</td>\n",
       "      <td>enquire</td>\n",
       "      <td>service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>97</td>\n",
       "      <td>10377</td>\n",
       "      <td>2525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sentence Utterance   Action   Object\n",
       "count               16175    16175    16175\n",
       "unique              13389       10       33\n",
       "top           บริการอื่นๆ  enquire  service\n",
       "freq                   97    10377     2525"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(data_df.head())\n",
    "data_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>raw_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>16175</td>\n",
       "      <td>16175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>13389</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>บริการอื่นๆ</td>\n",
       "      <td>service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>97</td>\n",
       "      <td>2525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              input raw_label\n",
       "count         16175     16175\n",
       "unique        13389        33\n",
       "top     บริการอื่นๆ   service\n",
       "freq             97      2525"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['payment', 'package', 'suspend', 'internet', 'phone_issues',\n",
       "       'service', 'nonTrueMove', 'balance', 'detail', 'bill', 'credit',\n",
       "       'promotion', 'mobile_setting', 'iservice', 'roaming', 'truemoney',\n",
       "       'information', 'lost_stolen', 'balance_minutes', 'idd',\n",
       "       'TrueMoney', 'garbage', 'Payment', 'IDD', 'ringtone', 'Idd',\n",
       "       'rate', 'loyalty_card', 'contact', 'officer', 'Balance', 'Service',\n",
       "       'Loyalty_card'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_df = data_df[[\"Sentence Utterance\", \"Object\"]]\n",
    "data_df.columns = ['input', 'raw_label']\n",
    "display(data_df.describe())\n",
    "display(data_df.raw_label.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>clean_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>16175</td>\n",
       "      <td>16175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>13389</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>บริการอื่นๆ</td>\n",
       "      <td>service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>97</td>\n",
       "      <td>2528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              input clean_label\n",
       "count         16175       16175\n",
       "unique        13389          26\n",
       "top     บริการอื่นๆ     service\n",
       "freq             97        2528"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['payment', 'package', 'suspend', 'internet', 'phone_issues',\n",
       "       'service', 'nontruemove', 'balance', 'detail', 'bill', 'credit',\n",
       "       'promotion', 'mobile_setting', 'iservice', 'roaming', 'truemoney',\n",
       "       'information', 'lost_stolen', 'balance_minutes', 'idd', 'garbage',\n",
       "       'ringtone', 'rate', 'loyalty_card', 'contact', 'officer'],\n",
       "      dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_df['clean_label']=data_df['raw_label'].str.lower().copy()\n",
    "data_df.drop('raw_label', axis=1, inplace=True)\n",
    "display(data_df.describe())\n",
    "display(data_df.clean_label.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>clean_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13389</td>\n",
       "      <td>13389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>13389</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>&lt;PHONE_NUMBER_REMOVED&gt; ผมไปจ่ายเงินที่ Counte...</td>\n",
       "      <td>service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>2111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    input clean_label\n",
       "count                                               13389       13389\n",
       "unique                                              13389          26\n",
       "top      <PHONE_NUMBER_REMOVED> ผมไปจ่ายเงินที่ Counte...     service\n",
       "freq                                                    1        2111"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_df = data_df.drop_duplicates(\"input\", keep=\"first\")\n",
    "data_df = data_df.reset_index(drop=True)\n",
    "display(data_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1 TF-IDF\n",
    "\n",
    "Build a model to train a tf-idf text classifier. Use a simple logistic regression model for the classifier.\n",
    "\n",
    "For this part, you may find this [tutorial](https://scikit-learn.org/stable/auto_examples/text/plot_document_classification_20newsgroups.html#sphx-glr-auto-examples-text-plot-document-classification-20newsgroups-py) helpful.\n",
    "\n",
    "Below are some design choices you need to consider to accomplish this task. Be sure to answer them when you submit your model.\n",
    "\n",
    "What tokenizer will you use? Why?\n",
    "\n",
    "**Ans:**\n",
    "`attacut`, because it is fast and accurate for Thai text. Although it is not the best tokenizer for Thai text, it is good enough for this task. The code below show comparison in time between `attacut` vs `deepcut` tokenizers. `deepcut` is the \"best\" tokenizer for Thai text, but it is a lot slower than `attacut`.\n",
    "\n",
    "Will you ignore some stop words (a, an, the, to, etc. for English) in your tf-idf? Is it important?\n",
    "PythaiNLP provides a list of stopwords if you want to use (https://pythainlp.org/docs/2.0/api/corpus.html#pythainlp.corpus.common.thai_stopwords)\n",
    "\n",
    "**Ans:**\n",
    "From my experiment:\n",
    "- Accuracy on test set including stop words: 64.413742%, time used for inference: 0.15224s\n",
    "- Accuracy on test set excluding stop words: 61.165049%, time used for inference: 0.06745s\n",
    "\n",
    "The dictionary of TF-IDF is usually based on the training data. How many words in the test set are OOVs?\n",
    "\n",
    "**Ans:**\n",
    "- 751 words in the test set are OOVs (not found in the training set's vocabulary)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepcut\n",
    "import attacut\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import pythainlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Total time: 17.082552909851074\n"
     ]
    }
   ],
   "source": [
    "# 19 secs for 100 samples\n",
    "# 13389 samples = 42 mins; ain't nobody got time for that\n",
    "start_time = time.time()\n",
    "for i in range(100):\n",
    "    # print(f\"original: {data_df['input'][i]}\")\n",
    "    # print(deepcut.tokenize(data_df['input'][i]))\n",
    "    deepcut.tokenize(data_df['input'][i])\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Total time: {end_time - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages/attacut/models/__init__.py:60: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=\"cpu\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 3.103543996810913\n"
     ]
    }
   ],
   "source": [
    "# 2.25 secs for 100 samples\n",
    "# 13389 samples = 5 mins; now we're talking\n",
    "start_time = time.time()\n",
    "for i in range(100):\n",
    "    attacut.tokenize(data_df['input'][0])\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Total time: {end_time - start_time}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create Mappings\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 'payment',\n",
       " 1: 'package',\n",
       " 2: 'suspend',\n",
       " 3: 'internet',\n",
       " 4: 'phone_issues',\n",
       " 5: 'service',\n",
       " 6: 'nontruemove',\n",
       " 7: 'balance',\n",
       " 8: 'detail',\n",
       " 9: 'bill',\n",
       " 10: 'credit',\n",
       " 11: 'promotion',\n",
       " 12: 'mobile_setting',\n",
       " 13: 'iservice',\n",
       " 14: 'roaming',\n",
       " 15: 'truemoney',\n",
       " 16: 'information',\n",
       " 17: 'lost_stolen',\n",
       " 18: 'balance_minutes',\n",
       " 19: 'idd',\n",
       " 20: 'garbage',\n",
       " 21: 'ringtone',\n",
       " 22: 'rate',\n",
       " 23: 'loyalty_card',\n",
       " 24: 'contact',\n",
       " 25: 'officer'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'payment': 0,\n",
       " 'package': 1,\n",
       " 'suspend': 2,\n",
       " 'internet': 3,\n",
       " 'phone_issues': 4,\n",
       " 'service': 5,\n",
       " 'nontruemove': 6,\n",
       " 'balance': 7,\n",
       " 'detail': 8,\n",
       " 'bill': 9,\n",
       " 'credit': 10,\n",
       " 'promotion': 11,\n",
       " 'mobile_setting': 12,\n",
       " 'iservice': 13,\n",
       " 'roaming': 14,\n",
       " 'truemoney': 15,\n",
       " 'information': 16,\n",
       " 'lost_stolen': 17,\n",
       " 'balance_minutes': 18,\n",
       " 'idd': 19,\n",
       " 'garbage': 20,\n",
       " 'ringtone': 21,\n",
       " 'rate': 22,\n",
       " 'loyalty_card': 23,\n",
       " 'contact': 24,\n",
       " 'officer': 25}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = data_df.copy().to_numpy()\n",
    "\n",
    "unique_label = data_df.clean_label.unique()\n",
    "\n",
    "label_2_num_map = dict(zip(unique_label, range(len(unique_label))))\n",
    "num_2_label_map = dict(zip(range(len(unique_label)), unique_label))\n",
    "\n",
    "print(\"Create Mappings\")\n",
    "display(num_2_label_map)\n",
    "display(label_2_num_map)\n",
    "\n",
    "# print(\"Before Mappings\")\n",
    "# display(data[:, 1])\n",
    "data[:,1] = np.vectorize(label_2_num_map.get)(data[:,1])\n",
    "# print(\"After Mappings\")\n",
    "# display(data[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_str(string):\n",
    "    return string.strip()\n",
    "     \n",
    "# print(\"Before\")\n",
    "# print(data)\n",
    "data[:,0] = np.vectorize(strip_str)(data[:,0])\n",
    "# print(\"After\")\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['<PHONE_NUMBER_REMOVED> ผมไปจ่ายเงินที่ Counter Services เค้าเช็ต 3276.25 บาท เมื่อวานที่ผมเช็คที่ศูนย์บอกมียอด 3057.79 บาท',\n",
       "        0],\n",
       "       ['internet ยังความเร็วอยุ่เท่าไหร ครับ', 1],\n",
       "       ['ตะกี้ไปชำระค่าบริการไปแล้ว แต่ยังใช้งานไม่ได้ ค่ะ', 2],\n",
       "       ...,\n",
       "       ['ยอดเงินเหลือเท่าไหร่ค่ะ', 7],\n",
       "       ['ยอดเงินในระบบ', 7],\n",
       "       ['สอบถามโปรโมชั่นปัจจุบันที่ใช้อยู่ค่ะ', 1]], dtype=object)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13389,) (13389,)\n"
     ]
    }
   ],
   "source": [
    "x = data[:, 0]\n",
    "y = data[:, 1]\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10711,) (2678,) (10711,) (2678,)\n"
     ]
    }
   ],
   "source": [
    "train_X: np.ndarray\n",
    "test_X: np.ndarray\n",
    "train_y: np.ndarray\n",
    "test_y: np.ndarray\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(x, y, stratify=y, test_size=0.2,random_state=42)\n",
    "print(train_X.shape, test_X.shape, train_y.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10711 [00:00<?, ?it/s]/Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages/attacut/models/__init__.py:60: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=\"cpu\"))\n",
      "100%|██████████| 10711/10711 [03:31<00:00, 50.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vocab = defaultdict(lambda: len(vocab))\n",
    "vocab[\"<UNK>\"] = 0\n",
    "for i in tqdm(range(len(train_X))):\n",
    "    tokens = attacut.tokenize(train_X[i])\n",
    "    for token in tokens:\n",
    "        vocab[token]\n",
    "    \n",
    "# 4728 unique tokens in training set (+ 1 from UNK)\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13389/13389 [04:25<00:00, 50.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vocab_ = defaultdict(lambda: len(vocab_))\n",
    "for i in tqdm(range(len(data))):\n",
    "    tokens = attacut.tokenize(data[i][0])\n",
    "    for token in tokens:\n",
    "        vocab_[token]\n",
    "# 5447 unique tokens in entire dataset\n",
    "print(len(vocab_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2678 [00:00<?, ?it/s]/Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages/attacut/models/__init__.py:60: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=\"cpu\"))\n",
      "100%|██████████| 2678/2678 [00:50<00:00, 53.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "oov_count = 0\n",
    "for i in tqdm(range(len(test_X))):\n",
    "    tokens = attacut.tokenize(test_X[i])\n",
    "    for token in tokens:\n",
    "        if token not in vocab:\n",
    "            oov_count += 1\n",
    "\n",
    "# 751 unique tokens in test set but not in training set (OOV)\n",
    "print(oov_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythainlp.corpus.common import thai_stopwords\n",
    "\n",
    "stopwords = thai_stopwords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_token_ids(X: np.ndarray):\n",
    "    new_X = np.zeros(X.shape, dtype=object)\n",
    "    for i in tqdm(range(len(X))):\n",
    "        token_ids = []\n",
    "        tokens = attacut.tokenize(X[i])\n",
    "        # should we remove any tokens?\n",
    "        # this line later added to test if removing stopwords is necessary\n",
    "        tokens = [token for token in tokens if token not in stopwords]\n",
    "\n",
    "        for token in tokens:\n",
    "            if token in vocab:\n",
    "                token_ids.append(vocab[token])\n",
    "            else:\n",
    "                token_ids.append(vocab[\"<UNK>\"])\n",
    "        \n",
    "        new_X[i] = token_ids\n",
    "    \n",
    "    return new_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "สอบถามทรูมันนี่มันยังใช่ไม่ได้ครับ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10711 [00:00<?, ?it/s]/Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages/attacut/models/__init__.py:60: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=\"cpu\"))\n",
      "100%|██████████| 10711/10711 [02:57<00:00, 60.44it/s]\n",
      "100%|██████████| 2678/2678 [00:43<00:00, 61.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(train_X[0])\n",
    "train_X = string_to_token_ids(train_X)\n",
    "test_X = string_to_token_ids(test_X)\n",
    "print(train_X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10711/10711 [00:00<00:00, 215361.12it/s]\n"
     ]
    }
   ],
   "source": [
    "num_docs_with_w = defaultdict(int)\n",
    "for i in tqdm(range(len(train_X))):\n",
    "    unique_tokens = set(train_X[i])\n",
    "    \n",
    "    for token in unique_tokens:\n",
    "        num_docs_with_w[token] += 1\n",
    "# sort token idx\n",
    "num_docs_with_w = dict(sorted(num_docs_with_w.items(), key=lambda x: x[0]))\n",
    "\n",
    "idf = np.log(len(train_X) / np.array(list(num_docs_with_w.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4457"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 2529,\n",
       " 2: 120,\n",
       " 10: 797,\n",
       " 12: 826,\n",
       " 14: 67,\n",
       " 15: 316,\n",
       " 16: 790,\n",
       " 18: 1281,\n",
       " 19: 4,\n",
       " 21: 61,\n",
       " 23: 6925,\n",
       " 25: 1318,\n",
       " 27: 7,\n",
       " 29: 10,\n",
       " 30: 368,\n",
       " 31: 238,\n",
       " 33: 438,\n",
       " 34: 1116,\n",
       " 37: 245,\n",
       " 39: 830,\n",
       " 41: 839,\n",
       " 45: 1576,\n",
       " 46: 533,\n",
       " 49: 3,\n",
       " 59: 432,\n",
       " 60: 4,\n",
       " 61: 8,\n",
       " 68: 657,\n",
       " 69: 2,\n",
       " 70: 732,\n",
       " 71: 723,\n",
       " 72: 233,\n",
       " 73: 255,\n",
       " 74: 1012,\n",
       " 76: 26,\n",
       " 78: 14,\n",
       " 79: 344,\n",
       " 80: 272,\n",
       " 82: 10,\n",
       " 84: 88,\n",
       " 85: 1311,\n",
       " 87: 79,\n",
       " 88: 79,\n",
       " 90: 377,\n",
       " 92: 244,\n",
       " 93: 8,\n",
       " 94: 33,\n",
       " 95: 37,\n",
       " 101: 598,\n",
       " 102: 77,\n",
       " 105: 132,\n",
       " 106: 178,\n",
       " 107: 442,\n",
       " 108: 139,\n",
       " 111: 23,\n",
       " 112: 32,\n",
       " 113: 724,\n",
       " 114: 277,\n",
       " 115: 389,\n",
       " 116: 718,\n",
       " 117: 548,\n",
       " 118: 110,\n",
       " 119: 40,\n",
       " 120: 736,\n",
       " 121: 45,\n",
       " 122: 147,\n",
       " 123: 370,\n",
       " 124: 395,\n",
       " 126: 80,\n",
       " 127: 21,\n",
       " 128: 23,\n",
       " 130: 1,\n",
       " 131: 37,\n",
       " 132: 7,\n",
       " 133: 5,\n",
       " 134: 36,\n",
       " 135: 1,\n",
       " 137: 565,\n",
       " 138: 1060,\n",
       " 140: 532,\n",
       " 142: 121,\n",
       " 143: 1,\n",
       " 144: 8,\n",
       " 145: 103,\n",
       " 147: 92,\n",
       " 151: 11,\n",
       " 153: 26,\n",
       " 154: 55,\n",
       " 155: 155,\n",
       " 156: 1,\n",
       " 157: 4,\n",
       " 159: 10,\n",
       " 160: 840,\n",
       " 161: 44,\n",
       " 163: 321,\n",
       " 165: 44,\n",
       " 166: 1,\n",
       " 167: 206,\n",
       " 168: 119,\n",
       " 169: 83,\n",
       " 172: 151,\n",
       " 173: 184,\n",
       " 175: 4,\n",
       " 177: 34,\n",
       " 178: 667,\n",
       " 179: 86,\n",
       " 181: 1,\n",
       " 182: 363,\n",
       " 183: 391,\n",
       " 184: 91,\n",
       " 187: 150,\n",
       " 190: 1,\n",
       " 192: 233,\n",
       " 194: 103,\n",
       " 195: 15,\n",
       " 198: 183,\n",
       " 199: 16,\n",
       " 201: 116,\n",
       " 204: 302,\n",
       " 205: 1,\n",
       " 206: 11,\n",
       " 212: 15,\n",
       " 214: 32,\n",
       " 215: 11,\n",
       " 216: 2,\n",
       " 217: 25,\n",
       " 218: 1,\n",
       " 220: 94,\n",
       " 221: 19,\n",
       " 222: 4,\n",
       " 223: 12,\n",
       " 224: 338,\n",
       " 226: 327,\n",
       " 227: 100,\n",
       " 229: 48,\n",
       " 230: 114,\n",
       " 231: 1,\n",
       " 233: 18,\n",
       " 234: 3,\n",
       " 235: 183,\n",
       " 237: 60,\n",
       " 238: 150,\n",
       " 240: 24,\n",
       " 241: 18,\n",
       " 242: 86,\n",
       " 244: 2,\n",
       " 247: 6,\n",
       " 248: 7,\n",
       " 249: 13,\n",
       " 253: 39,\n",
       " 254: 20,\n",
       " 256: 2,\n",
       " 257: 125,\n",
       " 258: 1,\n",
       " 259: 1,\n",
       " 261: 28,\n",
       " 262: 16,\n",
       " 263: 63,\n",
       " 264: 1,\n",
       " 265: 2,\n",
       " 266: 69,\n",
       " 267: 79,\n",
       " 269: 2,\n",
       " 270: 168,\n",
       " 272: 29,\n",
       " 273: 27,\n",
       " 274: 367,\n",
       " 275: 15,\n",
       " 276: 22,\n",
       " 277: 8,\n",
       " 278: 9,\n",
       " 279: 54,\n",
       " 280: 70,\n",
       " 281: 1,\n",
       " 283: 320,\n",
       " 284: 1,\n",
       " 285: 2,\n",
       " 286: 21,\n",
       " 287: 1,\n",
       " 288: 7,\n",
       " 289: 14,\n",
       " 292: 1,\n",
       " 293: 1,\n",
       " 294: 424,\n",
       " 295: 15,\n",
       " 296: 14,\n",
       " 297: 5,\n",
       " 298: 1,\n",
       " 299: 102,\n",
       " 301: 1,\n",
       " 302: 1,\n",
       " 303: 44,\n",
       " 304: 25,\n",
       " 305: 52,\n",
       " 307: 266,\n",
       " 308: 17,\n",
       " 309: 408,\n",
       " 310: 1,\n",
       " 312: 12,\n",
       " 313: 12,\n",
       " 314: 206,\n",
       " 315: 113,\n",
       " 316: 227,\n",
       " 318: 22,\n",
       " 319: 22,\n",
       " 320: 41,\n",
       " 321: 17,\n",
       " 322: 14,\n",
       " 323: 14,\n",
       " 324: 11,\n",
       " 326: 95,\n",
       " 327: 54,\n",
       " 329: 41,\n",
       " 330: 27,\n",
       " 331: 5,\n",
       " 332: 57,\n",
       " 333: 1,\n",
       " 334: 15,\n",
       " 335: 83,\n",
       " 336: 3,\n",
       " 337: 26,\n",
       " 338: 23,\n",
       " 339: 8,\n",
       " 340: 3,\n",
       " 341: 51,\n",
       " 343: 3,\n",
       " 344: 80,\n",
       " 345: 169,\n",
       " 346: 37,\n",
       " 347: 106,\n",
       " 348: 1,\n",
       " 349: 65,\n",
       " 350: 2,\n",
       " 351: 4,\n",
       " 352: 63,\n",
       " 353: 15,\n",
       " 354: 100,\n",
       " 355: 269,\n",
       " 356: 37,\n",
       " 357: 3,\n",
       " 358: 3,\n",
       " 359: 1,\n",
       " 360: 9,\n",
       " 361: 35,\n",
       " 362: 12,\n",
       " 363: 1,\n",
       " 364: 8,\n",
       " 365: 7,\n",
       " 366: 1,\n",
       " 367: 1,\n",
       " 368: 2,\n",
       " 371: 3,\n",
       " 372: 9,\n",
       " 373: 29,\n",
       " 374: 1,\n",
       " 375: 4,\n",
       " 376: 154,\n",
       " 377: 5,\n",
       " 378: 2,\n",
       " 379: 1,\n",
       " 380: 68,\n",
       " 381: 18,\n",
       " 382: 1,\n",
       " 383: 1,\n",
       " 384: 184,\n",
       " 385: 206,\n",
       " 386: 15,\n",
       " 389: 2,\n",
       " 391: 44,\n",
       " 392: 1,\n",
       " 393: 87,\n",
       " 395: 1,\n",
       " 396: 1,\n",
       " 397: 1,\n",
       " 398: 27,\n",
       " 399: 9,\n",
       " 400: 1,\n",
       " 401: 167,\n",
       " 402: 94,\n",
       " 406: 31,\n",
       " 407: 110,\n",
       " 408: 4,\n",
       " 409: 4,\n",
       " 410: 33,\n",
       " 411: 2,\n",
       " 412: 28,\n",
       " 413: 15,\n",
       " 414: 25,\n",
       " 415: 6,\n",
       " 416: 6,\n",
       " 417: 16,\n",
       " 418: 1,\n",
       " 419: 52,\n",
       " 420: 5,\n",
       " 423: 11,\n",
       " 424: 3,\n",
       " 425: 129,\n",
       " 426: 6,\n",
       " 427: 10,\n",
       " 428: 6,\n",
       " 429: 4,\n",
       " 431: 100,\n",
       " 432: 6,\n",
       " 433: 335,\n",
       " 434: 312,\n",
       " 435: 330,\n",
       " 437: 57,\n",
       " 438: 8,\n",
       " 439: 15,\n",
       " 440: 2,\n",
       " 441: 2,\n",
       " 444: 3,\n",
       " 445: 1,\n",
       " 446: 27,\n",
       " 448: 24,\n",
       " 449: 16,\n",
       " 450: 1,\n",
       " 452: 4,\n",
       " 453: 4,\n",
       " 456: 142,\n",
       " 457: 2,\n",
       " 458: 4,\n",
       " 459: 113,\n",
       " 460: 36,\n",
       " 462: 5,\n",
       " 463: 8,\n",
       " 464: 75,\n",
       " 465: 22,\n",
       " 466: 4,\n",
       " 467: 25,\n",
       " 468: 1,\n",
       " 469: 32,\n",
       " 470: 3,\n",
       " 471: 21,\n",
       " 472: 41,\n",
       " 473: 4,\n",
       " 474: 1,\n",
       " 475: 1,\n",
       " 476: 77,\n",
       " 477: 30,\n",
       " 478: 23,\n",
       " 479: 35,\n",
       " 480: 16,\n",
       " 481: 13,\n",
       " 482: 9,\n",
       " 483: 1,\n",
       " 484: 10,\n",
       " 485: 6,\n",
       " 486: 31,\n",
       " 488: 11,\n",
       " 490: 53,\n",
       " 491: 16,\n",
       " 492: 1,\n",
       " 493: 1,\n",
       " 494: 4,\n",
       " 495: 4,\n",
       " 496: 15,\n",
       " 497: 13,\n",
       " 498: 4,\n",
       " 499: 15,\n",
       " 500: 1,\n",
       " 501: 1,\n",
       " 502: 5,\n",
       " 503: 38,\n",
       " 504: 1,\n",
       " 505: 15,\n",
       " 507: 1,\n",
       " 508: 1,\n",
       " 509: 28,\n",
       " 510: 55,\n",
       " 511: 1,\n",
       " 512: 1,\n",
       " 513: 4,\n",
       " 514: 65,\n",
       " 515: 31,\n",
       " 516: 11,\n",
       " 519: 7,\n",
       " 520: 53,\n",
       " 521: 29,\n",
       " 522: 16,\n",
       " 523: 5,\n",
       " 524: 33,\n",
       " 525: 30,\n",
       " 526: 5,\n",
       " 527: 172,\n",
       " 528: 25,\n",
       " 529: 13,\n",
       " 530: 101,\n",
       " 531: 4,\n",
       " 532: 100,\n",
       " 534: 10,\n",
       " 536: 1,\n",
       " 538: 1,\n",
       " 539: 5,\n",
       " 540: 1,\n",
       " 542: 6,\n",
       " 543: 3,\n",
       " 544: 1,\n",
       " 545: 1,\n",
       " 546: 3,\n",
       " 547: 2,\n",
       " 548: 3,\n",
       " 550: 5,\n",
       " 552: 2,\n",
       " 553: 34,\n",
       " 554: 17,\n",
       " 556: 9,\n",
       " 557: 6,\n",
       " 558: 3,\n",
       " 559: 2,\n",
       " 560: 35,\n",
       " 561: 136,\n",
       " 562: 2,\n",
       " 563: 1,\n",
       " 564: 1,\n",
       " 565: 15,\n",
       " 566: 18,\n",
       " 567: 1,\n",
       " 568: 4,\n",
       " 569: 52,\n",
       " 570: 25,\n",
       " 571: 1,\n",
       " 572: 3,\n",
       " 573: 45,\n",
       " 574: 26,\n",
       " 575: 18,\n",
       " 577: 156,\n",
       " 578: 128,\n",
       " 579: 6,\n",
       " 581: 38,\n",
       " 582: 1,\n",
       " 583: 1,\n",
       " 584: 1,\n",
       " 586: 1,\n",
       " 587: 4,\n",
       " 588: 15,\n",
       " 589: 2,\n",
       " 591: 17,\n",
       " 592: 16,\n",
       " 594: 52,\n",
       " 595: 6,\n",
       " 596: 1,\n",
       " 597: 8,\n",
       " 599: 1,\n",
       " 601: 4,\n",
       " 602: 21,\n",
       " 603: 7,\n",
       " 604: 1,\n",
       " 605: 19,\n",
       " 606: 28,\n",
       " 607: 26,\n",
       " 608: 3,\n",
       " 610: 3,\n",
       " 611: 17,\n",
       " 612: 3,\n",
       " 613: 1,\n",
       " 614: 8,\n",
       " 615: 11,\n",
       " 617: 20,\n",
       " 618: 12,\n",
       " 619: 3,\n",
       " 620: 1,\n",
       " 621: 4,\n",
       " 623: 4,\n",
       " 624: 65,\n",
       " 626: 1,\n",
       " 627: 13,\n",
       " 628: 1,\n",
       " 629: 13,\n",
       " 630: 17,\n",
       " 632: 2,\n",
       " 633: 5,\n",
       " 635: 1,\n",
       " 636: 1,\n",
       " 637: 45,\n",
       " 638: 1,\n",
       " 639: 39,\n",
       " 640: 1,\n",
       " 641: 1,\n",
       " 642: 7,\n",
       " 643: 40,\n",
       " 644: 2,\n",
       " 645: 3,\n",
       " 646: 18,\n",
       " 647: 6,\n",
       " 649: 17,\n",
       " 650: 1,\n",
       " 652: 1,\n",
       " 653: 1,\n",
       " 654: 7,\n",
       " 655: 4,\n",
       " 656: 34,\n",
       " 657: 15,\n",
       " 658: 15,\n",
       " 659: 40,\n",
       " 660: 39,\n",
       " 662: 3,\n",
       " 664: 3,\n",
       " 665: 58,\n",
       " 666: 8,\n",
       " 667: 1,\n",
       " 668: 4,\n",
       " 670: 16,\n",
       " 671: 11,\n",
       " 672: 52,\n",
       " 673: 23,\n",
       " 675: 1,\n",
       " 676: 3,\n",
       " 677: 43,\n",
       " 678: 2,\n",
       " 679: 10,\n",
       " 680: 4,\n",
       " 681: 9,\n",
       " 682: 1,\n",
       " 683: 1,\n",
       " 684: 1,\n",
       " 685: 22,\n",
       " 686: 2,\n",
       " 687: 1,\n",
       " 688: 6,\n",
       " 689: 14,\n",
       " 690: 1,\n",
       " 691: 9,\n",
       " 692: 1,\n",
       " 693: 2,\n",
       " 694: 4,\n",
       " 695: 2,\n",
       " 696: 18,\n",
       " 697: 1,\n",
       " 698: 2,\n",
       " 699: 10,\n",
       " 700: 3,\n",
       " 701: 2,\n",
       " 702: 1,\n",
       " 703: 2,\n",
       " 704: 6,\n",
       " 705: 5,\n",
       " 706: 15,\n",
       " 707: 1,\n",
       " 708: 35,\n",
       " 709: 1,\n",
       " 711: 13,\n",
       " 713: 4,\n",
       " 714: 1,\n",
       " 715: 3,\n",
       " 717: 1,\n",
       " 718: 18,\n",
       " 719: 1,\n",
       " 721: 7,\n",
       " 722: 2,\n",
       " 723: 8,\n",
       " 724: 2,\n",
       " 725: 3,\n",
       " 726: 3,\n",
       " 727: 1,\n",
       " 728: 1,\n",
       " 729: 1,\n",
       " 730: 16,\n",
       " 731: 1,\n",
       " 732: 26,\n",
       " 733: 1,\n",
       " 737: 15,\n",
       " 738: 3,\n",
       " 739: 31,\n",
       " 740: 1,\n",
       " 741: 7,\n",
       " 742: 6,\n",
       " 743: 4,\n",
       " 744: 11,\n",
       " 745: 1,\n",
       " 746: 1,\n",
       " 747: 1,\n",
       " 748: 1,\n",
       " 749: 1,\n",
       " 750: 18,\n",
       " 751: 2,\n",
       " 752: 3,\n",
       " 753: 18,\n",
       " 754: 4,\n",
       " 755: 15,\n",
       " 756: 30,\n",
       " 757: 31,\n",
       " 758: 3,\n",
       " 759: 15,\n",
       " 760: 5,\n",
       " 761: 2,\n",
       " 762: 20,\n",
       " 763: 160,\n",
       " 764: 1,\n",
       " 767: 111,\n",
       " 768: 31,\n",
       " 769: 1,\n",
       " 770: 1,\n",
       " 771: 2,\n",
       " 772: 1,\n",
       " 773: 2,\n",
       " 774: 7,\n",
       " 775: 2,\n",
       " 776: 22,\n",
       " 777: 3,\n",
       " 778: 6,\n",
       " 779: 5,\n",
       " 780: 7,\n",
       " 781: 1,\n",
       " 782: 11,\n",
       " 784: 1,\n",
       " 785: 23,\n",
       " 786: 22,\n",
       " 787: 2,\n",
       " 788: 2,\n",
       " 789: 1,\n",
       " 790: 9,\n",
       " 791: 2,\n",
       " 792: 1,\n",
       " 793: 1,\n",
       " 794: 12,\n",
       " 795: 5,\n",
       " 796: 12,\n",
       " 797: 2,\n",
       " 798: 11,\n",
       " 800: 18,\n",
       " 801: 8,\n",
       " 803: 1,\n",
       " 804: 2,\n",
       " 805: 1,\n",
       " 806: 8,\n",
       " 807: 2,\n",
       " 808: 2,\n",
       " 809: 1,\n",
       " 810: 5,\n",
       " 811: 4,\n",
       " 812: 1,\n",
       " 813: 8,\n",
       " 814: 8,\n",
       " 815: 18,\n",
       " 816: 3,\n",
       " 817: 5,\n",
       " 818: 12,\n",
       " 819: 1,\n",
       " 820: 1,\n",
       " 821: 1,\n",
       " 822: 17,\n",
       " 823: 2,\n",
       " 824: 7,\n",
       " 825: 2,\n",
       " 826: 12,\n",
       " 828: 1,\n",
       " 829: 18,\n",
       " 830: 10,\n",
       " 831: 1,\n",
       " 832: 1,\n",
       " 833: 1,\n",
       " 834: 1,\n",
       " 835: 1,\n",
       " 836: 11,\n",
       " 837: 3,\n",
       " 838: 13,\n",
       " 839: 2,\n",
       " 840: 3,\n",
       " 841: 22,\n",
       " 842: 10,\n",
       " 843: 14,\n",
       " 844: 1,\n",
       " 845: 5,\n",
       " 846: 6,\n",
       " 847: 5,\n",
       " 848: 19,\n",
       " 849: 1,\n",
       " 850: 5,\n",
       " 851: 1,\n",
       " 852: 33,\n",
       " 853: 2,\n",
       " 854: 8,\n",
       " 855: 63,\n",
       " 856: 3,\n",
       " 857: 1,\n",
       " 858: 22,\n",
       " 859: 1,\n",
       " 861: 10,\n",
       " 862: 1,\n",
       " 863: 10,\n",
       " 864: 4,\n",
       " 865: 35,\n",
       " 866: 17,\n",
       " 867: 1,\n",
       " 868: 49,\n",
       " 869: 1,\n",
       " 870: 2,\n",
       " 871: 11,\n",
       " 872: 1,\n",
       " 873: 12,\n",
       " 874: 1,\n",
       " 875: 9,\n",
       " 876: 3,\n",
       " 877: 15,\n",
       " 878: 3,\n",
       " 879: 1,\n",
       " 880: 1,\n",
       " 881: 2,\n",
       " 882: 4,\n",
       " 883: 20,\n",
       " 884: 8,\n",
       " 885: 6,\n",
       " 886: 1,\n",
       " 887: 5,\n",
       " 888: 6,\n",
       " 889: 7,\n",
       " 890: 3,\n",
       " 891: 1,\n",
       " 892: 2,\n",
       " 894: 2,\n",
       " 895: 2,\n",
       " 896: 2,\n",
       " 897: 8,\n",
       " 898: 37,\n",
       " 899: 1,\n",
       " 900: 2,\n",
       " 901: 2,\n",
       " 902: 1,\n",
       " 903: 1,\n",
       " 904: 8,\n",
       " 905: 43,\n",
       " 906: 20,\n",
       " 907: 1,\n",
       " 908: 15,\n",
       " 909: 3,\n",
       " 910: 4,\n",
       " 911: 14,\n",
       " 912: 3,\n",
       " 913: 4,\n",
       " 914: 5,\n",
       " 915: 1,\n",
       " 916: 1,\n",
       " 917: 2,\n",
       " 918: 1,\n",
       " 919: 16,\n",
       " 920: 7,\n",
       " 922: 7,\n",
       " 923: 4,\n",
       " 924: 1,\n",
       " 925: 1,\n",
       " 926: 14,\n",
       " 927: 1,\n",
       " 928: 1,\n",
       " 929: 5,\n",
       " 930: 1,\n",
       " 931: 2,\n",
       " 932: 2,\n",
       " 933: 20,\n",
       " 934: 2,\n",
       " 935: 2,\n",
       " 936: 3,\n",
       " 937: 16,\n",
       " 938: 1,\n",
       " 940: 17,\n",
       " 941: 38,\n",
       " 942: 1,\n",
       " 943: 13,\n",
       " 944: 11,\n",
       " 945: 1,\n",
       " 946: 1,\n",
       " 947: 4,\n",
       " 951: 1,\n",
       " 952: 1,\n",
       " 953: 1,\n",
       " 954: 3,\n",
       " 955: 1,\n",
       " 956: 5,\n",
       " 957: 1,\n",
       " 958: 3,\n",
       " 959: 1,\n",
       " 960: 9,\n",
       " 961: 1,\n",
       " 962: 7,\n",
       " 963: 108,\n",
       " 964: 13,\n",
       " 965: 21,\n",
       " 966: 2,\n",
       " 967: 2,\n",
       " 968: 21,\n",
       " 969: 4,\n",
       " 970: 1,\n",
       " 971: 4,\n",
       " 972: 3,\n",
       " 973: 24,\n",
       " 974: 3,\n",
       " 975: 3,\n",
       " 976: 2,\n",
       " 977: 10,\n",
       " 978: 44,\n",
       " 979: 1,\n",
       " 980: 1,\n",
       " 981: 1,\n",
       " 982: 2,\n",
       " 983: 11,\n",
       " 984: 7,\n",
       " 985: 1,\n",
       " 986: 2,\n",
       " 987: 1,\n",
       " 988: 10,\n",
       " 989: 9,\n",
       " 990: 1,\n",
       " 991: 1,\n",
       " 992: 4,\n",
       " 993: 1,\n",
       " 994: 1,\n",
       " 995: 3,\n",
       " 996: 6,\n",
       " 997: 1,\n",
       " 998: 14,\n",
       " 999: 1,\n",
       " 1000: 3,\n",
       " 1001: 1,\n",
       " 1002: 11,\n",
       " 1003: 1,\n",
       " 1004: 5,\n",
       " 1005: 10,\n",
       " 1006: 3,\n",
       " 1007: 4,\n",
       " 1008: 8,\n",
       " 1009: 2,\n",
       " 1011: 1,\n",
       " 1012: 57,\n",
       " 1013: 8,\n",
       " 1014: 18,\n",
       " 1015: 4,\n",
       " 1016: 39,\n",
       " 1017: 3,\n",
       " 1018: 1,\n",
       " 1019: 1,\n",
       " 1020: 1,\n",
       " 1022: 1,\n",
       " 1023: 1,\n",
       " 1024: 1,\n",
       " 1025: 1,\n",
       " 1026: 1,\n",
       " 1027: 7,\n",
       " 1028: 12,\n",
       " 1029: 3,\n",
       " 1030: 2,\n",
       " 1031: 1,\n",
       " 1032: 7,\n",
       " 1033: 17,\n",
       " 1034: 1,\n",
       " 1035: 1,\n",
       " 1036: 3,\n",
       " 1037: 5,\n",
       " 1038: 10,\n",
       " 1039: 2,\n",
       " 1040: 9,\n",
       " 1041: 2,\n",
       " 1042: 8,\n",
       " 1043: 3,\n",
       " 1044: 1,\n",
       " 1045: 1,\n",
       " 1046: 3,\n",
       " 1047: 15,\n",
       " 1048: 2,\n",
       " 1049: 2,\n",
       " 1050: 2,\n",
       " 1051: 1,\n",
       " 1052: 1,\n",
       " 1053: 4,\n",
       " 1054: 2,\n",
       " 1055: 5,\n",
       " 1056: 1,\n",
       " 1057: 1,\n",
       " 1058: 3,\n",
       " 1059: 79,\n",
       " 1060: 3,\n",
       " 1061: 1,\n",
       " 1062: 3,\n",
       " 1063: 3,\n",
       " 1064: 1,\n",
       " 1065: 7,\n",
       " 1066: 1,\n",
       " 1067: 2,\n",
       " 1068: 2,\n",
       " 1069: 1,\n",
       " 1070: 1,\n",
       " 1071: 24,\n",
       " 1072: 22,\n",
       " 1073: 9,\n",
       " 1074: 15,\n",
       " 1075: 1,\n",
       " 1076: 8,\n",
       " 1077: 1,\n",
       " 1078: 1,\n",
       " 1079: 4,\n",
       " 1080: 8,\n",
       " 1081: 6,\n",
       " 1082: 4,\n",
       " 1083: 9,\n",
       " 1084: 1,\n",
       " 1085: 14,\n",
       " 1086: 15,\n",
       " 1087: 1,\n",
       " 1088: 4,\n",
       " 1090: 1,\n",
       " 1091: 1,\n",
       " 1092: 4,\n",
       " 1093: 6,\n",
       " 1095: 16,\n",
       " 1096: 26,\n",
       " 1097: 1,\n",
       " 1098: 1,\n",
       " 1099: 1,\n",
       " 1100: 3,\n",
       " 1101: 1,\n",
       " 1102: 21,\n",
       " 1103: 1,\n",
       " 1104: 6,\n",
       " 1105: 2,\n",
       " 1106: 11,\n",
       " 1107: 2,\n",
       " 1108: 1,\n",
       " 1109: 1,\n",
       " 1110: 2,\n",
       " 1111: 1,\n",
       " 1112: 1,\n",
       " 1113: 1,\n",
       " 1114: 1,\n",
       " 1115: 1,\n",
       " 1116: 2,\n",
       " 1117: 17,\n",
       " 1118: 4,\n",
       " 1119: 20,\n",
       " 1120: 2,\n",
       " 1121: 2,\n",
       " 1122: 2,\n",
       " 1123: 2,\n",
       " 1124: 3,\n",
       " 1125: 10,\n",
       " 1126: 40,\n",
       " 1127: 27,\n",
       " 1128: 7,\n",
       " 1129: 7,\n",
       " 1130: 2,\n",
       " 1131: 3,\n",
       " 1132: 2,\n",
       " 1133: 1,\n",
       " 1134: 6,\n",
       " 1135: 4,\n",
       " 1136: 2,\n",
       " 1137: 1,\n",
       " 1139: 1,\n",
       " 1140: 41,\n",
       " 1141: 6,\n",
       " 1142: 2,\n",
       " 1143: 1,\n",
       " 1144: 8,\n",
       " 1145: 5,\n",
       " 1146: 1,\n",
       " 1147: 2,\n",
       " 1148: 10,\n",
       " 1149: 4,\n",
       " 1150: 1,\n",
       " 1152: 1,\n",
       " 1153: 6,\n",
       " 1155: 1,\n",
       " 1156: 3,\n",
       " 1157: 1,\n",
       " 1158: 4,\n",
       " 1159: 1,\n",
       " 1160: 10,\n",
       " 1161: 3,\n",
       " 1162: 23,\n",
       " 1163: 1,\n",
       " 1164: 1,\n",
       " 1165: 26,\n",
       " 1166: 6,\n",
       " 1167: 1,\n",
       " 1168: 1,\n",
       " 1169: 1,\n",
       " 1170: 6,\n",
       " 1171: 1,\n",
       " 1172: 3,\n",
       " 1173: 1,\n",
       " 1174: 1,\n",
       " 1175: 4,\n",
       " 1176: 5,\n",
       " 1177: 11,\n",
       " 1178: 1,\n",
       " 1179: 1,\n",
       " 1180: 1,\n",
       " 1181: 17,\n",
       " 1182: 2,\n",
       " 1183: 8,\n",
       " 1184: 10,\n",
       " 1185: 2,\n",
       " 1186: 1,\n",
       " 1187: 8,\n",
       " 1188: 9,\n",
       " 1189: 1,\n",
       " 1190: 1,\n",
       " 1191: 1,\n",
       " 1192: 9,\n",
       " 1193: 3,\n",
       " 1194: 6,\n",
       " 1195: 7,\n",
       " ...}"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_docs_with_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.44344728, 4.49153479, 2.59817185, ..., 9.27902653, 9.27902653,\n",
       "       9.27902653])"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_tf_idf_for_sample(sample: list[int]):\n",
    "    N = len(sample)\n",
    "    tf = defaultdict(int)\n",
    "    for token in sample:\n",
    "        tf[token] += 1\n",
    "    for token in tf:\n",
    "        tf[token] = tf[token] / N\n",
    "    \n",
    "    tf_idf = np.zeros(len(vocab)) # vocab from only training set\n",
    "    for token in tf:\n",
    "        if token < len(idf)-1:\n",
    "            tf_idf[token] = tf[token] * idf[token]\n",
    "    \n",
    "    return tf_idf\n",
    "\n",
    "def gen_tf_idf(X: np.ndarray):\n",
    "    new_X = np.zeros((X.shape[0], len(vocab)))\n",
    "    for i, sample in enumerate(X):\n",
    "        new_X[i] = gen_tf_idf_for_sample(sample)\n",
    "    \n",
    "    return new_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10711,) (2678,) (10711,) (2678,) 4729\n"
     ]
    }
   ],
   "source": [
    "print(train_X.shape, test_X.shape, train_y.shape, test_y.shape, len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = gen_tf_idf(train_X)\n",
    "X_test = gen_tf_idf(test_X)\n",
    "y_train = train_y.copy().astype(int)\n",
    "y_test = test_y.copy().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10711, 4729) (2678, 4729) (10711,) (2678,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-7 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-7 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-7 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-7 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-7 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-7 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-7 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-7 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-7 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-7 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, random_state=2025)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, random_state=2025)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(class_weight='balanced', random_state=2025)"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 100 max epochs took 10s\n",
    "# 100 max epochs with ignoring stop words took 17s\n",
    "logmodel = LogisticRegression(class_weight='balanced', max_iter=100, random_state=2025)\n",
    "logmodel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 0.15224909782409668\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "predictions = logmodel.predict(X_test)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Total time: {end_time - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 0.06745219230651855\n"
     ]
    }
   ],
   "source": [
    "# with stop words\n",
    "start_time = time.time()\n",
    "predictions = logmodel.predict(X_test)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Total time: {end_time - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Acc. on test data 64.413742%\n"
     ]
    }
   ],
   "source": [
    "# 100 max epochs: acc 64.412% \n",
    "print(\"Model Acc. on test data %f%%\"\n",
    "       % ((y_test == predictions).sum() / y_test.shape[0] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Acc. on test data 61.165049%\n"
     ]
    }
   ],
   "source": [
    "# 100 max epochs with ignoring stop words: acc 61.165%\n",
    "print(\"Model Acc. on test data %f%%\"\n",
    "       % ((y_test == predictions).sum() / y_test.shape[0] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.572289156626506,\n",
       "  'recall': 0.7421875,\n",
       "  'f1-score': 0.6462585034013606,\n",
       "  'support': 128.0},\n",
       " '1': {'precision': 0.7096774193548387,\n",
       "  'recall': 0.55,\n",
       "  'f1-score': 0.6197183098591549,\n",
       "  'support': 360.0},\n",
       " '2': {'precision': 0.7295597484276729,\n",
       "  'recall': 0.7945205479452054,\n",
       "  'f1-score': 0.760655737704918,\n",
       "  'support': 146.0},\n",
       " '3': {'precision': 0.6873065015479877,\n",
       "  'recall': 0.6201117318435754,\n",
       "  'f1-score': 0.6519823788546255,\n",
       "  'support': 358.0},\n",
       " '4': {'precision': 0.5029239766081871,\n",
       "  'recall': 0.7413793103448276,\n",
       "  'f1-score': 0.5993031358885017,\n",
       "  'support': 116.0},\n",
       " '5': {'precision': 0.8379310344827586,\n",
       "  'recall': 0.5758293838862559,\n",
       "  'f1-score': 0.6825842696629213,\n",
       "  'support': 422.0},\n",
       " '6': {'precision': 0.359375,\n",
       "  'recall': 0.46938775510204084,\n",
       "  'f1-score': 0.40707964601769914,\n",
       "  'support': 49.0},\n",
       " '7': {'precision': 0.8857142857142857,\n",
       "  'recall': 0.7306397306397306,\n",
       "  'f1-score': 0.8007380073800738,\n",
       "  'support': 297.0},\n",
       " '8': {'precision': 0.23015873015873015,\n",
       "  'recall': 0.4393939393939394,\n",
       "  'f1-score': 0.3020833333333333,\n",
       "  'support': 66.0},\n",
       " '9': {'precision': 0.6974789915966386,\n",
       "  'recall': 0.7685185185185185,\n",
       "  'f1-score': 0.7312775330396476,\n",
       "  'support': 108.0},\n",
       " '10': {'precision': 0.7,\n",
       "  'recall': 0.8,\n",
       "  'f1-score': 0.7466666666666667,\n",
       "  'support': 35.0},\n",
       " '11': {'precision': 0.6294642857142857,\n",
       "  'recall': 0.6157205240174672,\n",
       "  'f1-score': 0.6225165562913907,\n",
       "  'support': 229.0},\n",
       " '12': {'precision': 0.4307692307692308,\n",
       "  'recall': 0.5,\n",
       "  'f1-score': 0.4628099173553719,\n",
       "  'support': 56.0},\n",
       " '13': {'precision': 0.25, 'recall': 0.75, 'f1-score': 0.375, 'support': 4.0},\n",
       " '14': {'precision': 0.6666666666666666,\n",
       "  'recall': 0.7755102040816326,\n",
       "  'f1-score': 0.7169811320754716,\n",
       "  'support': 49.0},\n",
       " '15': {'precision': 0.8181818181818182,\n",
       "  'recall': 0.72,\n",
       "  'f1-score': 0.7659574468085106,\n",
       "  'support': 50.0},\n",
       " '16': {'precision': 0.3924050632911392,\n",
       "  'recall': 0.5254237288135594,\n",
       "  'f1-score': 0.4492753623188406,\n",
       "  'support': 59.0},\n",
       " '17': {'precision': 0.8367346938775511,\n",
       "  'recall': 0.8913043478260869,\n",
       "  'f1-score': 0.8631578947368421,\n",
       "  'support': 46.0},\n",
       " '18': {'precision': 0.35,\n",
       "  'recall': 0.7,\n",
       "  'f1-score': 0.4666666666666667,\n",
       "  'support': 10.0},\n",
       " '19': {'precision': 0.7560975609756098,\n",
       "  'recall': 0.7560975609756098,\n",
       "  'f1-score': 0.7560975609756098,\n",
       "  'support': 41.0},\n",
       " '20': {'precision': 0.03333333333333333,\n",
       "  'recall': 0.1,\n",
       "  'f1-score': 0.05,\n",
       "  'support': 10.0},\n",
       " '21': {'precision': 0.41935483870967744,\n",
       "  'recall': 0.8125,\n",
       "  'f1-score': 0.5531914893617021,\n",
       "  'support': 16.0},\n",
       " '22': {'precision': 0.11764705882352941,\n",
       "  'recall': 0.2857142857142857,\n",
       "  'f1-score': 0.16666666666666666,\n",
       "  'support': 7.0},\n",
       " '23': {'precision': 0.44,\n",
       "  'recall': 0.8461538461538461,\n",
       "  'f1-score': 0.5789473684210527,\n",
       "  'support': 13.0},\n",
       " '24': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1.0},\n",
       " '25': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 2.0},\n",
       " 'accuracy': 0.6441374159820762,\n",
       " 'macro avg': {'precision': 0.5405026690330941,\n",
       "  'recall': 0.6350151121252531,\n",
       "  'f1-score': 0.5682929070571934,\n",
       "  'support': 2678.0},\n",
       " 'weighted avg': {'precision': 0.6883919072305033,\n",
       "  'recall': 0.6441374159820762,\n",
       "  'f1-score': 0.6557119304297164,\n",
       "  'support': 2678.0}}"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report = classification_report(y_test, predictions, output_dict=True, digits=2)\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87UHAQkt5dIw"
      },
      "source": [
        "# RNN Date Generation Demo on Pytoch Lightning: Date Generation (One-to-Many)\n",
        "\n",
        "In this demo, we will show you how to create a date generator using Pytoch Lightning. This demo is inspired by Andrew Ng's deeplearning.ai course on sequence models. In this demo, we create a one-to-many RNN model for generating date in the following format: e.g. \"2002-03-11\".  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yIz3jAIF5dI1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lightning in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (2.5.0.post0)\n",
            "Requirement already satisfied: PyYAML<8.0,>=5.4 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from lightning) (6.0.2)\n",
            "Requirement already satisfied: fsspec<2026.0,>=2022.5.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning) (2024.12.0)\n",
            "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from lightning) (0.11.9)\n",
            "Requirement already satisfied: packaging<25.0,>=20.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from lightning) (24.2)\n",
            "Requirement already satisfied: torch<4.0,>=2.1.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from lightning) (2.5.1)\n",
            "Requirement already satisfied: torchmetrics<3.0,>=0.7.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from lightning) (1.6.1)\n",
            "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from lightning) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<6.0,>=4.4.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from lightning) (4.12.2)\n",
            "Requirement already satisfied: pytorch-lightning in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from lightning) (2.5.0.post0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning) (3.11.11)\n",
            "Requirement already satisfied: setuptools in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from lightning-utilities<2.0,>=0.10.0->lightning) (75.7.0)\n",
            "Requirement already satisfied: filelock in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from torch<4.0,>=2.1.0->lightning) (3.16.1)\n",
            "Requirement already satisfied: networkx in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from torch<4.0,>=2.1.0->lightning) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from torch<4.0,>=2.1.0->lightning) (3.1.5)\n",
            "Requirement already satisfied: sympy==1.13.1 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from torch<4.0,>=2.1.0->lightning) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from sympy==1.13.1->torch<4.0,>=2.1.0->lightning) (1.3.0)\n",
            "Requirement already satisfied: numpy>1.20.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from torchmetrics<3.0,>=0.7.0->lightning) (2.2.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from jinja2->torch<4.0,>=2.1.0->lightning) (3.0.2)\n",
            "Requirement already satisfied: idna>=2.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (3.10)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "import sys\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "!pip install lightning\n",
        "import lightning as L\n",
        "from lightning import Trainer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULHSHW5X5dJE"
      },
      "source": [
        "# Generate Dataset\n",
        "We generate a toy dataset using datetime library.  The target output only comes in one format (iso format)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "km8dKUXP5dJH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['2025-01-20', '2025-01-19', '2025-01-18', '2025-01-17', '2025-01-16']\n"
          ]
        }
      ],
      "source": [
        "#Generating a toy dataset\n",
        "import datetime\n",
        "base = datetime.datetime.today()\n",
        "base = datetime.date(base.year, base.month, base.day)\n",
        "date_list = [base - datetime.timedelta(days=x) for x in range(0, 1500)]\n",
        "data = [date.isoformat() for date in date_list]\n",
        "print(data[:5])\n",
        "maxlen=10 #all the seqeunces have 10 characters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "FKLIr4Od5dJP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 1500 lines and 11 unique characters in your data.\n",
            "max length = 10\n",
            "['-', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n"
          ]
        }
      ],
      "source": [
        "chars = list(set(''.join(data)))\n",
        "data_size, vocab_size = len(data), len(chars)\n",
        "print('There are %d lines and %d unique characters in your data.' % (data_size, vocab_size))\n",
        "print(\"max length =\",maxlen)\n",
        "sorted_chars= sorted(chars)\n",
        "print(sorted_chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "YO-IDo5A5dJX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All Characters: ['<S>', '-', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
            "Vocab Size: 12\n"
          ]
        }
      ],
      "source": [
        "# In this demo, we will use \"<S>\" as a seed character to initiate the sequence\n",
        "sorted_chars.insert(0,\"<S>\")\n",
        "vocab_size = len(sorted_chars)\n",
        "\n",
        "print(f\"All Characters: {sorted_chars}\")\n",
        "print(f\"Vocab Size: {vocab_size}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "1SiYQTFehkLk"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[4, 2, 4, 6, 1, 3, 2, 1, 4, 8]\n",
            "2024-10-26\n"
          ]
        }
      ],
      "source": [
        "# Quick implementation of character tokenizer\n",
        "# create a mapping from characters to integers\n",
        "stoi = { ch:i for i,ch in enumerate(sorted_chars) }\n",
        "itos = { i:ch for i,ch in enumerate(sorted_chars) }\n",
        "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
        "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
        "\n",
        "print(encode(\"2024-10-26\"))\n",
        "print(decode(encode(\"2024-10-26\")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "DQ2fXwDoi48Q"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: '<S>',\n",
              " 1: '-',\n",
              " 2: '0',\n",
              " 3: '1',\n",
              " 4: '2',\n",
              " 5: '3',\n",
              " 6: '4',\n",
              " 7: '5',\n",
              " 8: '6',\n",
              " 9: '7',\n",
              " 10: '8',\n",
              " 11: '9'}"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "itos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "RIzWJicEjx-z"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'<S>': 0,\n",
              " '-': 1,\n",
              " '0': 2,\n",
              " '1': 3,\n",
              " '2': 4,\n",
              " '3': 5,\n",
              " '4': 6,\n",
              " '5': 7,\n",
              " '6': 8,\n",
              " '7': 9,\n",
              " '8': 10,\n",
              " '9': 11}"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stoi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRuFbBUx5dJr"
      },
      "source": [
        "# Preprocessing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "mw-BupZv5dJt"
      },
      "outputs": [],
      "source": [
        "#Encoding data\n",
        "encoded = []\n",
        "for line in data:\n",
        "    line = [l for l in line] #change from string to list\n",
        "    indices = encode(line)\n",
        "    encoded.append(indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "iwKOiX5B5dJ0"
      },
      "outputs": [],
      "source": [
        "class DateDataset(Dataset):\n",
        "  def __init__(self, data):\n",
        "    data = [[0] + d for d in data] # add <s> at the start of every data point\n",
        "    self.encoded = torch.LongTensor(data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.encoded[idx]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Q0MWLXPzJaZp"
      },
      "outputs": [],
      "source": [
        "class DateDataModule(L.LightningDataModule):\n",
        "\n",
        "  def __init__(self, train_data, batch_size, num_workers=0):\n",
        "      super().__init__()\n",
        "      self.train_data = train_data\n",
        "      self.batch_size = batch_size\n",
        "      self.num_workers = num_workers\n",
        "\n",
        "\n",
        "  def setup(self, stage: str):\n",
        "    pass\n",
        "\n",
        "  def collate_fn(self, batch):\n",
        "      one_hot_x = torch.stack([F.one_hot(b, num_classes=vocab_size) for b in batch])\n",
        "      return {\"x\": one_hot_x.float(), \"y\": torch.stack(batch)}\n",
        "\n",
        "  def train_dataloader(self):\n",
        "      train_dataset = DateDataset(self.train_data)\n",
        "      train_loader = DataLoader(train_dataset,\n",
        "                                batch_size = self.batch_size,\n",
        "                                shuffle = True,\n",
        "                                collate_fn = self.collate_fn,\n",
        "                                num_workers = self.num_workers)\n",
        "\n",
        "      return train_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "90IQfib5OYJI"
      },
      "outputs": [],
      "source": [
        "batch_size = 16\n",
        "data_module = DateDataModule(encoded, batch_size=batch_size,num_workers=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmXcPnNi5dJ9"
      },
      "source": [
        "# Create & train model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "YKKPBWnCJppN"
      },
      "outputs": [],
      "source": [
        "class SimpleRNN(L.LightningModule):\n",
        "    def __init__(self, vocab_size, learning_rate, criterion):\n",
        "\n",
        "        super().__init__()\n",
        "        self.hidden_dim = 16\n",
        "        self.vocab_size = vocab_size\n",
        "        # rnn cell = single RNN cell\n",
        "        self.rnn = nn.RNNCell(self.vocab_size, self.hidden_dim) # vocab_size is the input size (embedding dim)\n",
        "\n",
        "        self.fc = nn.Linear(self.hidden_dim, self.vocab_size)\n",
        "        self.learning_rate = learning_rate\n",
        "        self.criterion = criterion\n",
        "\n",
        "\n",
        "    def forward(self, src, hx):\n",
        "        hx = self.rnn(src, hx)\n",
        "        prediction_logit = self.fc(hx)\n",
        "        return prediction_logit, hx\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        src = batch['x'][:, :-1]\n",
        "        target = batch['y'][:, 1:]\n",
        "        temp = []\n",
        "        hx = torch.randn(src.shape[0], self.hidden_dim).to(self.rnn.weight_ih.device)\n",
        "        prediction = torch.zeros((src.shape[0], src.shape[1], self.vocab_size) ,device=hx.device)\n",
        "\n",
        "        for i in range(src.shape[1]):\n",
        "          prediction_logit, hx = self(src[:,i], hx) # forward(current_char, hidden_state)\n",
        "          prediction[:, i, :] = prediction_logit\n",
        "\n",
        "        prediction = prediction.reshape(-1, vocab_size)\n",
        "        target = target.reshape(-1)\n",
        "        loss = self.criterion(prediction, target)\n",
        "        self.log(\"train_loss\", loss)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return optim.Adam(self.parameters(), lr=self.learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "0w5KTNVpKKVr"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "vocab_size = vocab_size\n",
        "lr = 0.005\n",
        "model = SimpleRNN(vocab_size, lr, criterion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "wSpkkvTOTMRV"
      },
      "outputs": [],
      "source": [
        "def generate(model):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    output_list = []\n",
        "    input = F.one_hot(torch.zeros([1], dtype=torch.long), num_classes=vocab_size)\n",
        "    input = input.float()\n",
        "    input = input.to(model.device)\n",
        "    hx = torch.randn(input.shape[0], 16).to(model.device)\n",
        "    for i in range(10):\n",
        "      logit, hx = model(input, hx)\n",
        "      prob = F.softmax(logit, dim=-1)\n",
        "      pred = torch.multinomial(prob, 1)\n",
        "      output = pred.item()\n",
        "      output_list.append(output)\n",
        "\n",
        "      input = F.one_hot(torch.tensor([output], dtype=torch.long), num_classes=vocab_size) # use the predicted character as the next input\n",
        "      input = input.float()\n",
        "      input = input.to(model.device)\n",
        "  return decode(output_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "qvujPMWdPbDS"
      },
      "outputs": [],
      "source": [
        "class PrintCallback(L.pytorch.callbacks.Callback):\n",
        "  def __init__(self, what=\"epochs\", verbose=True):\n",
        "        self.what = what\n",
        "        self.verbose = verbose\n",
        "        self.state = {\"epochs\": 0, \"batches\": 0}\n",
        "\n",
        "  def on_train_epoch_end(self, *args, **kwargs):\n",
        "        if self.what == \"epochs\":\n",
        "            self.state[\"epochs\"] += 1\n",
        "        if self.state[\"epochs\"] % 2 == 0:\n",
        "            print('----- Generating text after Epoch: %d' % self.state[\"epochs\"])\n",
        "            for i in range(3):\n",
        "              print(generate(model))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "NeTcVNQmO3aZ"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: True (mps), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "/Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n"
          ]
        }
      ],
      "source": [
        "trainer = Trainer(\n",
        "    max_epochs=10,\n",
        "    callbacks=[PrintCallback()]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4M8URGW5dK0"
      },
      "source": [
        "# Let's train the model and generate some text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "QvtvwwwSqpAc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "940-584-20\n",
            "7341<S><S>6367\n",
            "3032-0-542\n"
          ]
        }
      ],
      "source": [
        "for i in range(3): #before training\n",
        "  print(generate(model))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "cTVJ8ZGFO5W3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  | Name      | Type             | Params | Mode\n",
            "------------------------------------------------------\n",
            "0 | rnn       | RNNCell          | 480    | eval\n",
            "1 | fc        | Linear           | 204    | eval\n",
            "2 | criterion | CrossEntropyLoss | 0      | eval\n",
            "------------------------------------------------------\n",
            "684       Trainable params\n",
            "0         Non-trainable params\n",
            "684       Total params\n",
            "0.003     Total estimated model params size (MB)\n",
            "0         Modules in train mode\n",
            "3         Modules in eval mode\n",
            "/Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: 100%|██████████| 94/94 [00:01<00:00, 55.25it/s, v_num=0]----- Generating text after Epoch: 2\n",
            "2021-10-21\n",
            "2024-17-07\n",
            "2021-32-10\n",
            "Epoch 3: 100%|██████████| 94/94 [00:01<00:00, 56.57it/s, v_num=0]----- Generating text after Epoch: 4\n",
            "2021-01-18\n",
            "2022-03-06\n",
            "2023-05-08\n",
            "Epoch 5: 100%|██████████| 94/94 [00:01<00:00, 57.53it/s, v_num=0]----- Generating text after Epoch: 6\n",
            "2023-10-01\n",
            "2023-01-27\n",
            "2021-09-11\n",
            "Epoch 7: 100%|██████████| 94/94 [00:01<00:00, 54.46it/s, v_num=0]----- Generating text after Epoch: 8\n",
            "2024-12-27\n",
            "2022-06-17\n",
            "2022-06-28\n",
            "Epoch 9: 100%|██████████| 94/94 [00:01<00:00, 58.78it/s, v_num=0]----- Generating text after Epoch: 10\n",
            "2024-07-26\n",
            "2022-04-19\n",
            "2022-04-29\n",
            "Epoch 9: 100%|██████████| 94/94 [00:01<00:00, 55.44it/s, v_num=0]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9: 100%|██████████| 94/94 [00:01<00:00, 55.17it/s, v_num=0]\n"
          ]
        }
      ],
      "source": [
        "trainer.fit(model, data_module)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "voYlHp7cWyAk"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-02-16\n",
            "2022-04-15\n",
            "2024-01-08\n",
            "2023-11-12\n",
            "2023-12-26\n",
            "2022-11-13\n",
            "2021-05-02\n",
            "2023-06-09\n",
            "2022-10-12\n",
            "2024-03-09\n"
          ]
        }
      ],
      "source": [
        "for i in range(10):\n",
        "  print(generate(model))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uhpse2Wl1-QR"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

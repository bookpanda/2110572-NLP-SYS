{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0u4d0nVRMVgG"
      },
      "source": [
        "# Additive Attention from scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EB0ipHig9gOm"
      },
      "source": [
        "## Attention Mechanism Demo on Pytorch: Machine Translation Example (Many-to-Many, encoder-decoder)\n",
        "\n",
        "In this demo, we will show you how to create a machine translator using Pytorch. This demo is inspired by Andrew Ng's deeplearning.ai course on sequence models. (Programming Assignment: Neural Machine Translation with Attention)    In this demo, we create a machine translator to translate dates in various formats  into dates in an ISO format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3_clL4w89gOt"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lightning in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (2.5.0.post0)\n",
            "Requirement already satisfied: PyYAML<8.0,>=5.4 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from lightning) (6.0.2)\n",
            "Requirement already satisfied: fsspec<2026.0,>=2022.5.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning) (2024.12.0)\n",
            "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from lightning) (0.11.9)\n",
            "Requirement already satisfied: packaging<25.0,>=20.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from lightning) (24.2)\n",
            "Requirement already satisfied: torch<4.0,>=2.1.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from lightning) (2.5.1)\n",
            "Requirement already satisfied: torchmetrics<3.0,>=0.7.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from lightning) (1.6.1)\n",
            "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from lightning) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<6.0,>=4.4.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from lightning) (4.12.2)\n",
            "Requirement already satisfied: pytorch-lightning in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from lightning) (2.5.0.post0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning) (3.11.11)\n",
            "Requirement already satisfied: setuptools in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from lightning-utilities<2.0,>=0.10.0->lightning) (75.7.0)\n",
            "Requirement already satisfied: filelock in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from torch<4.0,>=2.1.0->lightning) (3.16.1)\n",
            "Requirement already satisfied: networkx in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from torch<4.0,>=2.1.0->lightning) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from torch<4.0,>=2.1.0->lightning) (3.1.5)\n",
            "Requirement already satisfied: sympy==1.13.1 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from torch<4.0,>=2.1.0->lightning) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from sympy==1.13.1->torch<4.0,>=2.1.0->lightning) (1.3.0)\n",
            "Requirement already satisfied: numpy>1.20.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from torchmetrics<3.0,>=0.7.0->lightning) (2.2.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from jinja2->torch<4.0,>=2.1.0->lightning) (3.0.2)\n",
            "Requirement already satisfied: idna>=2.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (3.10)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "!pip install lightning\n",
        "import lightning as L\n",
        "from lightning import Trainer\n",
        "\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEyHEfFt9gO9"
      },
      "source": [
        "## Generate Dataset\n",
        "We generate a toy dataset using datetime library.  A target output only comes in one format (iso format), while there are three different date format for an input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "MWRgqvwY9gO_"
      },
      "outputs": [],
      "source": [
        "#Generating a toy dataset\n",
        "import datetime\n",
        "base = datetime.datetime.today()\n",
        "base = datetime.date(base.year, base.month, base.day)\n",
        "date_list = [base - datetime.timedelta(days=x) for x in range(0, 15000)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "KrNHzgFy9gPI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['2025-01-20', '2025-01-19', '2025-01-18', '2025-01-17', '2025-01-16']\n"
          ]
        }
      ],
      "source": [
        "target_date_list = [date.isoformat() for date in date_list]\n",
        "print(target_date_list[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "GT7V4FJL9gPR"
      },
      "outputs": [],
      "source": [
        "from random import randint\n",
        "random.seed(42)\n",
        "input_date_list = list()\n",
        "for date in date_list:\n",
        "    random_num = randint(0, 2)\n",
        "    if random_num == 0:\n",
        "        input_date_list.append(date.strftime(\"%d/%m/%y\"))#\"11/03/02\"\n",
        "    elif random_num == 1:\n",
        "        input_date_list.append(date.strftime(\"%A %d %B %Y\")) #\"Monday 11 March 2002\"\n",
        "    elif random_num == 2:\n",
        "        input_date_list.append(date.strftime(\"%d %B %Y\")) #\"11 March 2002\"\n",
        "\n",
        "# input: \"11/03/02\" or \"Monday 11 March 2002\" or \"11 March 2002\"\n",
        "# target: \"2002-03-11\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "isfXKy2y9gPZ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input: 20 January 2025,\t label: 2025-01-20\n",
            "input: 19/01/25,\t label: 2025-01-19\n",
            "input: 18/01/25,\t label: 2025-01-18\n",
            "input: 17 January 2025,\t label: 2025-01-17\n",
            "input: Thursday 16 January 2025,\t label: 2025-01-16\n",
            "input: 15/01/25,\t label: 2025-01-15\n",
            "input: 14/01/25,\t label: 2025-01-14\n",
            "input: 13/01/25,\t label: 2025-01-13\n",
            "input: 12 January 2025,\t label: 2025-01-12\n",
            "input: 11/01/25,\t label: 2025-01-11\n"
          ]
        }
      ],
      "source": [
        "for input_sample, target_sample in zip(input_date_list[0:10],target_date_list[0:10]):\n",
        "    print(f\"input: {input_sample},\\t label: {target_sample}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'e', 'h', 'l', 'o'}"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "set(\"hello\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "7KndjKsS9gPg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 15000 lines and 42 unique characters in your input data.\n"
          ]
        }
      ],
      "source": [
        "#Preprocessing\n",
        "input_chars = list(set(''.join(input_date_list)))\n",
        "output_chars = list(set(''.join(target_date_list)))\n",
        "\n",
        "# +1 for padding\n",
        "data_size, vocab_size = len(input_date_list), len(input_chars)+1\n",
        "output_vocab_size = len(output_chars)+1\n",
        "\n",
        "print('There are %d lines and %d unique characters in your input data.' % (data_size, vocab_size))\n",
        "maxlen = len( max(input_date_list, key=len)) #max input length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "3K-0kaUH9gPn"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Max input length: 27\n"
          ]
        }
      ],
      "source": [
        "print(\"Max input length:\", maxlen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "YaP2TKsD1UOn"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5, 5, 2, 4, 5, 2, 5, 7]\n",
            "22/12/24\n"
          ]
        }
      ],
      "source": [
        "sorted_chars= sorted(input_chars)\n",
        "sorted_output_chars= sorted(output_chars)\n",
        "sorted_chars.insert(0,\"<PAD>\") #PADDING for input\n",
        "sorted_output_chars.insert(0,\"<PAD>\") #PADDING for output\n",
        "\n",
        "# Quick implementation of character tokenizer\n",
        "# create a mapping from characters to integers\n",
        "input_stoi = { ch:i for i,ch in enumerate(sorted_chars) }\n",
        "input_itos = { i:ch for i,ch in enumerate(sorted_chars) }\n",
        "input_encode = lambda s: [input_stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
        "input_decode = lambda l: ''.join([input_itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
        "\n",
        "\n",
        "output_stoi = { ch:i for i,ch in enumerate(sorted_output_chars) }\n",
        "output_itos = { i:ch for i,ch in enumerate(sorted_output_chars) }\n",
        "output_encode = lambda s: [output_stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
        "output_decode = lambda l: ''.join([output_itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
        "\n",
        "print(input_encode(\"22/12/24\"))\n",
        "print(input_decode(input_encode(\"22/12/24\")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "ulW7bT9V1pS9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'<PAD>': 0, ' ': 1, '/': 2, '0': 3, '1': 4, '2': 5, '3': 6, '4': 7, '5': 8, '6': 9, '7': 10, '8': 11, '9': 12, 'A': 13, 'D': 14, 'F': 15, 'J': 16, 'M': 17, 'N': 18, 'O': 19, 'S': 20, 'T': 21, 'W': 22, 'a': 23, 'b': 24, 'c': 25, 'd': 26, 'e': 27, 'g': 28, 'h': 29, 'i': 30, 'l': 31, 'm': 32, 'n': 33, 'o': 34, 'p': 35, 'r': 36, 's': 37, 't': 38, 'u': 39, 'v': 40, 'y': 41}\n",
            "{'<PAD>': 0, '-': 1, '0': 2, '1': 3, '2': 4, '3': 5, '4': 6, '5': 7, '6': 8, '7': 9, '8': 10, '9': 11}\n"
          ]
        }
      ],
      "source": [
        "print(input_stoi)\n",
        "print(output_stoi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "8Q0XsxhL9gP2"
      },
      "outputs": [],
      "source": [
        "m=15000\n",
        "Tx=maxlen\n",
        "Ty=10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "PvKOfVnc9gP-"
      },
      "outputs": [],
      "source": [
        "X = []\n",
        "for line in input_date_list:\n",
        "    line = [l for l in line] #change from string to list\n",
        "    X.append(torch.tensor(input_encode(line)))\n",
        "Y = []\n",
        "for line in target_date_list:\n",
        "    line = [l for l in line] #change from string to list\n",
        "    Y.append(torch.tensor(output_encode(line)))\n",
        "\n",
        "X = nn.utils.rnn.pad_sequence(X, batch_first = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "trjH1DiZ3yyS"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([15000, 27])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "9khoV30W33US"
      },
      "outputs": [],
      "source": [
        "class DateDataset(Dataset):\n",
        "  def __init__(self, X, y):\n",
        "    self.encoded = X.long()\n",
        "    self.label = torch.stack(y).long()\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return {\"x\" :self.encoded[idx], \"y\":self.label[idx]}\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Z1ONZO0S3_qt"
      },
      "outputs": [],
      "source": [
        "class DateDataModule(L.LightningDataModule):\n",
        "\n",
        "  def __init__(self, train_data, y, batch_size, num_workers=0):\n",
        "      super().__init__()\n",
        "      self.train_data = train_data\n",
        "      self.y = y\n",
        "      self.batch_size = batch_size\n",
        "      self.num_workers = num_workers\n",
        "\n",
        "\n",
        "  def setup(self, stage: str):\n",
        "    pass\n",
        "\n",
        "  def collate_fn(self, batch):\n",
        "      one_hot_x = torch.stack([F.one_hot(b[\"x\"], num_classes=len(input_stoi)) for b in batch])\n",
        "      return {\"x\": one_hot_x.float(), \"y\": torch.stack([b[\"y\"] for b in batch])}\n",
        "\n",
        "  def train_dataloader(self):\n",
        "      train_dataset = DateDataset(self.train_data, self.y)\n",
        "      train_loader = DataLoader(train_dataset,\n",
        "                                batch_size = self.batch_size,\n",
        "                                shuffle = True,\n",
        "                                collate_fn = self.collate_fn,\n",
        "                                num_workers = self.num_workers)\n",
        "\n",
        "      return train_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "vHtxahO54IfJ"
      },
      "outputs": [],
      "source": [
        "batch_size = 16\n",
        "data_module = DateDataModule(X, Y, batch_size=batch_size,num_workers=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFYhwzdj9gQG"
      },
      "source": [
        "## Attention Mechanism\n",
        "![attn_mech](https://raw.githubusercontent.com/ekapolc/nlp_2019/master/HW8/images/attn_mech.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ry5bLZjX4pwX"
      },
      "outputs": [],
      "source": [
        "def one_step_attention(h, s_prev, linear_1, linear_2):\n",
        "    #h.shape = batch, seq_len, hidden_dim\n",
        "    #s_prev.shape = batch, hidden_dim\n",
        "    # #linear_1 and linear_2 are linear layers in the model\n",
        "    s_prev = s_prev.unsqueeze(1).repeat((1, h.shape[1], 1))\n",
        "    concat = torch.cat([h, s_prev], dim=-1) #concat.shape = batch, seq_len, hidden_dim*2\n",
        "\n",
        "    #Attention function###\n",
        "    e = F.tanh(linear_1(concat))\n",
        "    energies = F.relu(linear_2(e))\n",
        "    # calculate attention_scores (softmax)\n",
        "    attention_scores = F.softmax(energies, dim=1)\n",
        "    # calculate a context vector\n",
        "    temp = torch.mul(attention_scores, h)\n",
        "    context = torch.sum(temp,dim=1)\n",
        "\n",
        "    return context"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qv475_JS9gQY"
      },
      "source": [
        "## The model\n",
        "![rnn_model](https://raw.githubusercontent.com/ekapolc/nlp_2019/master/HW8/images/rnn_date.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "C0PIR2vV4MLo"
      },
      "outputs": [],
      "source": [
        "class AttentionModel(L.LightningModule):\n",
        "    def __init__(self, learning_rate, criterion):\n",
        "\n",
        "        super().__init__()\n",
        "        self.n_h = 32 #hidden dimensions for encoder\n",
        "        self.n_s = 64 #hidden dimensions for decoder\n",
        "\n",
        "        self.learning_rate = learning_rate\n",
        "        self.criterion = criterion\n",
        "\n",
        "        #encoder\n",
        "        bidirection = True\n",
        "        self.num_directions = 2 if bidirection else 1\n",
        "        self.lstm = nn.LSTM(len(input_stoi), self.n_h, bidirectional=bidirection, batch_first=True)\n",
        "        #decoder\n",
        "        self.decoder_lstm_cell = nn.LSTMCell(self.n_s, self.n_s)\n",
        "        self.output_layer = nn.Linear(self.n_s, len(output_stoi))\n",
        "        #attention\n",
        "        self.fc1 = nn.Linear(self.n_h*2*self.num_directions, self.n_h)\n",
        "        self.fc2 = nn.Linear(self.n_h, 1)\n",
        "\n",
        "    def forward(self, src):\n",
        "        lstm_out, _ = self.lstm(src)\n",
        "\n",
        "        decoder_s = torch.randn(src.shape[0], self.n_s).to(self.decoder_lstm_cell.weight_ih.device)\n",
        "        decoder_c = torch.randn(src.shape[0], self.n_s).to(self.decoder_lstm_cell.weight_ih.device)\n",
        "\n",
        "        prediction = torch.zeros((src.shape[0], Ty, len(output_stoi))).to(self.decoder_lstm_cell.weight_ih.device)\n",
        "        #Iterate for Ty steps (Decoding)\n",
        "        for t in range(Ty):\n",
        "\n",
        "            #Perform one step of the attention mechanism to calculate the context vector at timestep t\n",
        "            context = one_step_attention(lstm_out, decoder_s, self.fc1, self.fc2)\n",
        "            # Feed the context vector to the decoder LSTM cell\n",
        "            decoder_s, decoder_c = self.decoder_lstm_cell(context, (decoder_s, decoder_c))\n",
        "\n",
        "            # Pass the decoder hidden output to the output layer (softmax)\n",
        "            out = self.output_layer(decoder_s)\n",
        "\n",
        "            # Append an output list with the current output\n",
        "            prediction[:, t] = out\n",
        "        return prediction\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        src = batch['x']\n",
        "        target = batch['y']\n",
        "        prediction = self(src)\n",
        "        prediction = prediction.reshape(-1, len(output_stoi))\n",
        "        target = target.reshape(-1)\n",
        "        loss = self.criterion(prediction, target)\n",
        "        self.log(\"train_loss\", loss)\n",
        "        return loss\n",
        "\n",
        "    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n",
        "        src = batch['x']\n",
        "        with torch.no_grad():\n",
        "          prediction = self(src)\n",
        "          prediction = F.softmax(prediction, dim=-1)\n",
        "          prediction = torch.argmax(prediction, dim=-1)\n",
        "          for pred in prediction:\n",
        "            print(output_decode(pred.cpu().numpy()))\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return optim.Adam(self.parameters(), lr=self.learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "d6VHTvyoFuxh"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "lr = 0.01\n",
        "model = AttentionModel(lr, criterion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "tYColP-nGW5q"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: True (mps), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "/Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n"
          ]
        }
      ],
      "source": [
        "trainer = Trainer(\n",
        "    max_epochs=10,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "rD1UelkcGZSh"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  | Name              | Type             | Params | Mode \n",
            "---------------------------------------------------------------\n",
            "0 | criterion         | CrossEntropyLoss | 0      | train\n",
            "1 | lstm              | LSTM             | 19.5 K | train\n",
            "2 | decoder_lstm_cell | LSTMCell         | 33.3 K | train\n",
            "3 | output_layer      | Linear           | 780    | train\n",
            "4 | fc1               | Linear           | 4.1 K  | train\n",
            "5 | fc2               | Linear           | 33     | train\n",
            "---------------------------------------------------------------\n",
            "57.7 K    Trainable params\n",
            "0         Non-trainable params\n",
            "57.7 K    Total params\n",
            "0.231     Total estimated model params size (MB)\n",
            "6         Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9: 100%|██████████| 938/938 [00:50<00:00, 18.60it/s, v_num=1]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9: 100%|██████████| 938/938 [00:50<00:00, 18.60it/s, v_num=1]\n"
          ]
        }
      ],
      "source": [
        "trainer.fit(model, data_module)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePf2CDQb9gQ-"
      },
      "source": [
        "## Let's do some \"translation\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "6stNACsUP9h-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8\n"
          ]
        }
      ],
      "source": [
        "EXAMPLES = ['Monday 15 March 2025', '3 May 1999', '05 October 2009', '30 August 2016', '11 July 2000', 'Saturday 19 May 2018', '3 March 2001', '1 March 2001']\n",
        "predict_data = []\n",
        "for line in EXAMPLES:\n",
        "    line = [l for l in line] #change from string to list\n",
        "    predict_data.append(torch.tensor(input_encode(line)))\n",
        "\n",
        "print(len(predict_data))\n",
        "def collate_fn(batch):\n",
        "    one_hot_x = torch.stack([F.one_hot(b[\"x\"], num_classes=len(input_stoi)) for b in batch])\n",
        "    return {\"x\": one_hot_x.float()}\n",
        "\n",
        "predict_data = nn.utils.rnn.pad_sequence(predict_data, batch_first = True)\n",
        "predict_dataset = DateDataset(predict_data, [torch.tensor(0)]*len(predict_data))\n",
        "predict_loader = DataLoader(predict_dataset,\n",
        "                          batch_size = 1,\n",
        "                          shuffle = False,\n",
        "                          collate_fn = collate_fn,\n",
        "                          num_workers = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "LsN71S9uQ9wo"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicting DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]2025-03-15\n",
            "Predicting DataLoader 0:  12%|█▎        | 1/8 [00:02<00:16,  0.42it/s]1999-05-33\n",
            "Predicting DataLoader 0:  25%|██▌       | 2/8 [00:02<00:07,  0.83it/s]2029-10-05\n",
            "Predicting DataLoader 0:  38%|███▊      | 3/8 [00:02<00:04,  1.24it/s]2016-08-30\n",
            "Predicting DataLoader 0:  50%|█████     | 4/8 [00:02<00:02,  1.64it/s]2000-07-11\n",
            "Predicting DataLoader 0:  62%|██████▎   | 5/8 [00:02<00:01,  2.03it/s]2018-05-19\n",
            "Predicting DataLoader 0:  75%|███████▌  | 6/8 [00:02<00:00,  2.42it/s]2001-03-33\n",
            "Predicting DataLoader 0:  88%|████████▊ | 7/8 [00:02<00:00,  2.81it/s]2001-03-11\n",
            "Predicting DataLoader 0: 100%|██████████| 8/8 [00:02<00:00,  3.19it/s]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages/lightning/pytorch/loops/prediction_loop.py:257: predict returned None if it was on purpose, ignore this warning...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[None, None, None, None, None, None, None, None]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.predict(model, predict_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfUmXr1D1ZSR"
      },
      "source": [
        "# Key-Value Attention for Thai Karaoke Character-level Machine Translation (Many-to-Many, encoder-decoder)\n",
        "\n",
        "In this homework, you will create an MT model with attention mechnism that coverts names of Thai 2019 MP candidates from Thai script to Roman(Latin) script. E.g. นิยม-->niyom\n",
        "\n",
        "The use of Pytorch Lightning is optional but recommended. You can use Pytorch if you prefer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "18KMSkqZ-Pt-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lightning in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (2.5.0.post0)\n",
            "Requirement already satisfied: wandb in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (0.19.1)\n",
            "Requirement already satisfied: PyYAML<8.0,>=5.4 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from lightning) (6.0.2)\n",
            "Requirement already satisfied: fsspec<2026.0,>=2022.5.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning) (2024.12.0)\n",
            "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from lightning) (0.11.9)\n",
            "Requirement already satisfied: packaging<25.0,>=20.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from lightning) (24.2)\n",
            "Requirement already satisfied: torch<4.0,>=2.1.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from lightning) (2.5.1)\n",
            "Requirement already satisfied: torchmetrics<3.0,>=0.7.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from lightning) (1.6.1)\n",
            "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from lightning) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<6.0,>=4.4.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from lightning) (4.12.2)\n",
            "Requirement already satisfied: pytorch-lightning in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from lightning) (2.5.0.post0)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from wandb) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from wandb) (5.29.2)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from wandb) (6.1.1)\n",
            "Requirement already satisfied: pydantic<3,>=2.6 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from wandb) (2.10.4)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from wandb) (2.19.2)\n",
            "Requirement already satisfied: setproctitle in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from wandb) (1.3.4)\n",
            "Requirement already satisfied: setuptools in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from wandb) (75.7.0)\n",
            "Requirement already satisfied: six>=1.4.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning) (3.11.11)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from pydantic<3,>=2.6->wandb) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (2024.12.14)\n",
            "Requirement already satisfied: filelock in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from torch<4.0,>=2.1.0->lightning) (3.16.1)\n",
            "Requirement already satisfied: networkx in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from torch<4.0,>=2.1.0->lightning) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from torch<4.0,>=2.1.0->lightning) (3.1.5)\n",
            "Requirement already satisfied: sympy==1.13.1 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from torch<4.0,>=2.1.0->lightning) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from sympy==1.13.1->torch<4.0,>=2.1.0->lightning) (1.3.0)\n",
            "Requirement already satisfied: numpy>1.20.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from torchmetrics<3.0,>=0.7.0->lightning) (2.2.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.18.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from jinja2->torch<4.0,>=2.1.0->lightning) (3.0.2)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "--2025-01-20 17:52:30--  https://github.com/Phonbopit/sarabun-webfont/raw/master/fonts/thsarabunnew-webfont.ttf\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/Phonbopit/sarabun-webfont/master/fonts/thsarabunnew-webfont.ttf [following]\n",
            "--2025-01-20 17:52:30--  https://raw.githubusercontent.com/Phonbopit/sarabun-webfont/master/fonts/thsarabunnew-webfont.ttf\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 98308 (96K) [application/octet-stream]\n",
            "Saving to: ‘thsarabunnew-webfont.ttf.1’\n",
            "\n",
            "thsarabunnew-webfon 100%[===================>]  96.00K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2025-01-20 17:52:30 (3.23 MB/s) - ‘thsarabunnew-webfont.ttf.1’ saved [98308/98308]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!pip install lightning wandb\n",
        "!wget https://github.com/Phonbopit/sarabun-webfont/raw/master/fonts/thsarabunnew-webfont.ttf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import wandb\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKCBCWKARZEx",
        "outputId": "6ad8a585-fd68-44ee-deac-37143137cbcc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /Users/idhibhatpankam/.netrc\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# !wandb login\n",
        "api_key = os.getenv(\"WANDB_API_KEY\")\n",
        "wandb.login(key=api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ka2TN8IV1ZSU"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "mpl.font_manager.fontManager.addfont('thsarabunnew-webfont.ttf') # 3.2+\n",
        "mpl.rc('font', family='TH Sarabun New')\n",
        "import torch\n",
        "# import torchtext\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import lightning as L\n",
        "import numpy as np\n",
        "\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-f_s6vX1ZSZ"
      },
      "source": [
        "## Load Dataset\n",
        "We have generated a toy dataset using names of Thai MP candidates in 2019 Thai General Election from elect.in.th's github(https://github.com/codeforthailand/dataset-election-62-candidates) and tltk (https://pypi.org/project/tltk/) library to convert them into Roman script.\n",
        "\n",
        "```\n",
        "ไกรสีห์ kraisi\n",
        "พัชรี phatri\n",
        "ธีระ thira\n",
        "วุฒิกร wutthikon\n",
        "ไสว sawai\n",
        "สัมภาษณ์  samphat\n",
        "วศิน wasin\n",
        "ทินวัฒน์ thinwat\n",
        "ศักดินัย sakdinai\n",
        "สุรศักดิ์ surasak\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jte-Csrf-4kd",
        "outputId": "a1ba364b-64c2-4875-873c-90bc1808a4be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-01-20 17:56:09--  https://raw.githubusercontent.com/ekapolc/nlp_2019/master/HW8/mp_name_th_en.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 324399 (317K) [text/plain]\n",
            "Saving to: ‘mp_name_th_en.csv’\n",
            "\n",
            "mp_name_th_en.csv   100%[===================>] 316.80K  --.-KB/s    in 0.08s   \n",
            "\n",
            "2025-01-20 17:56:09 (3.83 MB/s) - ‘mp_name_th_en.csv’ saved [324399/324399]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/ekapolc/nlp_2019/master/HW8/mp_name_th_en.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 211,
      "metadata": {
        "id": "L9zXp7KH1ZSa"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "with open('mp_name_th_en.csv') as csvfile:\n",
        "    readCSV = csv.reader(csvfile, delimiter=',')\n",
        "    name_th = []\n",
        "    name_en = []\n",
        "    for row in readCSV:\n",
        "        temp_th = row[0]\n",
        "        temp_en = row[1]\n",
        "\n",
        "        name_th.append(temp_th)\n",
        "        name_en.append(temp_en)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 212,
      "metadata": {
        "id": "ZCsqrXxu1ZSe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ไกรสีห์ kraisi\n",
            "พัชรี phatri\n",
            "ธีระ thira\n",
            "วุฒิกร wutthikon\n",
            "ไสว sawai\n",
            "สัมภาษณ์  samphat\n",
            "วศิน wasin\n",
            "ทินวัฒน์ thinwat\n",
            "ศักดินัย sakdinai\n",
            "สุรศักดิ์ surasak\n"
          ]
        }
      ],
      "source": [
        "for th, en in zip(name_th[:10],name_en[:10]):\n",
        "    print(th,en)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvW8xqT81ZSh"
      },
      "source": [
        "## TODO1: Preprocess dataset\n",
        "* You will need 2 vocabularies (1 for input and another for output)\n",
        "* DON'T FORGET TO INCLUDE special token for padding (for both input and output)\n",
        "* DON'T FORGET TO INCLUDE special token for the end of word symbol (output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 213,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rv1Xd9A1ZSi",
        "outputId": "dece74ae-a492-41a7-f07d-2798157c7fcc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 10887 lines and 65 unique characters in your input data.\n"
          ]
        }
      ],
      "source": [
        "#Preprocessing\n",
        "input_chars = list(set(''.join(name_th)))\n",
        "output_chars = list(set(''.join(name_en)))\n",
        "data_size, vocab_size = len(name_th), len(input_chars)+1\n",
        "output_vocab_size = len(output_chars)+2#+2 for special end of sentence token/PADDING\n",
        "print('There are %d lines and %d unique characters in your input data.' % (data_size, vocab_size))\n",
        "maxlen = len( max(name_th, key=len)) #max input length\n",
        "maxlen_out = len( max(name_en, key=len)) #max input length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 214,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mo381I_t1ZSm",
        "outputId": "4467516a-90c8-477d-bc43-bb071b17a956"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Max input length: 20\n",
            "Max output length: 19\n"
          ]
        }
      ],
      "source": [
        "print(\"Max input length:\", maxlen)\n",
        "print(\"Max output length:\", maxlen_out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 302,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[59, 3, 35, 40, 50, 41, 65]\n",
            "ไกรสีห์\n"
          ]
        }
      ],
      "source": [
        "sorted_chars = sorted(input_chars)\n",
        "sorted_chars.insert(0, \"<PAD>\")\n",
        "# sorted_chars.insert(1, \"</s>\")\n",
        "\n",
        "sorted_output_chars = sorted(output_chars)\n",
        "sorted_output_chars.insert(0, \"<PAD>\")\n",
        "sorted_output_chars.insert(1, \"</s>\")\n",
        "\n",
        "input_stoi = { c:i for i, c in enumerate(sorted_chars) }\n",
        "input_itos = { i:c for i, c in enumerate(sorted_chars)}\n",
        "input_encode = lambda sentence: [input_stoi[c] for c in sentence]\n",
        "input_decode = lambda encoding: \"\".join([input_itos[i] for i in encoding])\n",
        "\n",
        "output_stoi = { c:i for i, c in enumerate(sorted_output_chars) }\n",
        "output_itos = { i:c for i, c in enumerate(sorted_output_chars)}\n",
        "output_encode = lambda sentence: [output_stoi[c] for c in sentence]\n",
        "output_decode = lambda encoding: \"\".join([output_itos[i] for i in encoding])\n",
        "\n",
        "print(input_encode(name_th[0]))\n",
        "print(input_decode(input_encode(name_th[0])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 303,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "66 {'<PAD>': 0, '</s>': 1, ' ': 2, 'ก': 3, 'ข': 4, 'ค': 5, 'ฆ': 6, 'ง': 7, 'จ': 8, 'ฉ': 9, 'ช': 10, 'ซ': 11, 'ฌ': 12, 'ญ': 13, 'ฎ': 14, 'ฏ': 15, 'ฐ': 16, 'ฑ': 17, 'ฒ': 18, 'ณ': 19, 'ด': 20, 'ต': 21, 'ถ': 22, 'ท': 23, 'ธ': 24, 'น': 25, 'บ': 26, 'ป': 27, 'ผ': 28, 'ฝ': 29, 'พ': 30, 'ฟ': 31, 'ภ': 32, 'ม': 33, 'ย': 34, 'ร': 35, 'ล': 36, 'ว': 37, 'ศ': 38, 'ษ': 39, 'ส': 40, 'ห': 41, 'ฬ': 42, 'อ': 43, 'ฮ': 44, 'ะ': 45, 'ั': 46, 'า': 47, 'ำ': 48, 'ิ': 49, 'ี': 50, 'ึ': 51, 'ื': 52, 'ุ': 53, 'ู': 54, 'เ': 55, 'แ': 56, 'โ': 57, 'ใ': 58, 'ไ': 59, '็': 60, '่': 61, '้': 62, '๊': 63, '๋': 64, '์': 65}\n",
            "23 {'<PAD>': 0, '-': 1, 'a': 2, 'b': 3, 'c': 4, 'd': 5, 'e': 6, 'f': 7, 'g': 8, 'h': 9, 'i': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'r': 17, 's': 18, 't': 19, 'u': 20, 'w': 21, 'y': 22}\n"
          ]
        }
      ],
      "source": [
        "print(len(input_stoi), input_stoi)\n",
        "print(len(output_stoi), output_stoi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 217,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = []\n",
        "for line in name_th:\n",
        "    X.append(torch.tensor(input_encode(line)))\n",
        "Y = []\n",
        "for line in name_en:\n",
        "    Y.append(torch.tensor(output_encode(line)))\n",
        "\n",
        "X = nn.utils.rnn.pad_sequence(X, batch_first=True)\n",
        "Y = nn.utils.rnn.pad_sequence(Y, batch_first=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 310,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([10887, 20]), torch.Size([10887, 19]))"
            ]
          },
          "execution_count": 310,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.shape, Y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 311,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([58,  2, 34, 39, 49, 40, 64,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0]),\n",
              " tensor([12, 18,  3, 11, 19, 11,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0]))"
            ]
          },
          "execution_count": 311,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X[0], Y[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 312,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "19"
            ]
          },
          "execution_count": 312,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Ty = len(max(Y, key=len))\n",
        "Ty"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 313,
      "metadata": {
        "id": "W3aXyJBEC-j_"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.types import Tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 314,
      "metadata": {
        "id": "-yirzlseC9NS"
      },
      "outputs": [],
      "source": [
        "class NameDataset(Dataset):\n",
        "  def __init__(self, X, y):\n",
        "    self.encoded = X.long()\n",
        "    self.label = y.long()\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return {\"x\": self.encoded[idx], \"y\": self.label[idx]}\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 315,
      "metadata": {
        "id": "qUPAB7LTDFOy"
      },
      "outputs": [],
      "source": [
        "class NameDataModule(L.LightningDataModule):\n",
        "\n",
        "  def __init__(self, train_data, y, batch_size, num_workers=0):\n",
        "      super().__init__()\n",
        "      self.train_data = train_data\n",
        "      self.y = y\n",
        "      self.batch_size = batch_size\n",
        "      self.num_workers = num_workers\n",
        "\n",
        "\n",
        "  def setup(self, stage: str):\n",
        "    pass\n",
        "\n",
        "  def collate_fn(self, batch):\n",
        "    one_hot_x = torch.stack([F.one_hot(b[\"x\"], num_classes=len(input_stoi)) for b in batch])\n",
        "    return {\"x\": one_hot_x.float(), \"y\": torch.stack([b[\"y\"] for b in batch])}\n",
        "\n",
        "  def train_dataloader(self):\n",
        "    train_dataset = NameDataset(self.train_data, self.y)\n",
        "    train_loader = DataLoader(train_dataset,\n",
        "                              batch_size=self.batch_size,\n",
        "                              shuffle=True,\n",
        "                              collate_fn=self.collate_fn,\n",
        "                              num_workers=self.num_workers)\n",
        "    return train_loader\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFSG1FqK1ZSy"
      },
      "source": [
        "# Attention Mechanism\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAlOrhbismQp"
      },
      "source": [
        "## TODO 2: Code your own (key-value) attention mechnism\n",
        "* PLEASE READ: you DO NOT have to follow all the details in (Daniluk, et al. 2017). You just need to create a key-value attention mechanism where the \"key\" part of the mechanism is used for attention score calculation, and the \"value\" part of the mechanism is used to encode information to create a context vector.  \n",
        "* fill code for one_step_attention function\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 316,
      "metadata": {
        "id": "avnlc6p9BZDv"
      },
      "outputs": [],
      "source": [
        "def one_step_attention(h: Tensor, s_prev: Tensor, linear_1: nn.Linear, linear_2: nn.Linear):\n",
        "    # (enc) h.shape = batch, seq_len, hidden_dim\n",
        "    # (dec) s_prev.shape = batch, hidden_dim\n",
        "    # print(f\"h.shape: {h.shape}, s_prev.shape: {s_prev.shape}\")\n",
        "\n",
        "    # Split into Key-Value\n",
        "    hidden_dim = h.shape[-1]\n",
        "    key_dim, value_dim = hidden_dim // 2, hidden_dim // 2\n",
        "    key, value = torch.split(h, [key_dim, value_dim], dim=-1)\n",
        "    # key: (batch, seq_len, key_dim), value: (batch, seq_len, value_dim)\n",
        "\n",
        "    seq_len = key.shape[1]\n",
        "    # unsqueeze: (batch, hidden_dim) -> (batch, 1, hidden_dim)\n",
        "    # repeat: (batch, 1, hidden_dim) -> (batch, seq_len, hidden_dim)\n",
        "    s_prev = s_prev.unsqueeze(1).repeat(1, seq_len, 1)\n",
        "\n",
        "    # do concat with s_prev.\n",
        "    concat = torch.cat([key, s_prev], dim=-1) # (batch, seq_len, key_dim + hidden_dim)\n",
        "    # print(f\"concat.shape: {concat.shape}\")\n",
        "\n",
        "    # hint: you will need to use s_prev.repeat(...) somehow so that it has the same dimension as the key\n",
        "    # hint2: s_prev.unsqueeze() could also be useful\n",
        "\n",
        "    # Attention function\n",
        "    # use layer(s) from your model to calculate attention_scores and then softmax\n",
        "    # calculate a context vector\n",
        "    e = F.tanh(linear_1(concat))\n",
        "    # print(f\"e.shape: {e.shape}\")\n",
        "    energies = F.relu(linear_2(e))\n",
        "    # print(f\"e.shape: {e.shape}, energies.shape: {energies.shape}\")\n",
        "    attention_scores = F.softmax(energies, dim=1)\n",
        "    context = torch.sum(attention_scores * value, dim=1)\n",
        "    # print(f\"context: {context.shape}, attention_scores.shape: {attention_scores.shape}, value.shape: {value.shape}\")\n",
        "\n",
        "    return context, attention_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zWN02ZtuOIU"
      },
      "source": [
        "# Translation Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0phyUQYg1ZS8"
      },
      "source": [
        "## TODO3: Create and train your encoder/decoder model here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 317,
      "metadata": {
        "id": "Ji_rUPhK1ZS9"
      },
      "outputs": [],
      "source": [
        "output_vocab = output_stoi\n",
        "class AttentionModel(L.LightningModule):\n",
        "    def __init__(self, learning_rate, criterion):\n",
        "\n",
        "        super().__init__()\n",
        "        self.n_h = 32 # hidden dimensions for encoder\n",
        "        self.n_s = 64 # hidden dimensions for decoder\n",
        "        self.learning_rate = learning_rate\n",
        "        self.criterion = criterion\n",
        "\n",
        "        #encoder can be any RNN of your choice\n",
        "        bidirection = True\n",
        "        self.num_directions = 2 if bidirection else 1\n",
        "        self.lstm = nn.LSTM(len(input_stoi), self.n_h, bidirectional=bidirection, batch_first=True)\n",
        "\n",
        "        #decoder has to be (any) RNNCell since we will need to calculate attention for each timestep manually\n",
        "        self.decoder_lstm_cell = nn.LSTMCell(self.n_s // 2, self.n_s)\n",
        "        # self.decoder_lstm_cell = nn.LSTMCell(self.n_s, self.n_s)\n",
        "        self.output_layer = nn.Linear(self.n_s, len(output_vocab))\n",
        "        \n",
        "        #attention\n",
        "        self.fc1 = nn.Linear(self.n_h*self.num_directions*3//2, self.n_h)\n",
        "        self.fc2 = nn.Linear(self.n_h, 1)\n",
        "\n",
        "    def forward(self, src, return_attention=False): \n",
        "        # use return_attention only when you want to get the attention scores for visualizing\n",
        "        # pass the input to the encoder\n",
        "        lstm_out, _ = self.lstm(src)\n",
        "        # print(f\"lstm_out.shape: {lstm_out.shape}, fc1.weight.shape: {self.fc1.weight.shape}, fc2.weight.shape: {self.fc2.weight.shape}\")\n",
        "\n",
        "        # Initialize the LSTM states. We have to do this since we are using LSTMCell (https://pytorch.org/docs/stable/generated/torch.nn.LSTMCell.html)\n",
        "        # These states will get updated while we are decoding\n",
        "        decoder_s = torch.randn(src.shape[0], self.n_s).to(self.decoder_lstm_cell.weight_ih.device)\n",
        "        decoder_c = torch.randn(src.shape[0], self.n_s).to(self.decoder_lstm_cell.weight_ih.device)\n",
        "\n",
        "        # Iterate until max_output_length (Decoding)\n",
        "        prediction = torch.zeros((src.shape[0], Ty, len(output_vocab))).to(self.decoder_lstm_cell.weight_ih.device)\n",
        "        attention_scores = [] # to store the score for each step\n",
        "        for t in range(Ty):\n",
        "            # Perform one step of the attention mechanism to calculate the context vector at timestep t\n",
        "            context, attention_score = one_step_attention(lstm_out, decoder_s, self.fc1, self.fc2)\n",
        "\n",
        "            # Feed the context vector to the decoder.\n",
        "            # print(f\"decoder_s.shape: {decoder_s.shape}, decoder_c.shape: {decoder_c.shape}, lstm_cell.shape: {self.decoder_lstm_cell.weight_ih.shape}\")\n",
        "            decoder_s, decoder_c = self.decoder_lstm_cell(context, (decoder_s, decoder_c))\n",
        "\n",
        "            # Pass the decoder hidden output to the output layer (softmax)\n",
        "            out = self.output_layer(decoder_s)\n",
        "\n",
        "            # Put the predicted output into the list for this timestep\n",
        "            prediction[:, t] = out\n",
        "\n",
        "            attention_scores.append(attention_score)\n",
        "\n",
        "        return (prediction, attention_scores if return_attention else None)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        src = batch['x']\n",
        "        target = batch['y']\n",
        "        prediction,_ = self(src)\n",
        "        prediction = prediction.reshape(-1, len(output_vocab))\n",
        "        target = target.reshape(-1)\n",
        "        loss = self.criterion(prediction, target)\n",
        "        self.log(\"train_loss\", loss)\n",
        "        return loss\n",
        "\n",
        "    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n",
        "        src = batch['x']\n",
        "        with torch.no_grad():\n",
        "          prediction, attention_scores = self(src, return_attention=True)\n",
        "          prediction = F.softmax(prediction, dim=-1)\n",
        "          prediction = torch.argmax(prediction, dim=-1)\n",
        "          for pred in prediction:\n",
        "            print(\"\".join(output_decode(pred.cpu().numpy())))\n",
        "            # print(\"\".join(output_vocab.lookup_tokens(pred.cpu().numpy())))\n",
        "        return prediction, attention_scores\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return optim.Adam(self.parameters(), lr=self.learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 226,
      "metadata": {
        "id": "RqrvmJalDLzF"
      },
      "outputs": [],
      "source": [
        "data_module = NameDataModule(X, Y, batch_size=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 227,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages/lightning/pytorch/core/module.py:441: You are trying to `self.log()` but the `self.trainer` reference is not registered on the model yet. This is most likely because the model hasn't been passed to the `Trainer`\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor(3.2289, grad_fn=<NllLossBackward0>)"
            ]
          },
          "execution_count": 227,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mock_data = NameDataset(X, Y)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "lr = 0.01\n",
        "mock_model = AttentionModel(lr, criterion)\n",
        "mock_batch = next(iter(data_module.train_dataloader()))\n",
        "mock_model.training_step(mock_batch, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 228,
      "metadata": {
        "id": "pSM9dgDcCz1E"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "lr = 0.01\n",
        "model = AttentionModel(lr, criterion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 229,
      "metadata": {
        "id": "_sFjzKX8SECo"
      },
      "outputs": [],
      "source": [
        "from lightning import Trainer\n",
        "from lightning.pytorch.loggers import WandbLogger\n",
        "wandb_logger = WandbLogger(project=\"hw3.1_attention\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 230,
      "metadata": {
        "id": "OGWSzS-X1ZTO"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: True (mps), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n"
          ]
        }
      ],
      "source": [
        "trainer = L.Trainer(\n",
        "    max_epochs=100,\n",
        "    logger=wandb_logger\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 236,
      "metadata": {
        "id": "7ZMi782c1ZTQ"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  | Name              | Type             | Params | Mode\n",
            "--------------------------------------------------------------\n",
            "0 | criterion         | CrossEntropyLoss | 0      | eval\n",
            "1 | lstm              | LSTM             | 25.3 K | eval\n",
            "2 | decoder_lstm_cell | LSTMCell         | 25.1 K | eval\n",
            "3 | output_layer      | Linear           | 1.6 K  | eval\n",
            "4 | fc1               | Linear           | 3.1 K  | eval\n",
            "5 | fc2               | Linear           | 33     | eval\n",
            "--------------------------------------------------------------\n",
            "55.1 K    Trainable params\n",
            "0         Non-trainable params\n",
            "55.1 K    Total params\n",
            "0.221     Total estimated model params size (MB)\n",
            "0         Modules in train mode\n",
            "6         Modules in eval mode\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 86:   6%|▌         | 39/681 [02:03<33:51,  0.32it/s, v_num=7l44]\n",
            "Epoch 99: 100%|██████████| 681/681 [00:58<00:00, 11.69it/s, v_num=7l44]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 99: 100%|██████████| 681/681 [00:58<00:00, 11.69it/s, v_num=7l44]\n"
          ]
        }
      ],
      "source": [
        "trainer.fit(model, data_module)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5BLw1Ir1ZTT"
      },
      "source": [
        "# Test Your Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRLjZzBMtCdA"
      },
      "source": [
        "## TODO4: Test your model on 5 examples of your choice including your name!\n",
        "\n",
        "Example Output:\n",
        "```\n",
        "prayutthatha</s></s>aa</s></s>a</s>\n",
        "somchai</s></s></s></s>a</s></s>a</s></s></s></s></s>\n",
        "thanathon</s></s></s></s></s></s></s></s></s></s></s>\n",
        "newin</s>i</s></s></s></s></s></s></s></s></s></s></s></s></s>\n",
        "suthep</s>he</s></s></s></s></s></s></s></s></s></s></s>\n",
        "prawit</s></s></s></s></s></s></s></s></s></s></s></s></s></s>\n",
        "chatchachatti</s></s>i</s></s></s></s>\n",
        "```\n",
        "\n",
        "<font color='blue'>Paste your model predictions in MyCourseVille</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 318,
      "metadata": {},
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "lr = 0.01\n",
        "model = AttentionModel.load_from_checkpoint(\"./hw3.1_attention/r6ga7l44/checkpoints/epoch=99-step=68192-nos.ckpt\", learning_rate=lr, criterion=criterion)\n",
        "# model = AttentionModel.load_from_checkpoint(\"./hw3.1_attention/r6ga7l44/checkpoints/epoch=99-step=68163.ckpt\", learning_rate=lr, criterion=criterion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 319,
      "metadata": {
        "id": "6stNACsUP9h-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8\n"
          ]
        }
      ],
      "source": [
        "EXAMPLES = ['ประยุทธ์','สมชาย','ธนาธร','เนวิน','สุเทพ','ประวิตร์','ชัชชาติ','อิทธิพัฒน์']\n",
        "predict_data = []\n",
        "for line in EXAMPLES:\n",
        "    line = [l for l in line] #change from string to list\n",
        "    predict_data.append(torch.tensor(input_encode(line)))\n",
        "\n",
        "print(len(predict_data))\n",
        "def collate_fn(batch):\n",
        "    one_hot_x = torch.stack([F.one_hot(b[\"x\"], num_classes=len(input_stoi)) for b in batch])\n",
        "    return {\"x\": one_hot_x.float()}\n",
        "\n",
        "predict_data = nn.utils.rnn.pad_sequence(predict_data, batch_first = True)\n",
        "predict_dataset = NameDataset(predict_data, torch.tensor([torch.tensor(0)]*len(predict_data)))\n",
        "predict_loader = DataLoader(predict_dataset,\n",
        "                          batch_size = 1,\n",
        "                          shuffle = False,\n",
        "                          collate_fn = collate_fn,\n",
        "                          num_workers = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 320,
      "metadata": {
        "id": "kbolC8XIhR3t"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AttentionModel(\n",
              "  (criterion): CrossEntropyLoss()\n",
              "  (lstm): LSTM(66, 32, batch_first=True, bidirectional=True)\n",
              "  (decoder_lstm_cell): LSTMCell(32, 64)\n",
              "  (output_layer): Linear(in_features=64, out_features=23, bias=True)\n",
              "  (fc1): Linear(in_features=96, out_features=32, bias=True)\n",
              "  (fc2): Linear(in_features=32, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 320,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 321,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicting DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]prayut<PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
            "Predicting DataLoader 0:  12%|█▎        | 1/8 [00:00<00:00, 27.91it/s]somchai<PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
            "Predicting DataLoader 0:  25%|██▌       | 2/8 [00:00<00:00, 13.66it/s]thanathon<PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
            "Predicting DataLoader 0:  38%|███▊      | 3/8 [00:00<00:00, 17.27it/s]nawin<PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
            "Predicting DataLoader 0:  50%|█████     | 4/8 [00:00<00:00, 19.62it/s]suthep<PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
            "Predicting DataLoader 0:  62%|██████▎   | 5/8 [00:00<00:00, 21.51it/s]prawit<PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
            "Predicting DataLoader 0:  75%|███████▌  | 6/8 [00:00<00:00, 22.73it/s]chatchachatti<PAD><PAD><PAD><PAD><PAD><PAD>\n",
            "Predicting DataLoader 0:  88%|████████▊ | 7/8 [00:00<00:00, 23.99it/s]itthiphattha<PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
            "Predicting DataLoader 0: 100%|██████████| 8/8 [00:00<00:00, 24.73it/s]\n"
          ]
        }
      ],
      "source": [
        "output = trainer.predict(model, predict_loader)\n",
        "\n",
        "prediction, attention_scores = zip(*output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 322,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: ประยุทธ์\n",
            "Output: prayut<PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
            "\n",
            "Input: สมชาย\n",
            "Output: somchai<PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
            "\n",
            "Input: ธนาธร\n",
            "Output: thanathon<PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
            "\n",
            "Input: เนวิน\n",
            "Output: nawin<PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
            "\n",
            "Input: สุเทพ\n",
            "Output: suthep<PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
            "\n",
            "Input: ประวิตร์\n",
            "Output: prawit<PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
            "\n",
            "Input: ชัชชาติ\n",
            "Output: chatchachatti<PAD><PAD><PAD><PAD><PAD><PAD>\n",
            "\n",
            "Input: อิทธิพัฒน์\n",
            "Output: itthiphattha<PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# prediction\n",
        "for pred, label in zip(prediction, EXAMPLES):\n",
        "    print(\"Input:\", label)\n",
        "    print(\"Output:\", \"\".join(output_decode([p for p in pred.cpu().numpy()[0]])))\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7o3893RL1ZT8"
      },
      "source": [
        "## TODO 5: Show your visualization of attention scores on one of your example\n",
        "\n",
        "<font color='blue'>Paste your visualization image in MyCourseVille</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 323,
      "metadata": {
        "id": "WHysSqYJ1ZUA"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: seaborn in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (0.13.2)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from seaborn) (2.2.1)\n",
            "Requirement already satisfied: pandas>=1.2 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from seaborn) (2.2.3)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from seaborn) (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from pandas>=1.2->seaborn) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from pandas>=1.2->seaborn) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "!pip install seaborn\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 328,
      "metadata": {
        "id": "XdktVnMv1ZTh"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6 19 torch.Size([1, 10, 1])\n",
            "(19, 10), (characters, attn to other characters)\n",
            "['p', 'r', 'a', 'y', 'u', 't', '<PAD>'] ['ป', 'ร', 'ะ', 'ย', 'ุ', 'ท', 'ธ', '์', '<PAD>']\n",
            "(9, 7) 8 6\n",
            "[[1.00000000e+00 2.47471128e-08 5.12847577e-13 1.44119376e-13\n",
            "  6.48376413e-14 6.16388247e-14 1.35125513e-13]\n",
            " [1.59105156e-02 9.82788026e-01 7.67192629e-04 9.48310480e-05\n",
            "  9.14632164e-06 2.97572733e-05 1.56889382e-05]\n",
            " [1.51827587e-02 3.63722742e-01 4.92217332e-01 9.71563533e-02\n",
            "  5.07918932e-03 2.46491167e-03 6.03888091e-03]\n",
            " [1.23585798e-02 4.23674919e-02 1.45891055e-01 6.02859139e-01\n",
            "  1.05935045e-01 3.72075588e-02 8.97136703e-03]\n",
            " [4.80735907e-03 2.45150868e-02 1.30463634e-02 7.07473159e-02\n",
            "  6.95244312e-01 1.58690676e-01 7.98849389e-03]\n",
            " [1.18507138e-02 1.47663541e-02 1.51386885e-02 3.10513172e-02\n",
            "  4.08705585e-02 7.10517287e-01 9.43935513e-02]\n",
            " [6.63872808e-03 6.30451227e-03 5.38905943e-03 2.38363128e-02\n",
            "  3.04471273e-02 1.59981921e-01 3.18440109e-01]\n",
            " [3.09308642e-03 2.99495598e-03 1.35496855e-02 1.25603639e-02\n",
            "  3.98966391e-03 9.14090574e-02 2.63271779e-01]\n",
            " [3.81421670e-03 2.06204038e-02 4.47481219e-03 3.94402444e-03\n",
            "  3.94395692e-03 8.92063882e-03 1.81137875e-01]]\n"
          ]
        }
      ],
      "source": [
        "# prediction, attention_scores = zip(*output)\n",
        "sample_pred = prediction[0]\n",
        "sample_pred = [p for p in sample_pred.cpu().numpy().tolist()[0] if p != 0]\n",
        "sample_attention_scores = attention_scores[0]\n",
        "# print(sample_attention_scores[0])\n",
        "print(len(sample_pred), len(sample_attention_scores), sample_attention_scores[0].shape)\n",
        "\n",
        "attn_viz = torch.stack(sample_attention_scores).squeeze().cpu().numpy()\n",
        "print(f\"{attn_viz.shape}, (characters, attn to other characters)\")\n",
        "attn_viz = attn_viz[:len(EXAMPLES[0])+1, :len(sample_pred)+1]\n",
        "# swap axes to have the same order as the input\n",
        "# attn_viz = np.swapaxes(attn_viz, 0, 1)\n",
        "output_text = [c for c in output_decode(sample_pred)]\n",
        "output_text.append(\"<PAD>\")\n",
        "xlabels = [c for c in EXAMPLES[0]]\n",
        "xlabels.append(\"<PAD>\")\n",
        "print(output_text, xlabels)\n",
        "print(attn_viz.shape, len(EXAMPLES[0]), len(sample_pred))\n",
        "print(attn_viz)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 329,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "ax = sns.heatmap(attn_viz, linewidth=0.5)\n",
        "ax.set_xticklabels(output_text,rotation=30)\n",
        "ax.set_yticklabels(xlabels,rotation=60)\n",
        "# ax.set_yticklabels(output_text,rotation=30)\n",
        "# ax.set_xticklabels(xlabels,rotation=60)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "BF6HD99lYlgQ",
        "outputId": "caaa0716-5b99-43e8-950f-dd0127d0fbb7"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "ax = sns.heatmap(attn_viz, linewidth=0.5)\n",
        "ax.set_yticklabels(output_text,rotation=30)\n",
        "ax.set_xticklabels(xlabels,rotation=60)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1UkIsCztaMS"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

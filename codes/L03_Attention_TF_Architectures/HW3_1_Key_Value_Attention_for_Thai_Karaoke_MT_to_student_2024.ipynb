{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfUmXr1D1ZSR"
      },
      "source": [
        "# Key-Value Attention for Thai Karaoke Character-level Machine Translation (Many-to-Many, encoder-decoder)\n",
        "\n",
        "In this homework, you will create an MT model with attention mechnism that coverts names of Thai 2019 MP candidates from Thai script to Roman(Latin) script. E.g. นิยม-->niyom\n",
        "\n",
        "The use of Pytorch Lightning is optional but recommended. You can use Pytorch if you prefer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "18KMSkqZ-Pt-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lightning in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (2.5.0.post0)\n",
            "Requirement already satisfied: wandb in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (0.19.1)\n",
            "Requirement already satisfied: PyYAML<8.0,>=5.4 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from lightning) (6.0.2)\n",
            "Requirement already satisfied: fsspec<2026.0,>=2022.5.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning) (2024.12.0)\n",
            "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from lightning) (0.11.9)\n",
            "Requirement already satisfied: packaging<25.0,>=20.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from lightning) (24.2)\n",
            "Requirement already satisfied: torch<4.0,>=2.1.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from lightning) (2.5.1)\n",
            "Requirement already satisfied: torchmetrics<3.0,>=0.7.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from lightning) (1.6.1)\n",
            "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from lightning) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<6.0,>=4.4.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from lightning) (4.12.2)\n",
            "Requirement already satisfied: pytorch-lightning in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from lightning) (2.5.0.post0)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from wandb) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from wandb) (5.29.2)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from wandb) (6.1.1)\n",
            "Requirement already satisfied: pydantic<3,>=2.6 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from wandb) (2.10.4)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from wandb) (2.19.2)\n",
            "Requirement already satisfied: setproctitle in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from wandb) (1.3.4)\n",
            "Requirement already satisfied: setuptools in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from wandb) (75.7.0)\n",
            "Requirement already satisfied: six>=1.4.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning) (3.11.11)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from pydantic<3,>=2.6->wandb) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (2024.12.14)\n",
            "Requirement already satisfied: filelock in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from torch<4.0,>=2.1.0->lightning) (3.16.1)\n",
            "Requirement already satisfied: networkx in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from torch<4.0,>=2.1.0->lightning) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from torch<4.0,>=2.1.0->lightning) (3.1.5)\n",
            "Requirement already satisfied: sympy==1.13.1 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from torch<4.0,>=2.1.0->lightning) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from sympy==1.13.1->torch<4.0,>=2.1.0->lightning) (1.3.0)\n",
            "Requirement already satisfied: numpy>1.20.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from torchmetrics<3.0,>=0.7.0->lightning) (2.2.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.18.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/idhibhatpankam/Code/courses/NLP-SYS/.venv/lib/python3.12/site-packages (from jinja2->torch<4.0,>=2.1.0->lightning) (3.0.2)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "--2025-01-20 17:52:30--  https://github.com/Phonbopit/sarabun-webfont/raw/master/fonts/thsarabunnew-webfont.ttf\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/Phonbopit/sarabun-webfont/master/fonts/thsarabunnew-webfont.ttf [following]\n",
            "--2025-01-20 17:52:30--  https://raw.githubusercontent.com/Phonbopit/sarabun-webfont/master/fonts/thsarabunnew-webfont.ttf\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 98308 (96K) [application/octet-stream]\n",
            "Saving to: ‘thsarabunnew-webfont.ttf.1’\n",
            "\n",
            "thsarabunnew-webfon 100%[===================>]  96.00K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2025-01-20 17:52:30 (3.23 MB/s) - ‘thsarabunnew-webfont.ttf.1’ saved [98308/98308]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!pip install lightning wandb\n",
        "!wget https://github.com/Phonbopit/sarabun-webfont/raw/master/fonts/thsarabunnew-webfont.ttf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import wandb\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKCBCWKARZEx",
        "outputId": "6ad8a585-fd68-44ee-deac-37143137cbcc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /Users/idhibhatpankam/.netrc\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# !wandb login\n",
        "api_key = os.getenv(\"WANDB_API_KEY\")\n",
        "wandb.login(key=api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ka2TN8IV1ZSU"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "mpl.font_manager.fontManager.addfont('thsarabunnew-webfont.ttf') # 3.2+\n",
        "mpl.rc('font', family='TH Sarabun New')\n",
        "import torch\n",
        "# import torchtext\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import lightning as L\n",
        "import numpy as np\n",
        "\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-f_s6vX1ZSZ"
      },
      "source": [
        "## Load Dataset\n",
        "We have generated a toy dataset using names of Thai MP candidates in 2019 Thai General Election from elect.in.th's github(https://github.com/codeforthailand/dataset-election-62-candidates) and tltk (https://pypi.org/project/tltk/) library to convert them into Roman script.\n",
        "\n",
        "```\n",
        "ไกรสีห์ kraisi\n",
        "พัชรี phatri\n",
        "ธีระ thira\n",
        "วุฒิกร wutthikon\n",
        "ไสว sawai\n",
        "สัมภาษณ์  samphat\n",
        "วศิน wasin\n",
        "ทินวัฒน์ thinwat\n",
        "ศักดินัย sakdinai\n",
        "สุรศักดิ์ surasak\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jte-Csrf-4kd",
        "outputId": "a1ba364b-64c2-4875-873c-90bc1808a4be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-01-20 17:56:09--  https://raw.githubusercontent.com/ekapolc/nlp_2019/master/HW8/mp_name_th_en.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 324399 (317K) [text/plain]\n",
            "Saving to: ‘mp_name_th_en.csv’\n",
            "\n",
            "mp_name_th_en.csv   100%[===================>] 316.80K  --.-KB/s    in 0.08s   \n",
            "\n",
            "2025-01-20 17:56:09 (3.83 MB/s) - ‘mp_name_th_en.csv’ saved [324399/324399]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/ekapolc/nlp_2019/master/HW8/mp_name_th_en.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "L9zXp7KH1ZSa"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "with open('mp_name_th_en.csv') as csvfile:\n",
        "    readCSV = csv.reader(csvfile, delimiter=',')\n",
        "    name_th = []\n",
        "    name_en = []\n",
        "    for row in readCSV:\n",
        "        temp_th = row[0]\n",
        "        temp_en = row[1]\n",
        "\n",
        "        name_th.append(temp_th)\n",
        "        name_en.append(temp_en)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ZCsqrXxu1ZSe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ไกรสีห์ kraisi\n",
            "พัชรี phatri\n",
            "ธีระ thira\n",
            "วุฒิกร wutthikon\n",
            "ไสว sawai\n",
            "สัมภาษณ์  samphat\n",
            "วศิน wasin\n",
            "ทินวัฒน์ thinwat\n",
            "ศักดินัย sakdinai\n",
            "สุรศักดิ์ surasak\n"
          ]
        }
      ],
      "source": [
        "for th, en in zip(name_th[:10],name_en[:10]):\n",
        "    print(th,en)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvW8xqT81ZSh"
      },
      "source": [
        "## TODO1: Preprocess dataset\n",
        "* You will need 2 vocabularies (1 for input and another for output)\n",
        "* DON'T FORGET TO INCLUDE special token for padding (for both input and output)\n",
        "* DON'T FORGET TO INCLUDE special token for the end of word symbol (output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rv1Xd9A1ZSi",
        "outputId": "dece74ae-a492-41a7-f07d-2798157c7fcc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 10887 lines and 65 unique characters in your input data.\n"
          ]
        }
      ],
      "source": [
        "#Preprocessing\n",
        "input_chars = list(set(''.join(name_th)))\n",
        "output_chars = list(set(''.join(name_en)))\n",
        "data_size, vocab_size = len(name_th), len(input_chars)+1\n",
        "output_vocab_size = len(output_chars)+2#+2 for special end of sentence token/PADDING\n",
        "print('There are %d lines and %d unique characters in your input data.' % (data_size, vocab_size))\n",
        "maxlen = len( max(name_th, key=len)) #max input length\n",
        "maxlen_out = len( max(name_en, key=len)) #max input length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mo381I_t1ZSm",
        "outputId": "4467516a-90c8-477d-bc43-bb071b17a956"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Max input length: 20\n",
            "Max output length: 19\n"
          ]
        }
      ],
      "source": [
        "print(\"Max input length:\", maxlen)\n",
        "print(\"Max output length:\", maxlen_out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[59, 3, 35, 40, 50, 41, 65]\n",
            "ไกรสีห์\n"
          ]
        }
      ],
      "source": [
        "sorted_chars = sorted(input_chars)\n",
        "sorted_chars.insert(0, \"<PAD>\")\n",
        "sorted_chars.insert(1, \"</s>\")\n",
        "\n",
        "sorted_output_chars = sorted(output_chars)\n",
        "sorted_output_chars.insert(0, \"<PAD>\")\n",
        "\n",
        "input_stoi = { c:i for i, c in enumerate(sorted_chars) }\n",
        "input_itos = { i:c for i, c in enumerate(sorted_chars)}\n",
        "input_encode = lambda sentence: [input_stoi[c] for c in sentence]\n",
        "input_decode = lambda encoding: \"\".join([input_itos[i] for i in encoding])\n",
        "\n",
        "output_stoi = { c:i for i, c in enumerate(sorted_output_chars) }\n",
        "output_itos = { i:c for i, c in enumerate(sorted_output_chars)}\n",
        "output_encode = lambda sentence: [output_stoi[c] for c in sentence]\n",
        "output_decode = lambda encoding: \"\".join([output_itos[i] for i in encoding])\n",
        "\n",
        "print(input_encode(name_th[0]))\n",
        "print(input_decode(input_encode(name_th[0])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'<PAD>': 0, '</s>': 1, ' ': 2, 'ก': 3, 'ข': 4, 'ค': 5, 'ฆ': 6, 'ง': 7, 'จ': 8, 'ฉ': 9, 'ช': 10, 'ซ': 11, 'ฌ': 12, 'ญ': 13, 'ฎ': 14, 'ฏ': 15, 'ฐ': 16, 'ฑ': 17, 'ฒ': 18, 'ณ': 19, 'ด': 20, 'ต': 21, 'ถ': 22, 'ท': 23, 'ธ': 24, 'น': 25, 'บ': 26, 'ป': 27, 'ผ': 28, 'ฝ': 29, 'พ': 30, 'ฟ': 31, 'ภ': 32, 'ม': 33, 'ย': 34, 'ร': 35, 'ล': 36, 'ว': 37, 'ศ': 38, 'ษ': 39, 'ส': 40, 'ห': 41, 'ฬ': 42, 'อ': 43, 'ฮ': 44, 'ะ': 45, 'ั': 46, 'า': 47, 'ำ': 48, 'ิ': 49, 'ี': 50, 'ึ': 51, 'ื': 52, 'ุ': 53, 'ู': 54, 'เ': 55, 'แ': 56, 'โ': 57, 'ใ': 58, 'ไ': 59, '็': 60, '่': 61, '้': 62, '๊': 63, '๋': 64, '์': 65}\n",
            "{'<PAD>': 0, '-': 1, 'a': 2, 'b': 3, 'c': 4, 'd': 5, 'e': 6, 'f': 7, 'g': 8, 'h': 9, 'i': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'r': 17, 's': 18, 't': 19, 'u': 20, 'w': 21, 'y': 22}\n"
          ]
        }
      ],
      "source": [
        "print(input_stoi)\n",
        "print(output_stoi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = []\n",
        "for line in name_th:\n",
        "    X.append(torch.tensor(input_encode(line)))\n",
        "Y = []\n",
        "for line in name_en:\n",
        "    Y.append(torch.tensor(output_encode(line)))\n",
        "\n",
        "X = nn.utils.rnn.pad_sequence(X, batch_first=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([10887, 20]), torch.Size([6]))"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([59,  3, 35, 40, 50, 41, 65,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0]),\n",
              " tensor([11, 17,  2, 10, 18, 10]))"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X[0], Y[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "Ty = len(max(Y, key=len))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "W3aXyJBEC-j_"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.types import Tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "-yirzlseC9NS"
      },
      "outputs": [],
      "source": [
        "class NameDataset(Dataset):\n",
        "  def __init__(self, X, y):\n",
        "    self.encoded = X.long()\n",
        "    self.label = torch.stack(y).long()\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return {\"x\": self.encoded[idx], \"y\": self.label[idx]}\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "qUPAB7LTDFOy"
      },
      "outputs": [],
      "source": [
        "class NameDataModule(L.LightningDataModule):\n",
        "\n",
        "  def __init__(self, train_data, y, batch_size, num_workers=0):\n",
        "      super().__init__()\n",
        "      self.train_data = train_data\n",
        "      self.y = y\n",
        "      self.batch_size = batch_size\n",
        "      self.num_workers = num_workers\n",
        "\n",
        "\n",
        "  def setup(self, stage: str):\n",
        "    pass\n",
        "\n",
        "  def collate_fn(self, batch):\n",
        "    one_hot_x = torch.stack([F.one_hot(b[\"x\"], num_classes=len(input_stoi)) for b in batch])\n",
        "    return {\"x\": one_hot_x.float(), \"y\": torch.stack([b[\"y\"] for b in batch])}\n",
        "\n",
        "  def train_dataloader(self):\n",
        "    train_dataset = NameDataset(self.train_data, self.y)\n",
        "    train_loader = DataLoader(train_dataset,\n",
        "                              batch_size=self.batch_size,\n",
        "                              shuffle=True,\n",
        "                              collate_fn=self.collate_fn,\n",
        "                              num_workers=self.num_workers)\n",
        "    return train_loader\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFSG1FqK1ZSy"
      },
      "source": [
        "# Attention Mechanism\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAlOrhbismQp"
      },
      "source": [
        "## TODO 2: Code your own (key-value) attention mechnism\n",
        "* PLEASE READ: you DO NOT have to follow all the details in (Daniluk, et al. 2017). You just need to create a key-value attention mechanism where the \"key\" part of the mechanism is used for attention score calculation, and the \"value\" part of the mechanism is used to encode information to create a context vector.  \n",
        "* fill code for one_step_attention function\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "avnlc6p9BZDv"
      },
      "outputs": [],
      "source": [
        "def one_step_attention(h: Tensor, s_prev: Tensor, linear_1: nn.Linear, linear_2: nn.Linear):\n",
        "    # (enc) h.shape = batch, seq_len, hidden_dim\n",
        "    # (dec) s_prev.shape = batch, hidden_dim\n",
        "\n",
        "    # Split into Key-Value\n",
        "    hidden_dim = h.shape[-1]\n",
        "    key_dim, value_dim = hidden_dim // 2, hidden_dim // 2\n",
        "    key, value = torch.split(h, [key_dim, value_dim], dim=-1)\n",
        "    # key: (batch, seq_len, key_dim), value: (batch, seq_len, value_dim)\n",
        "\n",
        "    seq_len = key.shape[1]\n",
        "    # unsqueeze: (batch, hidden_dim) -> (batch, 1, hidden_dim)\n",
        "    # repeat: (batch, 1, hidden_dim) -> (batch, seq_len, hidden_dim)\n",
        "    s_prev = s_prev.unsqueeze(1).repeat(1, seq_len, 1)\n",
        "\n",
        "    # do concat with s_prev.\n",
        "    concat = torch.cat([key, s_prev], dim=-1) # (batch, seq_len, key_dim + hidden_dim)\n",
        "\n",
        "    # hint: you will need to use s_prev.repeat(...) somehow so that it has the same dimension as the key\n",
        "    # hint2: s_prev.unsqueeze() could also be useful\n",
        "\n",
        "    # Attention function\n",
        "    # use layer(s) from your model to calculate attention_scores and then softmax\n",
        "    # calculate a context vector\n",
        "    e = F.tanh(linear_1(concat))\n",
        "    energies = F.relu(linear_2(e))\n",
        "    attention_scores = F.softmax(energies, dim=1)\n",
        "    context = torch.sum(attention_scores * value, dim=1) # expect error\n",
        "\n",
        "    return context"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zWN02ZtuOIU"
      },
      "source": [
        "# Translation Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0phyUQYg1ZS8"
      },
      "source": [
        "## TODO3: Create and train your encoder/decoder model here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ji_rUPhK1ZS9"
      },
      "outputs": [],
      "source": [
        "output_vocab = output_stoi\n",
        "class AttentionModel(L.LightningModule):\n",
        "    def __init__(self, learning_rate, criterion):\n",
        "\n",
        "        super().__init__()\n",
        "        self.n_h = 32 # hidden dimensions for encoder\n",
        "        self.n_s = 64 # hidden dimensions for decoder\n",
        "        self.learning_rate = learning_rate\n",
        "        self.criterion = criterion\n",
        "\n",
        "        #encoder can be any RNN of your choice\n",
        "        bidirection = True\n",
        "        self.num_directions = 2 if bidirection else 1\n",
        "        self.lstm = nn.LSTM(len(input_stoi), self.n_h, bidirectional=bidirection, batch_first=True)\n",
        "\n",
        "        #decoder has to be (any) RNNCell since we will need to calculate attention for each timestep manually\n",
        "        self.decoder_lstm_cell = nn.LSTMCell(self.n_s, self.n_s)\n",
        "        self.output_layer = nn.Linear(self.n_s, len(output_vocab))\n",
        "        \n",
        "        #attention\n",
        "        self.fc1 = nn.Linear(self.n_h*2*self.num_directions, self.n_h)\n",
        "        self.fc2 = nn.Linear(self.n_h, 1)\n",
        "\n",
        "    def forward(self, src, return_attention=False): \n",
        "        # use return_attention only when you want to get the attention scores for visualizing\n",
        "        # pass the input to the encoder\n",
        "        lstm_out, _ = self.lstm(src)\n",
        "\n",
        "        # Initialize the LSTM states. We have to do this since we are using LSTMCell (https://pytorch.org/docs/stable/generated/torch.nn.LSTMCell.html)\n",
        "        # These states will get updated while we are decoding\n",
        "        decoder_s = torch.randn(src.shape[0], self.n_s).to(self.decoder_lstm_cell.weight_ih.device)\n",
        "        decoder_c = torch.randn(src.shape[0], self.n_s).to(self.decoder_lstm_cell.weight_ih.device)\n",
        "\n",
        "        # Iterate until max_output_length (Decoding)\n",
        "        prediction = torch.zeros((src.shape[0], Ty, len(output_vocab))).to(self.decoder_lstm_cell.weight_ih.device)\n",
        "        attention_scores = [] # to store the score for each step\n",
        "        for t in range(...):\n",
        "\n",
        "            # Perform one step of the attention mechanism to calculate the context vector at timestep t\n",
        "            context, attention_score = one_step_attention(...)\n",
        "\n",
        "            # Feed the context vector to the decoder.\n",
        "\n",
        "            # Pass the decoder hidden output to the output layer (softmax)\n",
        "\n",
        "            # Put the predicted output into the list for this timestep\n",
        "            prediction[:, t] = out\n",
        "\n",
        "        return (prediction, attention_scores if return_attention else None)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        src = batch['x']\n",
        "        target = batch['y']\n",
        "        prediction,_ = self(src)\n",
        "        prediction = prediction.reshape(-1, len(output_vocab))\n",
        "        target = target.reshape(-1)\n",
        "        loss = self.criterion(prediction, target)\n",
        "        self.log(\"train_loss\", loss)\n",
        "        return loss\n",
        "\n",
        "    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n",
        "        src = batch['x']\n",
        "        with torch.no_grad():\n",
        "          prediction, attention_scores = self(src, return_attention=True)\n",
        "          prediction = F.softmax(prediction, dim=-1)\n",
        "          prediction = torch.argmax(prediction, dim=-1)\n",
        "          for pred in prediction:\n",
        "            print(\"\".join(output_decode(pred.cpu().numpy())))\n",
        "            # print(\"\".join(output_vocab.lookup_tokens(pred.cpu().numpy())))\n",
        "        return prediction, attention_scores\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return optim.Adam(self.parameters(), lr=self.learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pSM9dgDcCz1E"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "lr = 0.01\n",
        "model = AttentionModel(lr, criterion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RqrvmJalDLzF"
      },
      "outputs": [],
      "source": [
        "data_module = NameDataModule(X, Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_sFjzKX8SECo"
      },
      "outputs": [],
      "source": [
        "from lightning import Trainer\n",
        "from lightning.pytorch.loggers import WandbLogger\n",
        "wandb_logger = WandbLogger(project=\"hw3.1_attention\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OGWSzS-X1ZTO"
      },
      "outputs": [],
      "source": [
        "trainer = L.Trainer(\n",
        "    max_epochs=100,\n",
        "    logger=wandb_logger\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ZMi782c1ZTQ"
      },
      "outputs": [],
      "source": [
        "trainer.fit(model, data_module)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5BLw1Ir1ZTT"
      },
      "source": [
        "# Test Your Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRLjZzBMtCdA"
      },
      "source": [
        "## TODO4: Test your model on 5 examples of your choice including your name!\n",
        "\n",
        "Example Output:\n",
        "```\n",
        "prayutthatha</s></s>aa</s></s>a</s>\n",
        "somchai</s></s></s></s>a</s></s>a</s></s></s></s></s>\n",
        "thanathon</s></s></s></s></s></s></s></s></s></s></s>\n",
        "newin</s>i</s></s></s></s></s></s></s></s></s></s></s></s></s>\n",
        "suthep</s>he</s></s></s></s></s></s></s></s></s></s></s>\n",
        "prawit</s></s></s></s></s></s></s></s></s></s></s></s></s></s>\n",
        "chatchachatti</s></s>i</s></s></s></s>\n",
        "```\n",
        "\n",
        "<font color='blue'>Paste your model predictions in MyCourseVille</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6stNACsUP9h-"
      },
      "outputs": [],
      "source": [
        "EXAMPLES = ['ประยุทธ','สมชาย','ธนาธร','เนวิน','สุเทพ','ประวิตร์','ชัชชาติ']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kbolC8XIhR3t"
      },
      "outputs": [],
      "source": [
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LsN71S9uQ9wo"
      },
      "outputs": [],
      "source": [
        "output = trainer.predict(model, predict_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7o3893RL1ZT8"
      },
      "source": [
        "## TODO 5: Show your visualization of attention scores on one of your example\n",
        "\n",
        "<font color='blue'>Paste your visualization image in MyCourseVille</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WHysSqYJ1ZUA"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XdktVnMv1ZTh"
      },
      "outputs": [],
      "source": [
        "prediction, attention_scores = zip(*output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "BF6HD99lYlgQ",
        "outputId": "caaa0716-5b99-43e8-950f-dd0127d0fbb7"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "ax = sns.heatmap(attn_viz, linewidth=0.5)\n",
        "ax.set_yticklabels(output_text,rotation=30)\n",
        "ax.set_xticklabels(xlabels,rotation=60)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1UkIsCztaMS"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

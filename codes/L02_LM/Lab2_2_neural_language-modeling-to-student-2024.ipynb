{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"provenance":[{"file_id":"1sCWXCiBDs6UhYtxXTfWfIb30nC7kHTgc","timestamp":1612276273852},{"file_id":"1FIsDx7KTE5tiF-Xag22pl4VLQZc6G8Yw","timestamp":1612057948373}],"toc_visible":true},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Neural Language Modeling\n","metadata":{"collapsed":true,"id":"15QfB7RAuXAc","jupyter":{"outputs_hidden":true}}},{"cell_type":"markdown","source":"In this Exercise, we will be using Pytorch Lightning to implement our neural LM. Your job will be just to write the forward method of the model.\n","metadata":{"id":"gucid6KNuXAe"}},{"cell_type":"markdown","source":"## setup\n","metadata":{"id":"yL_M2zf4myYa"}},{"cell_type":"code","source":"# #download corpus\n!wget --no-check-certificate https://github.com/ekapolc/nlp_2019/raw/master/HW4/BEST2010.zip\n!unzip BEST2010.zip","metadata":{"id":"MRRrn78ZjL54","trusted":true,"execution":{"iopub.status.busy":"2025-01-16T00:13:34.176724Z","iopub.execute_input":"2025-01-16T00:13:34.177034Z","iopub.status.idle":"2025-01-16T00:13:35.555563Z","shell.execute_reply.started":"2025-01-16T00:13:34.177007Z","shell.execute_reply":"2025-01-16T00:13:35.554777Z"}},"outputs":[{"name":"stdout","text":"--2025-01-16 00:13:34--  https://github.com/ekapolc/nlp_2019/raw/master/HW4/BEST2010.zip\nResolving github.com (github.com)... 140.82.112.4\nConnecting to github.com (github.com)|140.82.112.4|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://raw.githubusercontent.com/ekapolc/nlp_2019/master/HW4/BEST2010.zip [following]\n--2025-01-16 00:13:34--  https://raw.githubusercontent.com/ekapolc/nlp_2019/master/HW4/BEST2010.zip\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 7423530 (7.1M) [application/zip]\nSaving to: ‘BEST2010.zip’\n\nBEST2010.zip        100%[===================>]   7.08M  --.-KB/s    in 0.08s   \n\n2025-01-16 00:13:35 (87.4 MB/s) - ‘BEST2010.zip’ saved [7423530/7423530]\n\nArchive:  BEST2010.zip\n   creating: BEST2010/\n  inflating: BEST2010/article.txt    \n  inflating: BEST2010/encyclopedia.txt  \n  inflating: BEST2010/news.txt       \n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install lightning","metadata":{"id":"SGmYebp38OUl","trusted":true,"execution":{"iopub.status.busy":"2025-01-16T00:13:35.556686Z","iopub.execute_input":"2025-01-16T00:13:35.556900Z","iopub.status.idle":"2025-01-16T00:13:40.814131Z","shell.execute_reply.started":"2025-01-16T00:13:35.556883Z","shell.execute_reply":"2025-01-16T00:13:40.813335Z"}},"outputs":[{"name":"stdout","text":"Collecting lightning\n  Downloading lightning-2.5.0.post0-py3-none-any.whl.metadata (40 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.4/40.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: PyYAML<8.0,>=5.4 in /usr/local/lib/python3.10/dist-packages (from lightning) (6.0.2)\nRequirement already satisfied: fsspec<2026.0,>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning) (2024.6.1)\nRequirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (0.11.9)\nRequirement already satisfied: packaging<25.0,>=20.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (24.1)\nRequirement already satisfied: torch<4.0,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (2.4.1+cu121)\nRequirement already satisfied: torchmetrics<3.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (1.6.0)\nRequirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (4.66.5)\nRequirement already satisfied: typing-extensions<6.0,>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (4.12.2)\nRequirement already satisfied: pytorch-lightning in /usr/local/lib/python3.10/dist-packages (from lightning) (2.4.0)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning) (3.10.5)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities<2.0,>=0.10.0->lightning) (71.0.4)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.16.1)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=2.1.0->lightning) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.1.4)\nRequirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics<3.0,>=0.7.0->lightning) (1.26.4)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (2.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (24.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (6.1.0)\nRequirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.11.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (4.0.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<4.0,>=2.1.0->lightning) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<4.0,>=2.1.0->lightning) (1.3.0)\nRequirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (3.10)\nDownloading lightning-2.5.0.post0-py3-none-any.whl (815 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: lightning\nSuccessfully installed lightning-2.5.0.post0\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"## code\n","metadata":{"id":"IR4HK5jQm17K"}},{"cell_type":"code","source":"total_word_count = 0\nbest2010 = []\nwith open(\"BEST2010/news.txt\", \"r\", encoding=\"utf-8\") as f:\n    for i, line in enumerate(f):\n        line = line.strip()[:-1]  # remove the trailing |\n        total_word_count += len(line.split(\"|\"))\n        best2010.append(line)\n\ntrain = best2010[: int(len(best2010) * 0.7)]\ntest = best2010[int(len(best2010) * 0.7) :]\n# Training data\ntrain_word_count = 0\nfor line in train:\n    for word in line.split(\"|\"):\n        train_word_count += 1\nprint(\"Total sentences in BEST2010 news training dataset :\\t\" + str(len(train)))\nprint(\"Total word counts in BEST2010 news training dataset :\\t\" + str(train_word_count))","metadata":{"id":"oPE1RqKOrWJ0","trusted":true,"execution":{"iopub.status.busy":"2025-01-16T00:13:40.816009Z","iopub.execute_input":"2025-01-16T00:13:40.816322Z","iopub.status.idle":"2025-01-16T00:13:41.163318Z","shell.execute_reply.started":"2025-01-16T00:13:40.816292Z","shell.execute_reply":"2025-01-16T00:13:41.162688Z"}},"outputs":[{"name":"stdout","text":"Total sentences in BEST2010 news training dataset :\t21678\nTotal word counts in BEST2010 news training dataset :\t1042797\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"Here we are going to use a library from huggingface called `tokenizers`. This will help us create a vocabulary and handle the encoding and decoding, i.e., convert text to its corresponding ID (which will be learned by the tokenizer).\n","metadata":{"id":"SQBjqe5arHGX"}},{"cell_type":"code","source":"from tokenizers import Tokenizer\nfrom tokenizers.models import WordLevel\nfrom tokenizers.pre_tokenizers import CharDelimiterSplit\nfrom tokenizers.trainers import WordLevelTrainer\n\n# Basically, we just use the new tokenizer as our vocab building tool.\n# In practice, you will have to use a compatible tokenizer like newmm to tokenize the corpus first then do this step\ntokenizer = Tokenizer(WordLevel(unk_token=\"[UNK]\"))\ntokenizer.pre_tokenizer = CharDelimiterSplit(\n    delimiter=\"|\"\n)  # now the tokenizer will split \"|\" for us\ntrainer = WordLevelTrainer(\n    min_frequency=3,  # we can set a frequency threshold for taking a word into our vocab. for this example, words with freq < 3 will be excluded from the vocab.\n    special_tokens=[\"[UNK]\", \"<s>\", \"</s>\"],\n)  # these are our special tokens: for unknown, begin-of-sentence, and end-of-sentence, respectively.\ntokenizer.train_from_iterator(train, trainer=trainer)","metadata":{"id":"elwE0gh2rE3C","trusted":true,"execution":{"iopub.status.busy":"2025-01-16T00:13:41.164255Z","iopub.execute_input":"2025-01-16T00:13:41.164513Z","iopub.status.idle":"2025-01-16T00:13:41.670980Z","shell.execute_reply.started":"2025-01-16T00:13:41.164494Z","shell.execute_reply":"2025-01-16T00:13:41.669246Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"len(tokenizer.get_vocab())  # same as nltk","metadata":{"id":"TrKtjv4PJpg2","trusted":true,"execution":{"iopub.status.busy":"2025-01-16T00:13:41.672068Z","iopub.execute_input":"2025-01-16T00:13:41.672437Z","iopub.status.idle":"2025-01-16T00:13:41.687513Z","shell.execute_reply.started":"2025-01-16T00:13:41.672369Z","shell.execute_reply":"2025-01-16T00:13:41.686571Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"9062"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"tokenizer.encode(\n    \"กฎหมาย|กับ|การ|เบียดบัง|คน|จน|asdf\"\n).tokens  # tokens we get after tokenizing this sentence. unknown words will be tokenized as [UNK]","metadata":{"id":"WqM_jrZwrJpB","trusted":true,"execution":{"iopub.status.busy":"2025-01-16T00:13:41.688312Z","iopub.execute_input":"2025-01-16T00:13:41.688643Z","iopub.status.idle":"2025-01-16T00:13:41.702944Z","shell.execute_reply.started":"2025-01-16T00:13:41.688612Z","shell.execute_reply":"2025-01-16T00:13:41.701975Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"['กฎหมาย', 'กับ', 'การ', 'เบียดบัง', 'คน', 'จน', '[UNK]']"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"tokenizer.encode(\n    \"กฎหมาย|กับ|การ|เบียดบัง|คน|จน|asdf\"\n).ids  # this is what we will feed to the LM","metadata":{"id":"1r1pJ1B_sp9j","trusted":true,"execution":{"iopub.status.busy":"2025-01-16T00:13:41.704193Z","iopub.execute_input":"2025-01-16T00:13:41.704546Z","iopub.status.idle":"2025-01-16T00:13:41.718006Z","shell.execute_reply.started":"2025-01-16T00:13:41.704515Z","shell.execute_reply":"2025-01-16T00:13:41.716796Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"[242, 28, 5, 8883, 22, 190, 0]"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"import itertools\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.optim as optim\nimport lightning as L\nfrom tqdm import tqdm","metadata":{"id":"Fkx6CSoXWXmG","trusted":true,"execution":{"iopub.status.busy":"2025-01-16T00:13:41.720105Z","iopub.execute_input":"2025-01-16T00:13:41.720369Z","iopub.status.idle":"2025-01-16T00:13:47.567421Z","shell.execute_reply.started":"2025-01-16T00:13:41.720348Z","shell.execute_reply":"2025-01-16T00:13:47.566780Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"L.seed_everything(42, workers=True)","metadata":{"id":"3XHJsP8_898x","trusted":true,"execution":{"iopub.status.busy":"2025-01-16T00:13:47.568435Z","iopub.execute_input":"2025-01-16T00:13:47.568781Z","iopub.status.idle":"2025-01-16T00:13:47.580425Z","shell.execute_reply.started":"2025-01-16T00:13:47.568758Z","shell.execute_reply":"2025-01-16T00:13:47.579560Z"}},"outputs":[{"name":"stderr","text":"INFO: Seed set to 42\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"42"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"class TextDataset(Dataset):\n    def __init__(self, data, seq_len=128):\n        #  data is currently a list of sentences\n        #  [sent1,\n        #   sent2,\n        #   ...,\n        #  ]\n\n        data = [d + \"|</s>\" for d in data]  # append an </s> token to each sentence\n        encodings = tokenizer.encode_batch(\n            data\n        )  # encode (turn token into token_id) data\n        token_ids = [\n            enc.ids for enc in encodings\n        ]  # get the token ids for each sentence\n        flatten_token_ids = list(\n            itertools.chain(*token_ids)\n        )  # turn a list of token_ids into one long token_ids\n        ## now data looks like this [sent1_ids </s> sent2_ids </s> ...]\n        encoded = torch.LongTensor(flatten_token_ids)\n\n        # remove some left over tokens so that we can form batches of seq_len (128 in this case). Optionally, we can use padding tokens instead.\n        left_over = len(encoded) % seq_len\n        encoded = encoded[: len(encoded) - left_over]\n        self.encoded = encoded.view(\n            -1, seq_len\n        )  # reshape data so it becomes a 2-D matrix of shape (len(encoded)//128, 128), i.e. each row contains data of len==128\n        ## now data looks like this\n        ## [ [1,2,3, ... , 128] (this is just an example, not actual input_ids)\n        ##   [1,2,3, ... , 128]\n        ##   [1,2,3, ... , 128]\n        ## ]\n\n    def __getitem__(self, idx):\n        return self.encoded[idx]\n\n    def __len__(self):\n        return len(self.encoded)","metadata":{"id":"-r_kyrrrDHZq","trusted":true,"execution":{"iopub.status.busy":"2025-01-16T00:13:47.581111Z","iopub.execute_input":"2025-01-16T00:13:47.581300Z","iopub.status.idle":"2025-01-16T00:13:47.586488Z","shell.execute_reply.started":"2025-01-16T00:13:47.581283Z","shell.execute_reply":"2025-01-16T00:13:47.585838Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"train_batch_size = 64\ntest_batch_size = 128\ntrain_dataset = TextDataset(train)\ntrain_loader = DataLoader(\n    train_dataset, batch_size=train_batch_size, shuffle=True\n)  # DataLoader will take care of the random sampling and batching of data\n\ntest_dataset = TextDataset(test)\ntest_loader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False)","metadata":{"id":"YmW-K0XBZ4Dq","trusted":true,"execution":{"iopub.status.busy":"2025-01-16T00:13:47.587747Z","iopub.execute_input":"2025-01-16T00:13:47.587945Z","iopub.status.idle":"2025-01-16T00:13:49.259705Z","shell.execute_reply.started":"2025-01-16T00:13:47.587928Z","shell.execute_reply":"2025-01-16T00:13:49.258736Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"## Model : Implement the forward function here\n","metadata":{"id":"ElhZcB94MUtC"}},{"cell_type":"code","source":"class LSTM(L.LightningModule):\n    def __init__(\n        self,\n        vocab_size,\n        embedding_dim,\n        hidden_dim,\n        num_layers,\n        dropout_rate,\n        learning_rate,\n        criterion,\n    ):\n\n        super().__init__()\n\n        self.num_layers = num_layers\n        self.hidden_dim = hidden_dim\n        self.embedding_dim = embedding_dim\n\n        self.embedding = nn.Embedding(\n            vocab_size, embedding_dim\n        )  # this will turn the token ids into vectors\n        self.lstm = nn.LSTM(\n            embedding_dim,\n            hidden_dim,\n            num_layers=num_layers,\n            dropout=dropout_rate,\n            batch_first=True,\n        )\n        self.dropout = nn.Dropout(dropout_rate)\n        self.fc = nn.Linear(\n            hidden_dim, vocab_size\n        )  # turn the vectors back into token ids\n        self.learning_rate = learning_rate\n        self.criterion = criterion\n\n    def forward(self, src):\n        embedded = self.embedding(src)\n        embedded = self.dropout(embedded)\n        lstm_out, _ = self.lstm(embedded)\n        lstm_out = self.dropout(lstm_out)\n        output = self.fc(lstm_out)\n\n        return output\n        \n\n    def training_step(self, batch, batch_idx):\n\n        src = batch[:, :-1]\n        target = batch[:, 1:]\n        prediction = self(\n            src\n        )  # run the sequence through the model (the forward method)\n        prediction = prediction.reshape(-1, vocab_size)\n        target = target.reshape(-1)\n        loss = self.criterion(prediction, target)\n        self.log(\"train_loss\", loss)\n        return loss\n\n    def test_step(self, batch, batch_idx):\n\n        src = batch[:, :-1]  # [batch_size (64) , seq_len-1 (127)] except last words\n        target = batch[:, 1:]  # [batch_size (64) , seq_len-1 (127)] except first words\n        with torch.no_grad():  # disable gradient calculation for faster inference\n            prediction = self(\n                src\n            )  # [batch_size (64), seq_len-1 (127) , vocab size (9000)]\n        prediction = prediction.reshape(\n            -1, vocab_size\n        )  # [batch_size*(seq_len-1) (64*127=8128) , vocab]\n        target = target.reshape(\n            -1\n        )  # [batch_size (64), seq_len-1 (127)] -> [batch_size*(seq_len-1) (8128)]\n        loss = self.criterion(prediction, target)\n        self.log(\"test_loss\", loss)\n        return loss\n\n    def configure_optimizers(self):\n        return optim.Adam(self.parameters(), lr=self.learning_rate)","metadata":{"id":"nKNJAolug-1I","trusted":true,"execution":{"iopub.status.busy":"2025-01-16T00:14:59.865256Z","iopub.execute_input":"2025-01-16T00:14:59.865591Z","iopub.status.idle":"2025-01-16T00:14:59.873612Z","shell.execute_reply.started":"2025-01-16T00:14:59.865564Z","shell.execute_reply":"2025-01-16T00:14:59.872902Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"vocab_size = tokenizer.get_vocab_size()\nembedding_dim = 200\nhidden_dim = 512\nnum_layers = 3\ndropout_rate = 0.2\nlr = 1e-3","metadata":{"id":"jBnYCh-miOEr","trusted":true,"execution":{"iopub.status.busy":"2025-01-16T00:15:00.082102Z","iopub.execute_input":"2025-01-16T00:15:00.082413Z","iopub.status.idle":"2025-01-16T00:15:00.088233Z","shell.execute_reply.started":"2025-01-16T00:15:00.082388Z","shell.execute_reply":"2025-01-16T00:15:00.087513Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\nmodel = LSTM(\n    vocab_size, embedding_dim, hidden_dim, num_layers, dropout_rate, lr, criterion\n)","metadata":{"id":"HHWXaPsvigPq","trusted":true,"execution":{"iopub.status.busy":"2025-01-16T00:15:00.282933Z","iopub.execute_input":"2025-01-16T00:15:00.283147Z","iopub.status.idle":"2025-01-16T00:15:00.375978Z","shell.execute_reply.started":"2025-01-16T00:15:00.283130Z","shell.execute_reply":"2025-01-16T00:15:00.375320Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"from lightning.pytorch.loggers import CSVLogger\n\ncsv_logger = CSVLogger(\"log\")","metadata":{"id":"_yNEZ4jwXumR","trusted":true,"execution":{"iopub.status.busy":"2025-01-16T00:15:01.951274Z","iopub.execute_input":"2025-01-16T00:15:01.951552Z","iopub.status.idle":"2025-01-16T00:15:01.955311Z","shell.execute_reply.started":"2025-01-16T00:15:01.951531Z","shell.execute_reply":"2025-01-16T00:15:01.954510Z"}},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":"### Training\n","metadata":{"id":"eZwqhWicMdH0"}},{"cell_type":"code","source":"trainer = L.Trainer(max_epochs=20, logger=csv_logger, deterministic=True)","metadata":{"id":"kr0zdeMAjD1U","trusted":true,"execution":{"iopub.status.busy":"2025-01-16T00:15:04.047114Z","iopub.execute_input":"2025-01-16T00:15:04.047400Z","iopub.status.idle":"2025-01-16T00:15:04.087182Z","shell.execute_reply.started":"2025-01-16T00:15:04.047379Z","shell.execute_reply":"2025-01-16T00:15:04.086545Z"}},"outputs":[{"name":"stderr","text":"INFO: Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\nINFO: GPU available: True (cuda), used: True\nINFO: TPU available: False, using: 0 TPU cores\nINFO: HPU available: False, using: 0 HPUs\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"trainer.fit(model, train_dataloaders=train_loader)  # takes about 8 mins","metadata":{"id":"A9qcwNA0mN6J","trusted":true,"execution":{"iopub.status.busy":"2025-01-16T00:15:04.473035Z","iopub.execute_input":"2025-01-16T00:15:04.473272Z","iopub.status.idle":"2025-01-16T00:24:05.267627Z","shell.execute_reply.started":"2025-01-16T00:15:04.473252Z","shell.execute_reply":"2025-01-16T00:24:05.267033Z"}},"outputs":[{"name":"stderr","text":"INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\nINFO: \n  | Name      | Type             | Params | Mode \n-------------------------------------------------------\n0 | embedding | Embedding        | 1.8 M  | train\n1 | lstm      | LSTM             | 5.7 M  | train\n2 | dropout   | Dropout          | 0      | train\n3 | fc        | Linear           | 4.6 M  | train\n4 | criterion | CrossEntropyLoss | 0      | train\n-------------------------------------------------------\n12.1 M    Trainable params\n0         Non-trainable params\n12.1 M    Total params\n48.504    Total estimated model params size (MB)\n5         Modules in train mode\n0         Modules in eval mode\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4ca422d1ac045f1b5539f453a9cd78e"}},"metadata":{}},{"name":"stderr","text":"INFO: `Trainer.fit` stopped: `max_epochs=20` reached.\n","output_type":"stream"}],"execution_count":23},{"cell_type":"markdown","source":"### Testing\n","metadata":{"id":"uUfWF_V6Me9H"}},{"cell_type":"code","source":"test_result = trainer.test(model, dataloaders=test_loader)","metadata":{"id":"WXVj9ewNqweZ","trusted":true,"execution":{"iopub.status.busy":"2025-01-16T00:25:27.869758Z","iopub.execute_input":"2025-01-16T00:25:27.870066Z","iopub.status.idle":"2025-01-16T00:25:33.034747Z","shell.execute_reply.started":"2025-01-16T00:25:27.870044Z","shell.execute_reply":"2025-01-16T00:25:33.034146Z"}},"outputs":[{"name":"stderr","text":"INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Testing: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f6484bf5c034d3b9c4b1ffbc8bfcaf2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    4.136300563812256    \u001b[0m\u001b[35m \u001b[0m│\n└───────────────────────────┴───────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     4.136300563812256     </span>│\n└───────────────────────────┴───────────────────────────┘\n</pre>\n"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"import numpy as np","metadata":{"id":"4pVjEyYDtnc-","trusted":true,"execution":{"iopub.status.busy":"2025-01-16T00:25:34.747102Z","iopub.execute_input":"2025-01-16T00:25:34.747392Z","iopub.status.idle":"2025-01-16T00:25:34.750910Z","shell.execute_reply.started":"2025-01-16T00:25:34.747370Z","shell.execute_reply":"2025-01-16T00:25:34.750013Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"print(f\"Perplexity : {np.exp(test_result[0]['test_loss'])}\")","metadata":{"id":"uuIPToGQs-ZG","trusted":true,"execution":{"iopub.status.busy":"2025-01-16T00:25:35.167544Z","iopub.execute_input":"2025-01-16T00:25:35.168031Z","iopub.status.idle":"2025-01-16T00:25:35.173209Z","shell.execute_reply.started":"2025-01-16T00:25:35.168001Z","shell.execute_reply":"2025-01-16T00:25:35.172371Z"}},"outputs":[{"name":"stdout","text":"Perplexity : 62.57091564368979\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"model.eval()  # disable dropout","metadata":{"id":"pAZwiRqsnOPe","trusted":true,"execution":{"iopub.status.busy":"2025-01-16T00:25:35.940058Z","iopub.execute_input":"2025-01-16T00:25:35.940327Z","iopub.status.idle":"2025-01-16T00:25:35.945561Z","shell.execute_reply.started":"2025-01-16T00:25:35.940308Z","shell.execute_reply":"2025-01-16T00:25:35.944893Z"}},"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"LSTM(\n  (embedding): Embedding(9062, 200)\n  (lstm): LSTM(200, 512, num_layers=3, batch_first=True, dropout=0.2)\n  (dropout): Dropout(p=0.2, inplace=False)\n  (fc): Linear(in_features=512, out_features=9062, bias=True)\n  (criterion): CrossEntropyLoss()\n)"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"unk_token_id = tokenizer.encode(\"[UNK]\").ids\neos_token_id = tokenizer.encode(\"</s>\").ids","metadata":{"id":"VFtebDAmVh_T","trusted":true,"execution":{"iopub.status.busy":"2025-01-16T00:25:36.340391Z","iopub.execute_input":"2025-01-16T00:25:36.340599Z","iopub.status.idle":"2025-01-16T00:25:36.344396Z","shell.execute_reply.started":"2025-01-16T00:25:36.340581Z","shell.execute_reply":"2025-01-16T00:25:36.343439Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"def generate_seq(context, max_new_token=10):\n    encoded = tokenizer.encode(context).ids\n    with torch.no_grad():\n        for i in range(max_new_token):\n            src = torch.LongTensor([encoded]).to(model.device)\n            prediction = model(src)\n            probs = torch.softmax(prediction[:, -1] / 1, dim=-1)\n            prediction = torch.multinomial(probs, num_samples=1).item()\n\n            while prediction == unk_token_id:\n                prediction = torch.multinomial(probs, num_samples=1).item()\n\n            if prediction == eos_token_id:\n                break\n\n            encoded.append(prediction)\n\n    return tokenizer.decode(encoded)","metadata":{"id":"hj-V4OsDqpBO","trusted":true,"execution":{"iopub.status.busy":"2025-01-16T00:25:37.865303Z","iopub.execute_input":"2025-01-16T00:25:37.865581Z","iopub.status.idle":"2025-01-16T00:25:37.870816Z","shell.execute_reply.started":"2025-01-16T00:25:37.865559Z","shell.execute_reply":"2025-01-16T00:25:37.869941Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"context = \"<s>|วัน|จันทร์\"\ngenerate_seq(context, 50)","metadata":{"id":"u20r9w8zvJi4","trusted":true,"execution":{"iopub.status.busy":"2025-01-16T00:25:39.632291Z","iopub.execute_input":"2025-01-16T00:25:39.632563Z","iopub.status.idle":"2025-01-16T00:25:40.644756Z","shell.execute_reply.started":"2025-01-16T00:25:39.632542Z","shell.execute_reply":"2025-01-16T00:25:40.643907Z"}},"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"'วัน จันทร์ ที่   1   กันยายน   ข้าง เครื่อง บิน สารสนเทศ 2   และ จาก โครงการ กอง ทัพ   นครราชสีมา   ขอ พ่น การ ทำลาย รถ ทั้ง สาม อำเภอ   จำนวน   100   ราย   เข้า ช่วยเหลือ     บริษัท ติดตาม เครื่องแบบ   อ.เมือง   บาดเจ็บ   ชาว คน'"},"metadata":{}}],"execution_count":30},{"cell_type":"markdown","source":"## Questions: Answer the following in MyCourseville\n\n1. What is the perplexity of the neural LM you trained?\n2. Paste your favorite sentence generated with the LM.\n","metadata":{"id":"1fr536NVvGX3"}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iU5fRQwhEdJy"
   },
   "source": [
    "# Subword Tokenization\n",
    "\n",
    "In this exercise, we will learn how to train our own subword tokenizers with different algorithms: BPE and Unigram. We will use `sentencepiece`, a library from Google to help create our tokenizers.\n",
    "\n",
    "## Ref:\n",
    "\n",
    "https://github.com/google/sentencepiece/blob/master/python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pI9gRZlUE80g"
   },
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "1pOsV-jaW975"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-01-15 13:41:32--  https://github.com/Knight-H/thai-lm/raw/refs/heads/master/data/pra-apai-manee-ch1-50.txt\n",
      "Resolving github.com (github.com)... 20.205.243.166\n",
      "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/Knight-H/thai-lm/refs/heads/master/data/pra-apai-manee-ch1-50.txt [following]\n",
      "--2025-01-15 13:41:33--  https://raw.githubusercontent.com/Knight-H/thai-lm/refs/heads/master/data/pra-apai-manee-ch1-50.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3231076 (3.1M) [application/octet-stream]\n",
      "Saving to: ‘pra-apai-manee-ch1-50.txt’\n",
      "\n",
      "pra-apai-manee-ch1- 100%[===================>]   3.08M  7.11MB/s    in 0.4s    \n",
      "\n",
      "2025-01-15 13:41:34 (7.11 MB/s) - ‘pra-apai-manee-ch1-50.txt’ saved [3231076/3231076]\n",
      "\n",
      "--2025-01-15 13:41:34--  https://github.com/Knight-H/thai-lm/raw/refs/heads/master/data/kratoo-40000000-40002000.jsonl\n",
      "Resolving github.com (github.com)... 20.205.243.166\n",
      "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/Knight-H/thai-lm/refs/heads/master/data/kratoo-40000000-40002000.jsonl [following]\n",
      "--2025-01-15 13:41:35--  https://raw.githubusercontent.com/Knight-H/thai-lm/refs/heads/master/data/kratoo-40000000-40002000.jsonl\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2968483 (2.8M) [text/plain]\n",
      "Saving to: ‘kratoo-40000000-40002000.jsonl’\n",
      "\n",
      "kratoo-40000000-400 100%[===================>]   2.83M  8.44MB/s    in 0.3s    \n",
      "\n",
      "2025-01-15 13:41:37 (8.44 MB/s) - ‘kratoo-40000000-40002000.jsonl’ saved [2968483/2968483]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/Knight-H/thai-lm/raw/refs/heads/master/data/pra-apai-manee-ch1-50.txt\n",
    "!wget https://github.com/Knight-H/thai-lm/raw/refs/heads/master/data/kratoo-40000000-40002000.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CSiDpG9WE-cT"
   },
   "source": [
    "## Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "OQd7M6gLWPLN"
   },
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "import io\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OifbmMIstzs8"
   },
   "source": [
    "Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "-FnIDvb1lMuh"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1060318"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pantip_text = []\n",
    "with open(\"kratoo-40000000-40002000.jsonl\", \"r\") as json_file:\n",
    "    json_list = list(json_file)\n",
    "    for json_str in json_list:\n",
    "        result = json.loads(json_str)\n",
    "        pantip_text.append(f\"{result['title']}\\n{result['content']}\\n\")\n",
    "sum([len(t) for t in pantip_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "yaaQVXZ8A0j1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1100605"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"pra-apai-manee-ch1-50.txt\") as f:\n",
    "    pra_apai_manee_data = f.readlines()\n",
    "sum([len(t) for t in pra_apai_manee_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "RbdfkF-vAoie"
   },
   "outputs": [],
   "source": [
    "pantip_train_text = pantip_text[: int(len(pantip_text) * 0.8)]\n",
    "pantip_test_text = pantip_text[int(len(pantip_text) * 0.8) :]\n",
    "\n",
    "pam_train_text = pra_apai_manee_data[\n",
    "    : int(len(pra_apai_manee_data) * 0.8)\n",
    "]  # pam = pra_apai_manee\n",
    "pam_test_text = pra_apai_manee_data[int(len(pra_apai_manee_data) * 0.8) :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BhwcH0Aot1XI"
   },
   "source": [
    "## Run tokenizer training\n",
    "\n",
    "The Python wrapper provides multiple APIs for training our tokenizers\n",
    "\n",
    "1. `spm.SentencePieceTrainer.train(input='input.txt', model_prefix='m', vocab_size=vocab_size, model_type=model_type)`\n",
    "   <br> This will output the tokenizer files `m.model` and `m.vocab` that can be later loaded into `SentencePieceProcessor`.\n",
    "   <br><br>\n",
    "2. `spm.SentencePieceTrainer.train(sentence_iterator=iterator, model_writer=obj_with_write_method, vocab_size=vocab_size, model_type=model_type)`\n",
    "   <br> This method will require a file object e.g. `obj_with_write_method = io.BytesIO()`. The advantage of this method is you can run sentencepiece on environments that have limited access to the local file system. But you will still have to save the model file if you want to re-use the model else you will have to train it again.\n",
    "   <br><br>\n",
    "3. `spm.SentencePieceTrainer.train('--input=input.txt --model_prefix=m --vocab_size=vocab_size --model_type=model_type')`\n",
    "   <br> Same as no.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c3XeFFYw-T_0"
   },
   "source": [
    "### Unigram tokenizer\n",
    "\n",
    "We are going to start with training a unigram tokenizer. You can use any method of training one. Make sure to set vocab_size to 1000.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = pantip_train_text + pam_train_text\n",
    "test_text = pantip_test_text + pam_test_text\n",
    "\n",
    "train_corpus = \"\\n\".join(train_text)\n",
    "test_corpus = \"\\n\".join(test_text)\n",
    "\n",
    "with open(\"train_corpus.txt\", \"w\") as f:\n",
    "    f.write(train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus_pam = \"\\n\".join(pam_train_text)\n",
    "test_corpus_pam = \"\\n\".join(pam_test_text)\n",
    "\n",
    "with open(\"train_corpus_pam.txt\", \"w\") as f:\n",
    "    f.write(train_corpus_pam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train\n",
    "spm.SentencePieceTrainer.train(\n",
    "    input=\"train_corpus_pam.txt\",\n",
    "    model_prefix=\"unigram_pam\",\n",
    "    vocab_size=1000,\n",
    "    model_type=\"unigram\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gdXPaoW3_v2T"
   },
   "source": [
    "### Q1 MCV\n",
    "\n",
    "How many tokens did you get when tokenizing the following sentence with your unigram tokenizer: <br>\n",
    "'อรุณสวัสดิ์ ฉันเอามเหสีมาหาม สวัสดี ประเทศไทยสบายดีไหม'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_pam_tokenizer = spm.SentencePieceProcessor(model_file='unigram_pam.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "J1bO3s-z-PLb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unigram_pam_tokenizer.encode(\"อรุณสวัสดิ์ ฉันเอามเหสีมาหาม สวัสดี ประเทศไทยสบายดีไหม\", out_type=str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tKkc1D-hAFxl"
   },
   "source": [
    "### BPE Tokenizer\n",
    "\n",
    "Now try training a BPE tokenizer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "AiXj57rh-PIv"
   },
   "outputs": [],
   "source": [
    "## Train\n",
    "spm.SentencePieceTrainer.train(\n",
    "    input=\"train_corpus_pam.txt\",\n",
    "    model_prefix=\"bpe_pam\",\n",
    "    vocab_size=1000,\n",
    "    model_type=\"bpe\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nrQwGmL5AMXc"
   },
   "source": [
    "### Q2 MCV\n",
    "\n",
    "How many tokens did you get when tokenizing the following sentence with your BPE tokenizer: <br>\n",
    "'อรุณสวัสดิ์ ฉันเอามเหสีมาหาม สวัสดี ประเทศไทยสบายดีไหม'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpe_pam_tokenizer = spm.SentencePieceProcessor(model_file='bpe_pam.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "0AXuzyaN-PEr"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bpe_pam_tokenizer.encode(\"อรุณสวัสดิ์ ฉันเอามเหสีมาหาม สวัสดี ประเทศไทยสบายดีไหม\", out_type=str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rbb6C6-IS_Ly"
   },
   "source": [
    "These are some of your vocabs. Note that you will see \"▁\" (U+2581) in every type of tokenizer in SentencePiece since it makes it possible to perform detokenization \\(unsplit your sentences\\) without relying on language-specific resources.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "Aa9j6XrTKjyA"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<unk> | <s> | </s> | ▁ | า | เ | น | ม | ย | ก | ร | ว | ด | ส | ง | บ | ค | มา | อ | ล | จะ | ท | ให้ | ห | ไป | ไม่ | แ | ว่า | พ | ุ | ี | ๏ | ฯ | ข | ช | เป็น | พระ | โ | ที่ | ใจ | ▁จะ | จ | ะ | ิ | ต | ก็ | อยู่ | ป | ได้ | ่ | ไ | เข้า | ู | ▁พระ | ้า | ตาม | ใน | ้ | ▁แล้ว | เหมือน | รา | ศ | เจ้า | เห็น | ลา | กัน | ั | หา | นาง | ทรง | ประ | ์ | ยา | ัก | ํา | ซ | าน | ัง | ฉ | องค์ | ัด | แล้ว | อน | ดู | ถ | ด้วย | มี | ▁จึง | นี้ | ่า | ผ | น้อง | แต่ | ทํา | ▁นาง | ▁ให้ | รัก | พี่ | คิด | ลูก | พา | รู้ | การ | กับ | ัน | หน้า | กระ | วน | ออก | ่อ | เขา | ถึง | ระ | ข้า | ับ | พล | นั่ง | ทั้ง | หน | รับ | ษ | กล | วง | ลง | ฝ | กร | พร | ความ | เสีย | ดี | ขึ้น | อง | ่ง | ธ | ▁แต่ | คน | กลับ | ▁ฝ่าย | ้น | อด | ภ | หรือ | ตร | ือ | ฟัง | แม่ | ▁ไม่ | ไว้ | ยัง | ▁เห็น | นา | ขอ | มิ | น้ํา | หล | ดัง | ▁พอ | ▁ทั้ง | ช่วย | สม | นั้น | ริ | ทัพ | ต้อง | วัน | อา | น้อย | รบ | ิน | อย่า | เอา | จน | เรา | สุด | เสียง | ข้าง | หลัง | ตี | ตัว | ละ | สุ | วัง | ทุก | ่น | ึก | นึก | เฝ้า | นาย | ฝรั่ง | ทูล | เส | วิ | ปล | ▁ถึง | ตาย | ใคร | อก | อั | ตา | เรือ | จึง | แล | ี่ | ั่ง | แสน | สอง | ของ | ็ | ลี | ี้ | จิต | หมาย | ้ม | แจ้ง | ั่น | สั่ง | ราช | พิ | เห | หาย | ้อง | เมือง | เหลือ | กลาง | กษัตริย์ | ยิ่ง | ตรัส | ึง | เลย | เล่า | ทาง | ุด | ศรี | เคย | ไหน | สาม | หนี | ณ | มัน | ื้อ | ค่อย | ชาย | พราหมณ์ | ▁อย่า | ญ | ที | นิ | น่า | สิ้น | ฉัน | กาย | ลังกา | ▁ด้วย | คอย | บอก | สิ | ฟ | สงสาร | พ่อ | ยง | จริง | ชาว | ถาม | ไร | ทหาร | ตั้ง | ▁อัน | เที่ยว | ปร | ผู้ | พวก | สาร | ชม | ศึก | คํา | ▁เป็น | ทอง | อบ | ใหญ่ | ถือ | สาว | พระอภัย | จง | สา | จับ | ั้น | พลาง | ▁มา | ยก | ▁บ้าง | ไพร่ | ลม | ล้วน | ▁ต่าง | ร้อย | พบ | งาม | แกล้ง | อาย | จะได้ | เคียง | อย่าง | เครื่อง | กลัว | ลาย | จํา | ต่าง | สินสมุทร | ▁พวก | ม้า | ลํา | นี่ | ผา | แก้ว | เพราะ | ▁ครั้น | ▁จน | ▁แม้น | สาย | พัน | พระองค์ | พร้อม | วาย | ชิง | ห้อง | ร้อง | สู้ | ▁จง | ลิ | ราย | ล่อ | จาก | ้ว | ท่าน | รอง | เดิน | เรียก | ขัด | เหล่า | กุมาร | ผล | ป่า | ู่ | คู่ | รูป | กิน | พอ | ร่ํา | โฉม | ▁ถ้า | คง | ่าย | ใช้ | ตอบ | หลง | ไล่ | จัด | ดับ | ▁เมื่อ | บน | อ่อน | แสง | คืน | ใส่ | แค้น | รถ | ตรง | แต่ง | แน่ | เชิญ | ชื่น | ถวาย | โห | จร | มิได้ | นอน | ุก | ชวน | เมีย | อาลัย | ้อม | ลับ | ไหว | ▁แม้ | บิดา | หญิง | หลับ | ดอก | กล้า | ขาด | จัก | ไม่มี | บาท | เสนา | ย์ | ช่าง | โศก | วาง | ติด | เสร็จ | ร้อน | คุณ | ผัว | นัก | ความตาม | พักตร์ | หน่อ | ้อย | ▁ซึ่ง | ตะ | ห้าม | พราย | ฟ้า | ไฉน | ใ | ตก | เมื่อ | ยศ | ชล | ดํา | หนึ่ง | ผัน | ใด | สัก | ร้าย | วิ่ง | แก้ | ยาม | ศรีสุวรรณ | ปืน | ฆ่า | ขับ | ขวา | ไฟ | พูด | หมอง | ก็ไม่ | กําลัง | รักษา | เช่น | ุ่ม | ผี | หาญ | เล่น | เนื้อ | รีบ | ถูก | ชัย | บุตรี | ฟัน | บ้าง | เอ๋ย | สงสัย | ผิด | นิ่ง | ชื่อ | เถิด | ผ่อน | หลาน | สี่ | ชาติ | อี | ปาก | ช้า | ึ | แตก | ตรา | รณ | ลอง | ปี | หมอ | เจ้าพราหมณ์ | พี่เลี้ยง | ต่อ | พลอย | โฉมยง | เนตร | หัก | กอด | เชย | ทั้งสอง | ยิ้ม | ค่ํา | นอก | ขวัญ | ซ้ํา | อารมณ์ | ทุกข์ | แขก | เย็น | หนักหนา | ั้ง | ปิด | โปรด | ้ง | กําปั่น | เรียง | แรง | สิ่ง | เศร้า'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_vocabs = [sp_pam.id_to_piece(id) for id in range(sp_pam.get_piece_size())]\n",
    "\" | \".join(unigram_vocabs[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "2TsXA0UqN5LN"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<unk> | <s> | </s> | ้า | ่า | อง | ระ | ํา | รา | อย | ่ง | มา | จะ | ัง | ัน | ▁เ | าย | ้ว | ับ | ี่ | ม่ | อน | ให | าม | ้น | ็น | พระ | ีย | าง | กล | ้ง | ัก | หน | ให้ | ไม่ | หล | ่น | ึง | ▁แ | ทั | ตร | าร | ้อง | ไป | ิด | ข้า | ว่า | หม | คร | ือ | ล้ว | เป | เส | ประ | าน | ั่ง | ▁๏ | ▁ฯ | ที่ | อก | เล | ิน | ได | พล | ทร | ัด | นาง | ึก | ได้ | ู่ | ▁จะ | ค์ | ี้ | พร | เป็น | สุ | ทั้ง | อม | ัย | เร | ห็น | ▁จ | ▁พระ | ก็ | ใจ | อา | ื่ | ่าง | ต่ | กร | ิง | วง | วน | ือน | เจ | ู้ | ียง | อยู่ | รร | ตาม | ▁พ | ้วย | าว | ถึง | คล | ั้น | รี | เข | ด้วย | สม | องค์ | สน | าก | ▁แล้ว | เช | ัว | ย์ | ใน | คว | น้ | หมือน | ▁ส | ูก | อบ | กระ | เจ้า | ทรง | ลา | กัน | มี | ่าย | พรา | ิ่ง | เข้า | เห็น | ิต | สง | อด | ณ์ | วย | ้ม | คิด | เม | เก | เด | ▁นาง | วา | ุก | ▁ให้ | ดู | หา | ▁อ | ▁จึง | ทํา | ลง | รัก | เค | แล้ว | ่าน | พี่ | เหมือน | ั่น | ความ | ยง | อย่า | หร | มิ | ืน | ช่ | การ | ัญ | ▁ไม่ | ฝ่าย | ศรี | ้าง | วก | ้อม | ือง | น้อง | ยว | พา | แก | กํา | ่อน | ื่น | หน้า | ยา | ดี | ั้ง | ▁ทั้ง | ปรา | คน | เน | หว | รับ | แต่ | ้าย | ัส | เหล | ดา | สํา | นี้ | สาร | กับ | ลูก | ละ | ▁ต | รู้ | ื่อ | ▁ฝ่าย | ึ่ง | ลัง | าด | ื้ | กา | ขึ | นั่ง | เท | ▁เห็น | ฟัง | ้อย | ไร | ขึ้น | เสีย | ▁แต่ | บุ | สา | ไว | ทุก | กลับ | สุด | ัต | ใคร | น้ํา | ชา | ุด | ทัพ | วัน | สอง | นา | หย | ตา | รบ | ▁มา | ่อ | หรือ | ทู | ยัง | รง | จร | ปร | ▁บ | ไว้ | ดัง | วิ | ช่วย | ปล | ออก | ัตร | เพ | สิ | แจ | แล | ็จ | ิย์ | ▁พอ | มาร | ค่ | วรร | หมณ์ | คํา | เขา | นั้น | กษ | เย | ข้าง | หมา | เว | ไพร | หลัง | จิต | พราหมณ์ | ้ํา | ▁ถึง | ขอ | ทูล | สาม | ื้อ | วาย | อภ | ทาง | ▁แม | วัง | โฉ | ่ม | จน | ▁เป | ัตริย์ | ื่อง | สั่ง | แม่ | ▁ช | ฝ้า | โฉม | ราช | ฝร | ▁ถ | ฝรั่ง | ิ์ | ลม | แต | ▁เป็น | หาร | ื้น | เห | ้อน | ตาย | ุ่ง | ตัว | อย่าง | ลี | ผู้ | น้อย | ฉัน | ตรี | กุ | ษา | ุทร | ถาม | ของ | พร้อม | ชี | สร | เอ | ุง | พลาง | ตี | สมุทร | หาย | ที | วรรณ | เลี้ | นึก | จึง | หมาย | ▁ด้วย | ขว | ียน | ศึก | ่อง | ต้อง | ลัย | บา | พิ | อุ | สุวรรณ | โย | เรา | กลาง | เฝ้า | กษัตริย์ | สะ | แท | สัย | แจ้ง | หญ | ▁อย่า | รํา | ตรัส | อภัย | ผล | เลย | ียว | ไหน | ้าว | แน | ิดา | ริ | สาว | ิ้ม | เมือง | เล่า | ขัด | ค่อย | ภา | โอ | ่ํา | มัน | ชม | ห์ | ชาย | ัล | นาย | ▁เจ | เสียง | ยิ่ง | รู | ๋ย | เปล | เอา | ▁เส | คง | ตรา | ห้า | ินสมุทร | คอย | หญิง | หนี | ้าน | ญา | คุ | บรร | ▁ประ | กาย | ทหาร | ▁อัน | สิ้น | ทธ | ทอง | ักษ | ลังกา | นิ | พู | ศ์ | ่ว | จา | ใหญ | ที่ยว | มน | ไล | จริง | ▁เจ้า | จํา | ▁บ้าง | บอก | ▁ต่าง | ติ | ▁เข้า | ไม | ศร | อั | เคย | เลี้ยง | กรา | แสน | ▁จน | จับ | พบ | ครั้น | จง | พวก | สี | ไข | ษฐ | เกล | คา | รม | พัก | พัน | ซึ่ง | หนัก | นี | ่าว | กรุง | กล้ง | ▁เหมือน | ครา | เคร | ท้าว | ใส | ▁พวก | ตั้ง | หลง | ล้วน | ▁ไป | ผี | ลํา | นัก | ร้อง | ▁จง | ทรา | หนา | ▁ก็ | กลัว | ▁ที่ | เคียง | อาย | เรือ | ▁แม้น | เต | แค | ยก | พราะ | ใหญ่ | ▁ครั้น | ▁น | แก้ว | ถือ | ▁ได้ | เหลือ'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpe_vocabs = [bpe.id_to_piece(id) for id in range(bpe.get_piece_size())]\n",
    "\" | \".join(bpe_vocabs[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eu6QnnRfQyFj"
   },
   "source": [
    "### User-defined symbols\n",
    "\n",
    "Another important concept to know of is User-defined symbols. These special symbols are reserved for a special purpose \\(e.g.\\, the \\<MASK\\> token used in BERT) and will always be tokenized into one token.\n",
    "\n",
    "Refer to the documentation for ways to add these special tokens to your tokenizer.\n",
    "\n",
    "https://github.com/google/sentencepiece/blob/master/python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QEFOj62ZEdzT"
   },
   "source": [
    "## Train another tokenizer on another domain\n",
    "\n",
    "Now try training another unigram tokenizer on `pantip_text` and we will use it to compare with the unigram tokenizer we trained earlier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus_pantip = \"\\n\".join(pantip_train_text)\n",
    "test_corpus_pantip = \"\\n\".join(pantip_test_text)\n",
    "\n",
    "with open(\"train_corpus_pantip.txt\", \"w\") as f:\n",
    "    f.write(train_corpus_pantip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "O7-QkA1eMZFf"
   },
   "outputs": [],
   "source": [
    "## Train\n",
    "spm.SentencePieceTrainer.train(\n",
    "    input=\"train_corpus_pantip.txt\",\n",
    "    model_prefix=\"unigram_pantip\",\n",
    "    vocab_size=1000,\n",
    "    model_type=\"unigram\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpe_pam = spm.SentencePieceProcessor(model_file='bpe_pam.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R5WOVMbONnYv"
   },
   "source": [
    "## Analyse top tokens on different datasets\n",
    "\n",
    "Use your tokenizers to tokenize the datasets and analyse your most common vocabularies (try 300-400 vocabs with len>1). Hint: tokenize your data and count the tokens.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_pantip_tokenizer = spm.SentencePieceProcessor(model_file='unigram_pantip.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wbfkGcsUrPYS"
   },
   "outputs": [],
   "source": [
    "tokens_pam = defaultdict(lambda: 0.0)\n",
    "for sent in pam_test_text:\n",
    "    tokens = unigram_pam_tokenizer.encode(sent, out_type=str)\n",
    "    for token in tokens:\n",
    "        tokens_pam[token] += 1\n",
    "\n",
    "top_tokens_pam = sorted(tokens_pam.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "tokens_pantip = defaultdict(lambda: 0.0)\n",
    "for sent in pantip_test_text:\n",
    "    tokens = unigram_pantip_tokenizer.encode(sent, out_type=str)\n",
    "    for token in tokens:\n",
    "        tokens_pantip[token] += 1\n",
    "\n",
    "top_tokens_pantip = sorted(tokens_pantip.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('▁', 21314.0),\n",
       " ('เ', 6614.0),\n",
       " ('า', 5493.0),\n",
       " ('น', 5018.0),\n",
       " ('ม', 4969.0),\n",
       " ('ก', 4802.0),\n",
       " ('ย', 4612.0),\n",
       " ('ร', 4409.0),\n",
       " ('ว', 4163.0),\n",
       " ('ส', 3941.0),\n",
       " ('บ', 3857.0),\n",
       " ('ด', 3820.0),\n",
       " ('ง', 3769.0),\n",
       " ('ค', 3051.0),\n",
       " ('มา', 3002.0),\n",
       " ('ท', 2876.0),\n",
       " ('อ', 2857.0),\n",
       " ('ล', 2780.0),\n",
       " ('จะ', 2506.0),\n",
       " ('ห', 2411.0),\n",
       " ('ไป', 2407.0),\n",
       " ('ให้', 2391.0),\n",
       " ('แ', 2271.0),\n",
       " ('ว่า', 2214.0),\n",
       " ('ช', 2098.0),\n",
       " ('ุ', 2087.0),\n",
       " ('ไม่', 2085.0),\n",
       " ('ี', 1996.0),\n",
       " ('พ', 1953.0),\n",
       " ('ข', 1933.0),\n",
       " ('๏', 1923.0),\n",
       " ('ฯ', 1922.0),\n",
       " ('โ', 1789.0),\n",
       " ('ที่', 1632.0),\n",
       " ('เป็น', 1587.0),\n",
       " ('▁จะ', 1580.0),\n",
       " ('พระ', 1561.0),\n",
       " ('ต', 1535.0),\n",
       " ('ะ', 1512.0),\n",
       " ('จ', 1504.0),\n",
       " ('ิ', 1461.0),\n",
       " ('ใจ', 1458.0),\n",
       " ('ก็', 1368.0),\n",
       " ('อยู่', 1339.0),\n",
       " ('ป', 1329.0),\n",
       " ('ั', 1326.0),\n",
       " ('์', 1296.0),\n",
       " ('ไ', 1280.0),\n",
       " ('▁พระ', 1251.0),\n",
       " ('ได้', 1247.0),\n",
       " ('ศ', 1197.0),\n",
       " ('เข้า', 1190.0),\n",
       " ('ู', 1152.0),\n",
       " ('รา', 1128.0),\n",
       " ('ตาม', 1096.0),\n",
       " ('้า', 1086.0),\n",
       " ('▁แล้ว', 1085.0),\n",
       " ('ใน', 1069.0),\n",
       " ('ยา', 1063.0),\n",
       " ('่', 1061.0),\n",
       " ('ลา', 1052.0),\n",
       " ('ํา', 1039.0),\n",
       " ('เจ้า', 1024.0),\n",
       " ('้', 1011.0),\n",
       " ('เหมือน', 1009.0),\n",
       " ('กัน', 976.0),\n",
       " ('หา', 973.0),\n",
       " ('ประ', 944.0),\n",
       " ('อน', 933.0),\n",
       " ('ทรง', 914.0),\n",
       " ('ัง', 914.0),\n",
       " ('เห็น', 910.0),\n",
       " ('ถ', 905.0),\n",
       " ('▁ให้', 898.0),\n",
       " ('าน', 879.0),\n",
       " ('นาง', 875.0),\n",
       " ('ซ', 875.0),\n",
       " ('ัก', 868.0),\n",
       " ('ฉ', 844.0),\n",
       " ('ัด', 837.0),\n",
       " ('ดู', 834.0),\n",
       " ('องค์', 827.0),\n",
       " ('มี', 809.0),\n",
       " ('่า', 801.0),\n",
       " ('▁จึง', 799.0),\n",
       " ('▁นาง', 792.0),\n",
       " ('วน', 782.0),\n",
       " ('พา', 777.0),\n",
       " ('ษ', 771.0),\n",
       " ('แล้ว', 771.0),\n",
       " ('นี้', 770.0),\n",
       " ('่อ', 765.0),\n",
       " ('ด้วย', 760.0),\n",
       " ('ผ', 757.0),\n",
       " ('ลูก', 744.0),\n",
       " ('น้อง', 741.0),\n",
       " ('ทํา', 738.0),\n",
       " ('รัก', 736.0),\n",
       " ('หน', 731.0),\n",
       " ('ภ', 730.0),\n",
       " ('พี่', 719.0),\n",
       " ('การ', 714.0),\n",
       " ('คิด', 712.0),\n",
       " ('พล', 712.0),\n",
       " ('กระ', 710.0),\n",
       " ('รู้', 695.0),\n",
       " ('กับ', 683.0),\n",
       " ('แต่', 677.0),\n",
       " ('หน้า', 670.0),\n",
       " ('ระ', 666.0),\n",
       " ('ออก', 665.0),\n",
       " ('▁ไม่', 662.0),\n",
       " ('ัน', 660.0),\n",
       " ('ธ', 660.0),\n",
       " ('ับ', 656.0),\n",
       " ('เขา', 652.0),\n",
       " ('่ง', 637.0),\n",
       " ('พร', 622.0),\n",
       " ('นั่ง', 620.0),\n",
       " ('ข้า', 620.0),\n",
       " ('คน', 617.0),\n",
       " ('รับ', 616.0),\n",
       " ('ื', 615.0),\n",
       " ('วง', 614.0),\n",
       " ('ดี', 610.0),\n",
       " ('ฝ', 607.0),\n",
       " ('ถึง', 601.0),\n",
       " ('ริ', 597.0),\n",
       " ('▁แต่', 592.0),\n",
       " ('หล', 585.0),\n",
       " ('▁เห็น', 581.0),\n",
       " ('ลง', 578.0),\n",
       " ('กร', 576.0),\n",
       " ('อด', 576.0),\n",
       " ('กล', 574.0),\n",
       " ('สม', 573.0),\n",
       " ('ความ', 573.0),\n",
       " ('ตร', 568.0),\n",
       " ('ทั้ง', 566.0),\n",
       " ('ขึ้น', 566.0),\n",
       " ('เสีย', 564.0),\n",
       " ('ือ', 557.0),\n",
       " ('กลับ', 555.0),\n",
       " ('▁ฝ่าย', 553.0),\n",
       " ('ปร', 544.0),\n",
       " ('มิ', 540.0),\n",
       " ('ขอ', 540.0),\n",
       " ('้น', 539.0),\n",
       " ('หรือ', 534.0),\n",
       " ('ญ', 533.0),\n",
       " ('ยัง', 531.0),\n",
       " ('▁ทั้ง', 528.0),\n",
       " ('เส', 526.0),\n",
       " ('ฟัง', 523.0),\n",
       " ('แม่', 522.0),\n",
       " ('ไว้', 521.0),\n",
       " ('▁พอ', 513.0),\n",
       " ('วัน', 512.0),\n",
       " ('ดัง', 508.0),\n",
       " ('รบ', 504.0),\n",
       " ('น้ํา', 502.0),\n",
       " ('ิน', 502.0),\n",
       " ('อา', 497.0),\n",
       " ('ี่', 493.0),\n",
       " ('ช่วย', 493.0),\n",
       " ('นา', 491.0),\n",
       " ('นั้น', 490.0),\n",
       " ('อง', 489.0),\n",
       " ('ทัพ', 477.0),\n",
       " ('▁มา', 474.0),\n",
       " ('ต้อง', 474.0),\n",
       " ('น้อย', 472.0),\n",
       " ('เรา', 468.0),\n",
       " ('จน', 467.0),\n",
       " ('ปล', 465.0),\n",
       " ('เอา', 462.0),\n",
       " ('สุด', 456.0),\n",
       " ('ละ', 453.0),\n",
       " ('เสียง', 452.0),\n",
       " ('สุ', 451.0),\n",
       " ('ข้าง', 448.0),\n",
       " ('ตี', 446.0),\n",
       " ('ึก', 444.0),\n",
       " ('หลัง', 440.0),\n",
       " ('พิ', 439.0),\n",
       " ('▁ถึง', 436.0),\n",
       " ('ตัว', 436.0),\n",
       " ('วัง', 433.0),\n",
       " ('นาย', 433.0),\n",
       " ('ทูล', 432.0),\n",
       " ('วิ', 431.0),\n",
       " ('่น', 429.0),\n",
       " ('ยง', 429.0),\n",
       " ('อก', 426.0),\n",
       " ('อย่า', 423.0),\n",
       " ('ทุก', 420.0),\n",
       " ('นึก', 417.0),\n",
       " ('ลี', 412.0),\n",
       " ('เฝ้า', 406.0),\n",
       " ('ตา', 403.0),\n",
       " ('ตาย', 398.0),\n",
       " ('ฝรั่ง', 398.0),\n",
       " ('ณ', 394.0),\n",
       " ('▁เป็น', 394.0),\n",
       " ('็', 393.0),\n",
       " ('แล', 392.0),\n",
       " ('อั', 391.0),\n",
       " ('ใคร', 391.0),\n",
       " ('ราช', 390.0),\n",
       " ('ย์', 390.0),\n",
       " ('เรือ', 383.0),\n",
       " ('้ม', 380.0),\n",
       " ('ของ', 372.0),\n",
       " ('สอง', 369.0),\n",
       " ('กษัตริย์', 367.0),\n",
       " ('แสน', 367.0),\n",
       " ('ี้', 367.0),\n",
       " ('ึง', 363.0),\n",
       " ('หาย', 359.0),\n",
       " ('ั่ง', 359.0),\n",
       " ('จิต', 358.0),\n",
       " ('หมาย', 357.0),\n",
       " ('สั่ง', 355.0),\n",
       " ('จึง', 355.0),\n",
       " ('▁ด้วย', 354.0),\n",
       " ('แจ้ง', 352.0),\n",
       " ('นิ', 346.0),\n",
       " ('เห', 346.0),\n",
       " ('ุด', 345.0),\n",
       " ('สาม', 343.0),\n",
       " ('▁อย่า', 342.0),\n",
       " ('เมือง', 341.0),\n",
       " ('ั่น', 340.0),\n",
       " ('สาว', 340.0),\n",
       " ('ฟ', 339.0),\n",
       " ('เหลือ', 339.0),\n",
       " ('กลาง', 338.0),\n",
       " ('ยิ่ง', 336.0),\n",
       " ('ตรัส', 335.0),\n",
       " ('มัน', 333.0),\n",
       " ('ลังกา', 333.0),\n",
       " ('เลย', 332.0),\n",
       " ('เล่า', 331.0),\n",
       " ('ทาง', 329.0),\n",
       " ('ศรี', 328.0),\n",
       " ('ไหน', 328.0),\n",
       " ('้อง', 327.0),\n",
       " ('เคย', 327.0),\n",
       " ('หนี', 326.0),\n",
       " ('ื้อ', 323.0),\n",
       " ('น่า', 322.0),\n",
       " ('ที', 322.0),\n",
       " ('ยก', 321.0),\n",
       " ('ค่อย', 320.0),\n",
       " ('ชาย', 318.0),\n",
       " ('พราหมณ์', 313.0),\n",
       " ('ถาม', 311.0),\n",
       " ('ไร', 306.0),\n",
       " ('สิ้น', 305.0),\n",
       " ('กาย', 305.0),\n",
       " ('ฉัน', 305.0),\n",
       " ('ลม', 304.0),\n",
       " ('บอก', 303.0),\n",
       " ('ชาว', 301.0),\n",
       " ('พ่อ', 301.0),\n",
       " ('คอย', 299.0),\n",
       " ('สงสาร', 298.0),\n",
       " ('สาร', 297.0),\n",
       " ('อบ', 296.0),\n",
       " ('ชม', 295.0),\n",
       " ('จริง', 295.0),\n",
       " ('▁อัน', 291.0),\n",
       " ('คํา', 291.0),\n",
       " ('ตั้ง', 291.0),\n",
       " ('ทหาร', 291.0),\n",
       " ('เที่ยว', 290.0),\n",
       " ('ผู้', 289.0),\n",
       " ('วาย', 288.0),\n",
       " ('ทอง', 287.0),\n",
       " ('ผา', 286.0),\n",
       " ('ศึก', 286.0),\n",
       " ('สิ', 283.0),\n",
       " ('จะได้', 282.0),\n",
       " ('ใหญ่', 281.0),\n",
       " ('ถือ', 281.0),\n",
       " ('สา', 280.0),\n",
       " ('▁บ้าง', 279.0),\n",
       " ('ั้น', 279.0),\n",
       " ('พบ', 279.0),\n",
       " ('พระอภัย', 278.0),\n",
       " ('▁ต่าง', 277.0),\n",
       " ('ม้า', 277.0),\n",
       " ('จับ', 276.0),\n",
       " ('จง', 273.0),\n",
       " ('พลาง', 273.0),\n",
       " ('ล่อ', 271.0),\n",
       " ('พวก', 270.0),\n",
       " ('▁จน', 268.0),\n",
       " ('ลาย', 268.0),\n",
       " ('ไพร่', 267.0),\n",
       " ('ราย', 267.0),\n",
       " ('รอง', 264.0),\n",
       " ('ร้อย', 264.0),\n",
       " ('ล้วน', 263.0),\n",
       " ('▁พวก', 263.0),\n",
       " ('อาย', 262.0),\n",
       " ('พร้อม', 261.0),\n",
       " ('้ว', 261.0),\n",
       " ('ชิง', 260.0),\n",
       " ('พัน', 260.0),\n",
       " ('งาม', 259.0),\n",
       " ('อย่าง', 258.0),\n",
       " ('แกล้ง', 257.0),\n",
       " ('จํา', 254.0),\n",
       " ('เคียง', 252.0),\n",
       " ('เครื่อง', 251.0),\n",
       " ('กลัว', 251.0),\n",
       " ('ลํา', 250.0),\n",
       " ('นี่', 249.0),\n",
       " ('▁จง', 245.0),\n",
       " ('สินสมุทร', 244.0),\n",
       " ('สาย', 241.0),\n",
       " ('แก้ว', 240.0),\n",
       " ('พระองค์', 240.0),\n",
       " ('▁แม้น', 239.0),\n",
       " ('▁ครั้น', 238.0),\n",
       " ('เพราะ', 238.0),\n",
       " ('บน', 236.0),\n",
       " ('ร้อง', 235.0),\n",
       " ('คง', 234.0),\n",
       " ('ต่าง', 232.0),\n",
       " ('ผล', 231.0),\n",
       " ('ห้อง', 229.0),\n",
       " ('สู้', 227.0),\n",
       " ('จาก', 222.0),\n",
       " ('ท่าน', 220.0),\n",
       " ('ขัด', 220.0),\n",
       " ('โห', 219.0),\n",
       " ('เดิน', 217.0),\n",
       " ('หลับ', 217.0),\n",
       " ('เรียก', 216.0),\n",
       " ('ป่า', 216.0),\n",
       " ('นัก', 215.0),\n",
       " ('เหล่า', 215.0),\n",
       " ('กิน', 214.0),\n",
       " ('กุมาร', 214.0),\n",
       " ('ลิ', 212.0),\n",
       " ('คู่', 211.0),\n",
       " ('โศก', 210.0),\n",
       " ('หลง', 209.0),\n",
       " ('ร่ํา', 209.0),\n",
       " ('ู่', 209.0),\n",
       " ('รูป', 208.0),\n",
       " ('▁เมื่อ', 208.0),\n",
       " ('่าย', 207.0),\n",
       " ('โฉม', 205.0),\n",
       " ('จร', 204.0),\n",
       " ('นอน', 204.0),\n",
       " ('ดับ', 204.0),\n",
       " ('แต่ง', 204.0),\n",
       " ('พอ', 204.0),\n",
       " ('ห้าม', 204.0),\n",
       " ('▁ถ้า', 202.0),\n",
       " ('รถ', 202.0),\n",
       " ('ตอบ', 201.0),\n",
       " ('หน่อ', 201.0),\n",
       " ('จัด', 201.0),\n",
       " ('ใช้', 200.0),\n",
       " ('ตรง', 199.0),\n",
       " ('ไล่', 198.0),\n",
       " ('ตรา', 197.0),\n",
       " ('ฐ', 196.0),\n",
       " ('ึ', 195.0),\n",
       " ('แสง', 195.0),\n",
       " ('ไม่มี', 195.0),\n",
       " ('อ่อน', 195.0),\n",
       " ('คืน', 194.0),\n",
       " ('แน่', 194.0),\n",
       " ('แค้น', 194.0),\n",
       " ('ใ', 194.0),\n",
       " ('ใส่', 194.0),\n",
       " ('ชื่น', 193.0),\n",
       " ('ถวาย', 193.0),\n",
       " ('เชิญ', 193.0),\n",
       " ('ชวน', 192.0),\n",
       " ('ฤ', 192.0),\n",
       " ('ติ', 191.0),\n",
       " ('มิได้', 191.0),\n",
       " ('ดอก', 188.0),\n",
       " ('เมีย', 188.0),\n",
       " ('อาลัย', 187.0),\n",
       " ('ขวา', 186.0),\n",
       " ('ุก', 185.0),\n",
       " ('ตก', 185.0),\n",
       " ('ไหว', 185.0),\n",
       " ('้อม', 184.0),\n",
       " ('บิดา', 184.0),\n",
       " ('จัก', 183.0),\n",
       " ('หญิง', 183.0),\n",
       " ('▁แม้', 182.0),\n",
       " ('กล้า', 182.0),\n",
       " ('รณ', 181.0),\n",
       " ('ยศ', 180.0),\n",
       " ('ขาด', 180.0),\n",
       " ('ลับ', 180.0),\n",
       " ('▁ซึ่ง', 178.0),\n",
       " ('บาท', 178.0),\n",
       " ('เสนา', 178.0),\n",
       " ('ตะ', 177.0),\n",
       " ('ติด', 177.0),\n",
       " ('ดํา', 176.0),\n",
       " ('ช่าง', 176.0),\n",
       " ('ความตาม', 175.0),\n",
       " ('เชย', 175.0),\n",
       " ('เสร็จ', 175.0),\n",
       " ('ร้อน', 175.0),\n",
       " ('คุณ', 174.0),\n",
       " ('สัก', 174.0),\n",
       " ('ผัว', 174.0),\n",
       " ('พักตร์', 173.0),\n",
       " ('ยาม', 172.0),\n",
       " ('พราย', 172.0),\n",
       " ('ฟ้า', 171.0),\n",
       " ('้ง', 171.0),\n",
       " ('ลอง', 170.0),\n",
       " ('ไฉน', 170.0),\n",
       " ('ใด', 167.0),\n",
       " ('ผัน', 167.0),\n",
       " ('หนึ่ง', 166.0),\n",
       " ('้อย', 166.0),\n",
       " ('ขับ', 166.0),\n",
       " ('ร้าย', 165.0),\n",
       " ('วิ่ง', 165.0),\n",
       " ('ศรีสุวรรณ', 164.0),\n",
       " ('หมอง', 163.0),\n",
       " ('ก็ไม่', 163.0),\n",
       " ('แก้', 163.0),\n",
       " ('ไฟ', 163.0),\n",
       " ('ปืน', 163.0),\n",
       " ('ฆ่า', 163.0),\n",
       " ('พูด', 162.0),\n",
       " ('อี', 161.0),\n",
       " ('กําลัง', 160.0),\n",
       " ('ผี', 160.0),\n",
       " ('รักษา', 159.0),\n",
       " ('ุ่ม', 159.0),\n",
       " ('หาญ', 159.0),\n",
       " ('เช่น', 159.0),\n",
       " ('เนื้อ', 158.0),\n",
       " ('รีบ', 158.0),\n",
       " ('เล่น', 158.0),\n",
       " ('สี่', 158.0),\n",
       " ('เมื่อ', 157.0),\n",
       " ('ชัย', 157.0),\n",
       " ('ถูก', 157.0),\n",
       " ('บุตรี', 157.0),\n",
       " ('ฟัน', 157.0),\n",
       " ('เอ๋ย', 156.0),\n",
       " ('สงสัย', 156.0),\n",
       " ('ปี', 155.0),\n",
       " ('วาง', 155.0),\n",
       " ('ผิด', 155.0),\n",
       " ('นิ่ง', 155.0),\n",
       " ('สะอื้น', 155.0),\n",
       " ('หลาน', 155.0),\n",
       " ('ชื่อ', 154.0),\n",
       " ('ผ่อน', 154.0),\n",
       " ('ช้า', 154.0),\n",
       " ('เถิด', 154.0),\n",
       " ('กอด', 153.0),\n",
       " ('ปาก', 152.0),\n",
       " ('ชาติ', 152.0),\n",
       " ('แตก', 152.0),\n",
       " ('ชล', 151.0),\n",
       " ('หัก', 151.0),\n",
       " ('ต่อ', 150.0),\n",
       " ('เจ้าพราหมณ์', 149.0),\n",
       " ('หมอ', 149.0),\n",
       " ('พี่เลี้ยง', 148.0),\n",
       " ('นอก', 148.0),\n",
       " ('พลอย', 148.0),\n",
       " ('ทั้งสอง', 147.0),\n",
       " ('โฉมยง', 147.0),\n",
       " ('เนตร', 146.0),\n",
       " ('บ้าง', 146.0),\n",
       " ('ค่ํา', 144.0),\n",
       " ('ยิ้ม', 143.0),\n",
       " ('มือ', 143.0),\n",
       " ('ซ้ํา', 142.0),\n",
       " ('ขวัญ', 142.0),\n",
       " ('อารมณ์', 141.0),\n",
       " ('ทุกข์', 141.0),\n",
       " ('แขก', 141.0),\n",
       " ('หนักหนา', 140.0),\n",
       " ('เย็น', 140.0),\n",
       " ('นาม', 139.0),\n",
       " ('ปิด', 139.0),\n",
       " ('ตัด', 139.0),\n",
       " ('กราบ', 138.0),\n",
       " ('ั้ง', 138.0),\n",
       " ('เรียง', 138.0),\n",
       " ('โปรด', 138.0),\n",
       " ('กําปั่น', 138.0),\n",
       " ('สิ่ง', 137.0),\n",
       " ('แรง', 137.0),\n",
       " ('ขัน', 136.0),\n",
       " ('ต้น', 136.0),\n",
       " ('เศร้า', 136.0),\n",
       " ('วงศ์', 135.0),\n",
       " ('ท้าว', 135.0),\n",
       " ('เสด็จ', 135.0),\n",
       " ('เวลา', 135.0),\n",
       " ('ผลึก', 135.0),\n",
       " ('ชิด', 134.0),\n",
       " ('มนต์', 133.0),\n",
       " ('ล้อม', 133.0),\n",
       " ('สวาท', 132.0),\n",
       " ('หยุด', 132.0),\n",
       " ('เคือง', 132.0),\n",
       " ('มาถึง', 131.0),\n",
       " ('ชอบ', 131.0),\n",
       " ('ผ้า', 131.0),\n",
       " ('โยธา', 131.0),\n",
       " ('ดวง', 130.0),\n",
       " ('แล่น', 130.0),\n",
       " ('ไกล', 130.0),\n",
       " ('โอรส', 129.0),\n",
       " ('แห่', 129.0),\n",
       " ('หวัง', 129.0),\n",
       " ('สบาย', 129.0),\n",
       " ('ใกล้', 129.0),\n",
       " ('ลอย', 129.0),\n",
       " ('อย่างไร', 128.0),\n",
       " ('แก่', 127.0),\n",
       " ('ควร', 127.0),\n",
       " ('มิให้', 126.0),\n",
       " ('เลี้ยง', 126.0),\n",
       " ('ลืม', 125.0),\n",
       " ('เดือน', 125.0),\n",
       " ('ฌ', 125.0),\n",
       " ('เหตุ', 124.0),\n",
       " ('งค์', 123.0),\n",
       " ('หลาย', 123.0),\n",
       " ('บ้าน', 123.0),\n",
       " ('ไม้', 123.0),\n",
       " ('ไหล', 123.0),\n",
       " ('ส่ง', 122.0),\n",
       " ('มารดา', 122.0),\n",
       " ('ประสา', 122.0),\n",
       " ('นุช', 121.0),\n",
       " ('่ํา', 120.0),\n",
       " ('หนัก', 120.0),\n",
       " ('ทัน', 120.0),\n",
       " ('ฆ', 120.0),\n",
       " ('บรร', 119.0),\n",
       " ('ลุก', 119.0),\n",
       " ('บังคม', 119.0),\n",
       " ('ห่าง', 119.0),\n",
       " ('โกรธ', 118.0),\n",
       " ('ด่าน', 118.0),\n",
       " ('โทษ', 118.0),\n",
       " ('ผูก', 118.0),\n",
       " ('▁โอ้', 118.0),\n",
       " ('เช้า', 118.0),\n",
       " ('น้ําตา', 118.0),\n",
       " ('ตื่น', 117.0),\n",
       " ('ียว', 117.0),\n",
       " ('ผู้หญิง', 116.0),\n",
       " ('สว่าง', 116.0),\n",
       " ('ฤทธิ์', 116.0),\n",
       " ('กรุง', 115.0),\n",
       " ('ยุพา', 115.0),\n",
       " ('สําราญ', 114.0),\n",
       " ('ทั้งสาม', 114.0),\n",
       " ('ศักดิ์', 114.0),\n",
       " ('กล่าว', 114.0),\n",
       " ('ประคอง', 113.0),\n",
       " ('ร่าง', 113.0),\n",
       " ('คํานับ', 113.0),\n",
       " ('เขต', 113.0),\n",
       " ('ลั่น', 111.0),\n",
       " ('สัย', 111.0),\n",
       " ('รุ่ง', 110.0),\n",
       " ('สุดสาคร', 110.0),\n",
       " ('แท่น', 109.0),\n",
       " ('ปี่', 109.0),\n",
       " ('พงศ์', 109.0),\n",
       " ('กระไร', 109.0),\n",
       " ('ทิ้ง', 109.0),\n",
       " ('ทรวง', 109.0),\n",
       " ('บุญ', 109.0),\n",
       " ('เกรง', 108.0),\n",
       " ('เสือ', 107.0),\n",
       " ('เธอ', 106.0),\n",
       " ('เกาะ', 106.0),\n",
       " ('ธิดา', 106.0),\n",
       " ('ยืน', 105.0),\n",
       " ('ม้วย', 105.0),\n",
       " ('พึ่ง', 104.0),\n",
       " ('นวล', 104.0),\n",
       " ('เดี๋ยวนี้', 104.0),\n",
       " ('ล้ํา', 103.0),\n",
       " ('ฝ่าย', 103.0),\n",
       " ('ประโลม', 101.0),\n",
       " ('สงคราม', 101.0),\n",
       " ('สรรพ', 101.0),\n",
       " ('สําคัญ', 101.0),\n",
       " ('เพียง', 100.0),\n",
       " ('เนิน', 100.0),\n",
       " ('ใบ', 100.0),\n",
       " ('หมด', 100.0),\n",
       " ('ร่วม', 100.0),\n",
       " ('ทั้งซ้ายขวา', 100.0),\n",
       " ('เรื่อง', 100.0),\n",
       " ('ครื้น', 100.0),\n",
       " ('รัตน์', 99.0),\n",
       " ('หวั่น', 99.0),\n",
       " ('เฒ่า', 99.0),\n",
       " ('กรรม', 99.0),\n",
       " ('เท่า', 99.0),\n",
       " ('ขืน', 99.0),\n",
       " ('เร่ง', 99.0),\n",
       " ('๋', 99.0),\n",
       " ('วัณฬา', 99.0),\n",
       " ('ประทาน', 98.0),\n",
       " ('ครั้ง', 97.0),\n",
       " ('ฮ', 97.0),\n",
       " ('ธานี', 96.0),\n",
       " ('ชีวิต', 96.0),\n",
       " ('จะใคร่', 96.0),\n",
       " ('พลัด', 96.0),\n",
       " ('เดียว', 96.0),\n",
       " ('สัญญา', 96.0),\n",
       " ('ผ่อง', 95.0),\n",
       " ('ประสงค์', 95.0),\n",
       " ('พลางทาง', 95.0),\n",
       " ('ยิง', 95.0),\n",
       " ('ชั้น', 95.0),\n",
       " ('ฏ', 94.0),\n",
       " ('ฤทัย', 94.0),\n",
       " ('เลี้ยว', 94.0),\n",
       " ('พระธิดา', 94.0),\n",
       " ('บุรี', 93.0),\n",
       " ('แก้ไข', 93.0),\n",
       " ('เทว', 93.0),\n",
       " ('หม่อม', 93.0),\n",
       " ('หลวง', 93.0),\n",
       " ('บุตร', 92.0),\n",
       " ('รําคาญ', 92.0),\n",
       " ('เจ็บ', 91.0),\n",
       " ('ก่อน', 91.0),\n",
       " ('ทราบ', 91.0),\n",
       " ('อุศเรน', 91.0),\n",
       " ('ลูบ', 90.0),\n",
       " ('พูดจา', 90.0),\n",
       " ('สารพัด', 90.0),\n",
       " ('อ่าน', 90.0),\n",
       " ('ผีเสื้อ', 90.0),\n",
       " ('ฎ', 90.0),\n",
       " ('ุ้ง', 90.0),\n",
       " ('กองทัพ', 90.0),\n",
       " ('เกิด', 89.0),\n",
       " ('เกณฑ์', 89.0),\n",
       " ('สําเร็จ', 89.0),\n",
       " ('รื่น', 89.0),\n",
       " ('มารศรี', 89.0),\n",
       " ('บัลลังก์', 88.0),\n",
       " ('ปรึกษา', 88.0),\n",
       " ('อาสัญ', 88.0),\n",
       " ('พลับพลา', 88.0),\n",
       " ('หัตถ์', 87.0),\n",
       " ('เสวย', 87.0),\n",
       " ('คิดอ่าน', 87.0),\n",
       " ('ครึ', 87.0),\n",
       " ('คลื่น', 87.0),\n",
       " ('รับสั่ง', 87.0),\n",
       " ('ท้าวเจ้า', 87.0),\n",
       " ('สนม', 86.0),\n",
       " ('ภัย', 86.0),\n",
       " ('สถาน', 86.0),\n",
       " ('พระเชษฐา', 86.0),\n",
       " ('เปล่า', 86.0),\n",
       " ('พาที', 86.0),\n",
       " ('ฟื้น', 86.0),\n",
       " ('ประตู', 86.0),\n",
       " ('รําภา', 86.0),\n",
       " ('จิตคิด', 85.0),\n",
       " ('แย้ม', 85.0),\n",
       " ('สรง', 84.0),\n",
       " ('ฆ้อง', 84.0),\n",
       " ('ินทร์', 84.0),\n",
       " ('พระทัย', 84.0),\n",
       " ('ป้อม', 84.0),\n",
       " ('ทะเล', 83.0),\n",
       " ('เลีย', 83.0),\n",
       " ('เกี้ยว', 83.0),\n",
       " ('ลัย', 83.0),\n",
       " ('เพชร', 83.0),\n",
       " ('บรรทม', 83.0),\n",
       " ('ฮึก', 83.0),\n",
       " ('วิชา', 82.0),\n",
       " ('ข้าศึก', 82.0),\n",
       " ('โรค', 82.0),\n",
       " ('สําหรับ', 82.0),\n",
       " ('ครู', 81.0),\n",
       " ('ซึ่ง', 81.0),\n",
       " ('กลืน', 81.0),\n",
       " ('สวัสดิ์', 80.0),\n",
       " ('มัว', 80.0),\n",
       " ('สัตย์', 80.0),\n",
       " ('มเหสี', 80.0),\n",
       " ('ชนนี', 79.0),\n",
       " ('ประณต', 79.0),\n",
       " ('แข็ง', 79.0),\n",
       " ('บรรลัย', 79.0),\n",
       " ('หวาน', 78.0),\n",
       " ('ชีวา', 78.0),\n",
       " ('มิใช่', 78.0),\n",
       " ('นารี', 78.0),\n",
       " ('กรุงศรี', 78.0),\n",
       " ('ฉลาด', 77.0),\n",
       " ('ไต่ถาม', 77.0),\n",
       " ('ราตรี', 77.0),\n",
       " ('ฉวย', 77.0),\n",
       " ('ปลอบ', 77.0),\n",
       " ('จอม', 77.0),\n",
       " ('ทั้งหลาย', 77.0),\n",
       " ('สุวรรณ', 76.0),\n",
       " ('ฑ', 76.0),\n",
       " ('สนอง', 76.0),\n",
       " ('ถอย', 76.0),\n",
       " ('▁ส่วน', 76.0),\n",
       " ('แคลง', 76.0),\n",
       " ('แทง', 76.0),\n",
       " ('สําเนียง', 75.0),\n",
       " ('เคราะห์', 75.0),\n",
       " ('ตรวจ', 75.0),\n",
       " ('เกศ', 75.0),\n",
       " ('ประจัญ', 75.0),\n",
       " ('หม่อมฉัน', 75.0),\n",
       " ('ท้าย', 74.0),\n",
       " ('ละออง', 74.0),\n",
       " ('เสียดาย', 74.0),\n",
       " ('หลีก', 73.0),\n",
       " ('รบพุ่ง', 73.0),\n",
       " ('หัว', 72.0),\n",
       " ('ฝาก', 72.0),\n",
       " ('อ้าย', 72.0),\n",
       " ('อุตส่าห์', 72.0),\n",
       " ('ชาญ', 71.0),\n",
       " ('อาจารย์', 71.0),\n",
       " ('แทน', 71.0),\n",
       " ('เวียน', 71.0),\n",
       " ('หนังสือ', 70.0),\n",
       " ('สรวล', 70.0),\n",
       " ('เมิน', 70.0),\n",
       " ('คลาด', 70.0),\n",
       " ('หมื่น', 70.0),\n",
       " ('เชื้อ', 69.0),\n",
       " ('เรียน', 69.0),\n",
       " ('เชษฐา', 69.0),\n",
       " ('วิสัย', 69.0),\n",
       " ('ผลาญ', 69.0),\n",
       " ('ปราสาท', 69.0),\n",
       " ('เคลื่อน', 69.0),\n",
       " ('เพื่อน', 68.0),\n",
       " ('คงคา', 68.0),\n",
       " ('บิตุรงค์', 67.0),\n",
       " ('สนิท', 67.0),\n",
       " ('เหลียว', 67.0),\n",
       " ('ประเทศ', 67.0),\n",
       " ('ทั่ว', 67.0),\n",
       " ('ประทับ', 67.0),\n",
       " ('ซื่อ', 67.0),\n",
       " ('ตลบ', 67.0),\n",
       " ('พระอนุชา', 66.0),\n",
       " ('สมุทร', 66.0),\n",
       " ('กรุงไกร', 65.0),\n",
       " ('ครัน', 65.0),\n",
       " ('จันทร์', 65.0),\n",
       " ('แถลง', 65.0),\n",
       " ('อดสู', 65.0),\n",
       " ('ัณฑ์', 65.0),\n",
       " ('คลอ', 65.0),\n",
       " ('อื่น', 65.0),\n",
       " ('บาทหลวง', 65.0),\n",
       " ('สนั่น', 64.0),\n",
       " ('เขียน', 64.0),\n",
       " ('กลิ่น', 64.0),\n",
       " ('คุม', 64.0),\n",
       " ('อาสน์', 63.0),\n",
       " ('ยินดี', 63.0),\n",
       " ('เงือก', 63.0),\n",
       " ('ขุนนาง', 63.0),\n",
       " ('แถลงไข', 62.0),\n",
       " ('หยิบ', 62.0),\n",
       " ('ประหลาด', 62.0),\n",
       " ('ชู้', 62.0),\n",
       " ('ขัดขวาง', 62.0),\n",
       " ('อภิวาท', 62.0),\n",
       " ('หวาด', 61.0),\n",
       " ('นักหนา', 61.0),\n",
       " ('ชีวัน', 61.0),\n",
       " ('ข่าว', 61.0),\n",
       " ('ปรางค์', 61.0),\n",
       " ('เลือด', 61.0),\n",
       " ('เพลง', 60.0),\n",
       " ('สูญ', 60.0),\n",
       " ('เปลื้อง', 60.0),\n",
       " ('เตรียม', 60.0),\n",
       " ('ฟาด', 60.0),\n",
       " ('กําแพง', 59.0),\n",
       " ('พี่น้องสอง', 59.0),\n",
       " ('กระจ่าง', 59.0),\n",
       " ('ปัญญา', 59.0),\n",
       " ('แปลง', 59.0),\n",
       " ('เจียว', 59.0),\n",
       " ('ว่าขาน', 59.0),\n",
       " ('พร้อมพรั่ง', 59.0),\n",
       " ('ละเวงวัณฬา', 59.0),\n",
       " ('ทํานอง', 58.0),\n",
       " ('เภตรา', 58.0),\n",
       " ('จูบ', 58.0),\n",
       " ('ภาษา', 58.0),\n",
       " ('ไสว', 58.0),\n",
       " ('ร้าง', 58.0),\n",
       " ('สมทบ', 58.0),\n",
       " ('หยุดยั้ง', 57.0),\n",
       " ('ประการใด', 57.0),\n",
       " ('ล่วง', 56.0),\n",
       " ('วิญญาณ์', 56.0),\n",
       " ('ฬ', 56.0),\n",
       " ('บรรดา', 56.0),\n",
       " ('▁นางฟังคํา', 56.0),\n",
       " ('▁สินสมุทรสุด', 56.0),\n",
       " ('สําเภา', 55.0),\n",
       " ('พิสมัย', 55.0),\n",
       " ('เปลี่ยว', 55.0),\n",
       " ('คลั่ง', 55.0),\n",
       " ('ธรรม', 55.0),\n",
       " ('เปรียบ', 54.0),\n",
       " ('โยคี', 54.0),\n",
       " ('ล่ห์', 54.0),\n",
       " ('อํามาตย์', 54.0),\n",
       " ('ญาติ', 54.0),\n",
       " ('อาศัย', 54.0),\n",
       " ('มนุษย์', 54.0),\n",
       " ('พลิก', 54.0),\n",
       " ('กระบวน', 54.0),\n",
       " ('ภูวไนย', 54.0),\n",
       " ('เข็ญ', 54.0),\n",
       " ('กลิ้ง', 54.0),\n",
       " ('ทูต', 54.0),\n",
       " ('กระดาษ', 54.0),\n",
       " ('สุวรรณมาลี', 54.0),\n",
       " ('รักใคร่', 53.0),\n",
       " ('ธุระ', 53.0),\n",
       " ('ได้ยิน', 53.0),\n",
       " ('ถนอม', 53.0),\n",
       " ('แคล้ว', 53.0),\n",
       " ('โยธี', 53.0),\n",
       " ('แผ่นดิน', 53.0),\n",
       " ('สิงหล', 53.0),\n",
       " ('เศษ', 52.0),\n",
       " ('กํานัล', 52.0),\n",
       " ('คะนึง', 52.0),\n",
       " ('บํารุง', 52.0),\n",
       " ('ชั่ว', 52.0),\n",
       " ('ตํารา', 52.0),\n",
       " ('ครวญ', 52.0),\n",
       " ('เกษรา', 52.0),\n",
       " ('ละห้อย', 52.0),\n",
       " ('พรั่งพร้อม', 52.0),\n",
       " ('รําลึก', 52.0),\n",
       " ('▁ฝ่ายโฉมยงองค์', 52.0),\n",
       " ('ลักษณ์', 51.0),\n",
       " ('ปรารถนา', 51.0),\n",
       " ('อาวรณ์', 51.0),\n",
       " ('หน่อนาถ', 51.0),\n",
       " ('เมตตา', 51.0),\n",
       " ('แฝง', 51.0),\n",
       " ('พรุ่งนี้', 51.0),\n",
       " ('ว่าถ้า', 51.0),\n",
       " ('เหน็บ', 51.0),\n",
       " ('ปิ่น', 51.0),\n",
       " ('ทรงธรรม์', 51.0),\n",
       " ('เจ็ด', 50.0),\n",
       " ('เบื่อ', 50.0),\n",
       " ('เต็ม', 50.0),\n",
       " ('เด็ก', 50.0),\n",
       " ('ไม้เท้า', 50.0),\n",
       " ('ยุทธ์', 49.0),\n",
       " ('ๅ', 49.0),\n",
       " ('วุ่น', 49.0),\n",
       " ('๊', 49.0),\n",
       " ('นงลักษณ์', 48.0),\n",
       " ('สมเด็จ', 48.0),\n",
       " ('สวรรค์', 48.0),\n",
       " ('▁หน่อกษัตริย์', 48.0),\n",
       " ('▁ศรีสุวรรณนั้น', 48.0),\n",
       " ('จริต', 48.0),\n",
       " ('ใต้', 48.0),\n",
       " ('แสร้ง', 48.0),\n",
       " ('เพลิง', 48.0),\n",
       " ('หน่วง', 48.0),\n",
       " ('ตรึกตรา', 48.0),\n",
       " ('สาวสุรางค์', 48.0),\n",
       " ('รู้สึก', 48.0),\n",
       " ('บิดร', 48.0),\n",
       " ('เยื้อง', 47.0),\n",
       " ('เพลิน', 47.0),\n",
       " ('ลําบาก', 47.0),\n",
       " ('อะไร', 47.0),\n",
       " ('ปราศรัย', 47.0),\n",
       " ('มัจฉา', 47.0),\n",
       " ('อุ้ม', 47.0),\n",
       " ('กําสรด', 47.0),\n",
       " ('ถิ่น', 47.0),\n",
       " ('สังเกต', 47.0),\n",
       " ('ป้องกัน', 46.0),\n",
       " ('ปรานี', 46.0),\n",
       " ('บิตุเรศ', 45.0),\n",
       " ('แผ่น', 45.0),\n",
       " ('วิเชียร', 45.0),\n",
       " ('กลุ้ม', 45.0),\n",
       " ('ไมตรี', 45.0),\n",
       " ('ตะลึง', 45.0),\n",
       " ('พหลพล', 45.0),\n",
       " ('ประมาณ', 44.0),\n",
       " ('อาวุธ', 44.0),\n",
       " ('กษัตรา', 44.0),\n",
       " ('สิงขร', 44.0),\n",
       " ('นิจจาเอ๋ย', 44.0),\n",
       " ('หยิก', 44.0),\n",
       " ('สําอาง', 44.0),\n",
       " ('เขนย', 44.0),\n",
       " ('จัดแจง', 44.0),\n",
       " ('เคล้า', 43.0),\n",
       " ('ยิ้มพริ้ม', 43.0),\n",
       " ('ยับยั้ง', 43.0),\n",
       " ('เลี่ยง', 43.0),\n",
       " ('เล็ก', 43.0),\n",
       " ('ชํานาญ', 42.0),\n",
       " ('เลือก', 42.0),\n",
       " ('สุริย์', 42.0),\n",
       " ('รมจักร', 42.0),\n",
       " ('บัดสี', 42.0),\n",
       " ('หลงใหล', 42.0),\n",
       " ('ไสยาสน์', 42.0),\n",
       " ('อัคเรศ', 42.0),\n",
       " ('เตือน', 41.0),\n",
       " ('แอบแนบ', 41.0),\n",
       " ('ท่วงที', 41.0),\n",
       " ('ผ่านเกล้า', 41.0),\n",
       " ('ชําเลือง', 40.0),\n",
       " ('เจริญ', 40.0),\n",
       " ('เอ็นดู', 40.0),\n",
       " ('ประชวร', 40.0),\n",
       " ('เหนื่อย', 39.0),\n",
       " ('พระอภัยมณี', 39.0),\n",
       " ('มารดร', 39.0),\n",
       " ('หัวร่อ', 39.0),\n",
       " ('เรียบ', 39.0),\n",
       " ('ตรึกตรอง', 39.0),\n",
       " ('ท้าวทศวงศ์', 39.0),\n",
       " ('โปรดปราน', 39.0),\n",
       " ('คล้าย', 39.0),\n",
       " ('นัดดา', 39.0),\n",
       " ('อิ่ม', 38.0),\n",
       " ('เคลิ้ม', 38.0),\n",
       " ('กิจจา', 38.0),\n",
       " ('ขัดข้อง', 38.0),\n",
       " ('ร้องไห้', 38.0),\n",
       " ('เจียน', 38.0),\n",
       " ('ณรงค์', 38.0),\n",
       " ('รอบขอบ', 38.0),\n",
       " ('นิเวศน์', 38.0),\n",
       " ('ใหม่', 38.0),\n",
       " ('จํารัส', 38.0),\n",
       " ('สมบัติ', 37.0),\n",
       " ('แจ่ม', 37.0),\n",
       " ('เบือน', 37.0),\n",
       " ('จํานรรจา', 37.0),\n",
       " ('บูรี', 37.0),\n",
       " ('สุคนธ์', 37.0),\n",
       " ('หัวเราะ', 37.0),\n",
       " ('ชีวี', 37.0),\n",
       " ('ทั้งไพร่นาย', 37.0),\n",
       " ('อังกุหร่า', 37.0),\n",
       " ('ย่องตอด', 37.0),\n",
       " ('หรรษา', 36.0),\n",
       " ('โบราณ', 36.0),\n",
       " ('เขม้น', 36.0),\n",
       " ('ปีศาจ', 36.0),\n",
       " ('กระจาย', 36.0),\n",
       " ('สังวาล', 36.0),\n",
       " ('รอรั้ง', 36.0),\n",
       " ('ฤกษ์', 36.0),\n",
       " ('คลาไคล', 36.0),\n",
       " ('สุรางค์นาง', 34.0),\n",
       " ...]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_tokens_pam "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qz0GdZ-5YYM9"
   },
   "source": [
    "### To answer\n",
    "\n",
    "What are some notable differences you see between the two vocabs?\n",
    "\n",
    "Write your answer below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QxxYr0QLbDoU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ipjO87HPYl4N"
   },
   "source": [
    "## Using tokenizer across domains\n",
    "\n",
    "One problem you may face is your dataset is very specialized. In that case the tokenizer trained on a general domain may not perform as good as it should when used on your dataset.\n",
    "\n",
    "Next you will try using tokenizers trained on one general domain (on Pantip) and use it on a specialized domain (พระอภัยมณี) and vice versa.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I4_6JG_l5BXh"
   },
   "source": [
    "### Q3 MCV\n",
    "\n",
    "What percentage increase do you observe when tokenizing the whole พระอภัยมณี dataset with a tokenizer trained on Pantip compared to the one trained on พระอภัยมณี.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3tCh1RaZrTAM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "duaCJRO96SX1"
   },
   "source": [
    "### Q4 MCV\n",
    "\n",
    "What percentage increase do you observe when tokenizing the whole Pantip dataset with a tokenizer trained on พระอภัยมณี compared to the one trained on Pantip.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "axk9gOIgrTYd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yZYKuamv7-wI"
   },
   "source": [
    "### To answer\n",
    "\n",
    "Why do you think the number of tokens tokenized by the general tokenizer (the one trained on Pantip) has a higher percentage increase compared to the number of tokens tokenized by the specialized tokenizer? (Hint: we fixed vocab size.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gh9a6d7Q8ivJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O7j_Cc0p9-5S"
   },
   "source": [
    "## The effect on language models\n",
    "\n",
    "Next, we will see the effect of using \"cross-domain\" tokenizers on Language models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KiWztANvohhn"
   },
   "source": [
    "### Setup\n",
    "\n",
    "We are going to reuse the code from the last assignment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7pVtSbmVpwOo"
   },
   "outputs": [],
   "source": [
    "!pip install lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JMt5GzLrW4x3"
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import lightning as L\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0OIs_VS_oo1M"
   },
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, seq_len=128):\n",
    "\n",
    "        token_ids = [tokenizer.encode(d, add_bos=True, add_eos=True) for d in data]\n",
    "        flatten_token_ids = list(itertools.chain(*token_ids))\n",
    "        encoded = torch.LongTensor(flatten_token_ids)\n",
    "\n",
    "        left_over = len(encoded) % seq_len\n",
    "        encoded = encoded[: len(encoded) - left_over]\n",
    "        self.encoded = encoded.view(-1, seq_len)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.encoded[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hk6vEPiMq34n"
   },
   "outputs": [],
   "source": [
    "class LSTM(L.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size,\n",
    "        embedding_dim,\n",
    "        hidden_dim,\n",
    "        num_layers,\n",
    "        dropout_rate,\n",
    "        learning_rate,\n",
    "        criterion,\n",
    "    ):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(\n",
    "            embedding_dim,\n",
    "            hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout_rate,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "        self.learning_rate = learning_rate\n",
    "        self.criterion = criterion\n",
    "\n",
    "    def forward(self, src):\n",
    "        pass\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "\n",
    "        src = batch[:, :-1]\n",
    "        target = batch[:, 1:]\n",
    "        prediction = self(src)\n",
    "        prediction = prediction.reshape(-1, self.vocab_size)\n",
    "        target = target.reshape(-1)\n",
    "        loss = self.criterion(prediction, target)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "\n",
    "        src = batch[:, :-1]\n",
    "        target = batch[:, 1:]\n",
    "        with torch.no_grad():\n",
    "            prediction = self(src)\n",
    "        prediction = prediction.reshape(-1, self.vocab_size)\n",
    "        target = target.reshape(-1)\n",
    "        loss = self.criterion(prediction, target)\n",
    "        self.log(\"test_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.parameters(), lr=self.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oKhuOygixndB"
   },
   "outputs": [],
   "source": [
    "vocab_size = sp_pam.get_piece_size()\n",
    "embedding_dim = 200\n",
    "hidden_dim = 512\n",
    "num_layers = 3\n",
    "dropout_rate = 0.2\n",
    "lr = 1e-3\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "train_batch_size = 64\n",
    "test_batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kOtOE7mr-heY"
   },
   "source": [
    "### Training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g8-x9HiPDcpE"
   },
   "source": [
    "<a name=\"no1\"></a>\n",
    "\n",
    "#### 1. Training on Pantip data with Pantip tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oUv_A4MTx0Ob"
   },
   "outputs": [],
   "source": [
    "trainer = L.Trainer(max_epochs=10, deterministic=True)\n",
    "model = LSTM(\n",
    "    vocab_size, embedding_dim, hidden_dim, num_layers, dropout_rate, lr, criterion\n",
    ")\n",
    "\n",
    "pantip_train_dataset = TextDataset(pantip_train_text, sp_pantip)\n",
    "pantip_train_loader = DataLoader(\n",
    "    pantip_train_dataset, batch_size=train_batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "pantip_test_dataset = TextDataset(pantip_test_text, sp_pantip)\n",
    "pantip_test_loader = DataLoader(\n",
    "    pantip_test_dataset, batch_size=test_batch_size, shuffle=False\n",
    ")\n",
    "\n",
    "pam_train_dataset = TextDataset(pam_train_text, sp_pantip)\n",
    "pam_train_loader = DataLoader(\n",
    "    pam_train_dataset, batch_size=train_batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "pam_test_dataset = TextDataset(pam_test_text, sp_pantip)\n",
    "pam_test_loader = DataLoader(\n",
    "    pam_test_dataset, batch_size=test_batch_size, shuffle=False\n",
    ")\n",
    "\n",
    "trainer.fit(model, train_dataloaders=pantip_train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1e-Y1_GYy65g"
   },
   "outputs": [],
   "source": [
    "test_result = trainer.test(\n",
    "    model,\n",
    "    dataloaders=[\n",
    "        pantip_train_loader,\n",
    "        pam_train_loader,\n",
    "        pantip_test_loader,\n",
    "        pam_test_loader,\n",
    "    ],\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Perplexity on Pantip train set is:\\t{np.exp(test_result[0]['test_loss/dataloader_idx_0'])}\"\n",
    ")\n",
    "print(\n",
    "    f\"Perplexity on Pra apai manee train set is:\\t{np.exp(test_result[1]['test_loss/dataloader_idx_1'])}\"\n",
    ")\n",
    "print(\n",
    "    f\"Perplexity on Pantip test set is:\\t{np.exp(test_result[2]['test_loss/dataloader_idx_2'])}\"\n",
    ")\n",
    "print(\n",
    "    f\"Perplexity on Pra apai manee test set is:\\t{np.exp(test_result[3]['test_loss/dataloader_idx_3'])}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7s3AmE4nDjmL"
   },
   "source": [
    "<a name=\"no2\"></a>\n",
    "\n",
    "#### 2. Training on Pantip data with Pra apai manee tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vfRdW3m1Dmj_"
   },
   "outputs": [],
   "source": [
    "trainer = L.Trainer(max_epochs=10, deterministic=True)\n",
    "model = LSTM(\n",
    "    vocab_size, embedding_dim, hidden_dim, num_layers, dropout_rate, lr, criterion\n",
    ")\n",
    "\n",
    "pantip_train_dataset = TextDataset(pantip_train_text, sp_pam)\n",
    "pantip_train_loader = DataLoader(\n",
    "    pantip_train_dataset, batch_size=train_batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "pantip_test_dataset = TextDataset(pantip_test_text, sp_pam)\n",
    "pantip_test_loader = DataLoader(\n",
    "    pantip_test_dataset, batch_size=test_batch_size, shuffle=False\n",
    ")\n",
    "\n",
    "pam_train_dataset = TextDataset(pam_train_text, sp_pam)\n",
    "pam_train_loader = DataLoader(\n",
    "    pam_train_dataset, batch_size=train_batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "pam_test_dataset = TextDataset(pam_test_text, sp_pam)\n",
    "pam_test_loader = DataLoader(\n",
    "    pam_test_dataset, batch_size=test_batch_size, shuffle=False\n",
    ")\n",
    "\n",
    "trainer.fit(model, train_dataloaders=pantip_train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xwLN1IarD3g9"
   },
   "outputs": [],
   "source": [
    "test_result = trainer.test(\n",
    "    model,\n",
    "    dataloaders=[\n",
    "        pantip_train_loader,\n",
    "        pam_train_loader,\n",
    "        pantip_test_loader,\n",
    "        pam_test_loader,\n",
    "    ],\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Perplexity on Pantip train set is:\\t{np.exp(test_result[0]['test_loss/dataloader_idx_0'])}\"\n",
    ")\n",
    "print(\n",
    "    f\"Perplexity on Pra apai manee train set is:\\t{np.exp(test_result[1]['test_loss/dataloader_idx_1'])}\"\n",
    ")\n",
    "print(\n",
    "    f\"Perplexity on Pantip test set is:\\t{np.exp(test_result[2]['test_loss/dataloader_idx_2'])}\"\n",
    ")\n",
    "print(\n",
    "    f\"Perplexity on Pra apai manee test set is:\\t{np.exp(test_result[3]['test_loss/dataloader_idx_3'])}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NB8zqptTWcA6"
   },
   "source": [
    "#### To answer\n",
    "\n",
    "The perplexity numbers should indicate that:\n",
    "\n",
    "1. Training the LM with Pra apai manee tokenizer on Pantip (no. [2](#no2)) results in overfitting to Pantip and poor generalization to the Pra apai manee dataset.\n",
    "2. However using the Pantip tokenizer (no. [1](#no1)) results in a much better generalization.\n",
    "\n",
    "Try and come up with some reasons for the results above. <br>\n",
    "Hint:\n",
    "\n",
    "1. think about \"general\" vocabs and domain-specific vocabs.\n",
    "2. what do you think happens to the model when the token ids become longer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TmHGQf2saPj_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y8VPMm7pLdSl"
   },
   "source": [
    "<a name=\"no3\"></a>\n",
    "\n",
    "#### 3. Training on Pra apai manee data with Pantip tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oR5fp-YCLnnU"
   },
   "outputs": [],
   "source": [
    "trainer = L.Trainer(max_epochs=10, deterministic=True)\n",
    "model = LSTM(\n",
    "    vocab_size, embedding_dim, hidden_dim, num_layers, dropout_rate, lr, criterion\n",
    ")\n",
    "\n",
    "pantip_train_dataset = TextDataset(pantip_train_text, sp_pantip)\n",
    "pantip_train_loader = DataLoader(\n",
    "    pantip_train_dataset, batch_size=train_batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "pantip_test_dataset = TextDataset(pantip_test_text, sp_pantip)\n",
    "pantip_test_loader = DataLoader(\n",
    "    pantip_test_dataset, batch_size=test_batch_size, shuffle=False\n",
    ")\n",
    "\n",
    "pam_train_dataset = TextDataset(pam_train_text, sp_pantip)\n",
    "pam_train_loader = DataLoader(\n",
    "    pam_train_dataset, batch_size=train_batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "pam_test_dataset = TextDataset(pam_test_text, sp_pantip)\n",
    "pam_test_loader = DataLoader(\n",
    "    pam_test_dataset, batch_size=test_batch_size, shuffle=False\n",
    ")\n",
    "\n",
    "trainer.fit(model, train_dataloaders=pam_train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f_LhF7w7Lxwo"
   },
   "outputs": [],
   "source": [
    "test_result = trainer.test(\n",
    "    model,\n",
    "    dataloaders=[\n",
    "        pantip_train_loader,\n",
    "        pam_train_loader,\n",
    "        pantip_test_loader,\n",
    "        pam_test_loader,\n",
    "    ],\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Perplexity on Pantip train set is:\\t{np.exp(test_result[0]['test_loss/dataloader_idx_0'])}\"\n",
    ")\n",
    "print(\n",
    "    f\"Perplexity on Pra apai manee train set is:\\t{np.exp(test_result[1]['test_loss/dataloader_idx_1'])}\"\n",
    ")\n",
    "print(\n",
    "    f\"Perplexity on Pantip test set is:\\t{np.exp(test_result[2]['test_loss/dataloader_idx_2'])}\"\n",
    ")\n",
    "print(\n",
    "    f\"Perplexity on Pra apai manee test set is:\\t{np.exp(test_result[3]['test_loss/dataloader_idx_3'])}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "apk9crJjMLoW"
   },
   "source": [
    "<a name=\"no4\"></a>\n",
    "\n",
    "#### 4. Training on Pra apai manee data with Pra apai manee tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_G7GMBIKLzGK"
   },
   "outputs": [],
   "source": [
    "trainer = L.Trainer(max_epochs=10, deterministic=True)\n",
    "model = LSTM(\n",
    "    vocab_size, embedding_dim, hidden_dim, num_layers, dropout_rate, lr, criterion\n",
    ")\n",
    "\n",
    "pantip_train_dataset = TextDataset(pantip_train_text, sp_pam)\n",
    "pantip_train_loader = DataLoader(\n",
    "    pantip_train_dataset, batch_size=train_batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "pantip_test_dataset = TextDataset(pantip_test_text, sp_pam)\n",
    "pantip_test_loader = DataLoader(\n",
    "    pantip_test_dataset, batch_size=test_batch_size, shuffle=False\n",
    ")\n",
    "\n",
    "pam_train_dataset = TextDataset(pam_train_text, sp_pam)\n",
    "pam_train_loader = DataLoader(\n",
    "    pam_train_dataset, batch_size=train_batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "pam_test_dataset = TextDataset(pam_test_text, sp_pam)\n",
    "pam_test_loader = DataLoader(\n",
    "    pam_test_dataset, batch_size=test_batch_size, shuffle=False\n",
    ")\n",
    "\n",
    "trainer.fit(model, train_dataloaders=pam_train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9H753o_JMRFw"
   },
   "outputs": [],
   "source": [
    "test_result = trainer.test(\n",
    "    model,\n",
    "    dataloaders=[\n",
    "        pantip_train_loader,\n",
    "        pam_train_loader,\n",
    "        pantip_test_loader,\n",
    "        pam_test_loader,\n",
    "    ],\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Perplexity on Pantip train set is:\\t{np.exp(test_result[0]['test_loss/dataloader_idx_0'])}\"\n",
    ")\n",
    "print(\n",
    "    f\"Perplexity on Pra apai manee train set is:\\t{np.exp(test_result[1]['test_loss/dataloader_idx_1'])}\"\n",
    ")\n",
    "print(\n",
    "    f\"Perplexity on Pantip test set is:\\t{np.exp(test_result[2]['test_loss/dataloader_idx_2'])}\"\n",
    ")\n",
    "print(\n",
    "    f\"Perplexity on Pra apai manee test set is:\\t{np.exp(test_result[3]['test_loss/dataloader_idx_3'])}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "en9Lmmj4dZ-1"
   },
   "source": [
    "#### To answer\n",
    "\n",
    "The perplexity numbers should indicate that:\n",
    "\n",
    "1. Both LM overfits on Pra apai manee data and performs really bad on Pantip data.\n",
    "2. However using the Pra apai manee tokenizer (no. [4](#no4)) results in a better generalization than the Pantip tokenizer(no. [3](#no3)).\n",
    "\n",
    "Try and come up with some reasons for the results above. <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HlE-mWSMfbv3"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

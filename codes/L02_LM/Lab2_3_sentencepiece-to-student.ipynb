{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iU5fRQwhEdJy"
   },
   "source": [
    "# Subword Tokenization\n",
    "\n",
    "In this exercise, we will learn how to train our own subword tokenizers with different algorithms: BPE and Unigram. We will use `sentencepiece`, a library from Google to help create our tokenizers.\n",
    "\n",
    "## Ref:\n",
    "\n",
    "https://github.com/google/sentencepiece/blob/master/python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pI9gRZlUE80g"
   },
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "1pOsV-jaW975"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-01-15 13:41:32--  https://github.com/Knight-H/thai-lm/raw/refs/heads/master/data/pra-apai-manee-ch1-50.txt\n",
      "Resolving github.com (github.com)... 20.205.243.166\n",
      "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/Knight-H/thai-lm/refs/heads/master/data/pra-apai-manee-ch1-50.txt [following]\n",
      "--2025-01-15 13:41:33--  https://raw.githubusercontent.com/Knight-H/thai-lm/refs/heads/master/data/pra-apai-manee-ch1-50.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3231076 (3.1M) [application/octet-stream]\n",
      "Saving to: ‘pra-apai-manee-ch1-50.txt’\n",
      "\n",
      "pra-apai-manee-ch1- 100%[===================>]   3.08M  7.11MB/s    in 0.4s    \n",
      "\n",
      "2025-01-15 13:41:34 (7.11 MB/s) - ‘pra-apai-manee-ch1-50.txt’ saved [3231076/3231076]\n",
      "\n",
      "--2025-01-15 13:41:34--  https://github.com/Knight-H/thai-lm/raw/refs/heads/master/data/kratoo-40000000-40002000.jsonl\n",
      "Resolving github.com (github.com)... 20.205.243.166\n",
      "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/Knight-H/thai-lm/refs/heads/master/data/kratoo-40000000-40002000.jsonl [following]\n",
      "--2025-01-15 13:41:35--  https://raw.githubusercontent.com/Knight-H/thai-lm/refs/heads/master/data/kratoo-40000000-40002000.jsonl\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2968483 (2.8M) [text/plain]\n",
      "Saving to: ‘kratoo-40000000-40002000.jsonl’\n",
      "\n",
      "kratoo-40000000-400 100%[===================>]   2.83M  8.44MB/s    in 0.3s    \n",
      "\n",
      "2025-01-15 13:41:37 (8.44 MB/s) - ‘kratoo-40000000-40002000.jsonl’ saved [2968483/2968483]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/Knight-H/thai-lm/raw/refs/heads/master/data/pra-apai-manee-ch1-50.txt\n",
    "!wget https://github.com/Knight-H/thai-lm/raw/refs/heads/master/data/kratoo-40000000-40002000.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CSiDpG9WE-cT"
   },
   "source": [
    "## Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "OQd7M6gLWPLN"
   },
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "import io\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OifbmMIstzs8"
   },
   "source": [
    "Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "-FnIDvb1lMuh"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1060318"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pantip_text = []\n",
    "with open(\"kratoo-40000000-40002000.jsonl\", \"r\") as json_file:\n",
    "    json_list = list(json_file)\n",
    "    for json_str in json_list:\n",
    "        result = json.loads(json_str)\n",
    "        pantip_text.append(f\"{result['title']}\\n{result['content']}\\n\")\n",
    "sum([len(t) for t in pantip_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "yaaQVXZ8A0j1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1100605"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"pra-apai-manee-ch1-50.txt\") as f:\n",
    "    pra_apai_manee_data = f.readlines()\n",
    "sum([len(t) for t in pra_apai_manee_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "RbdfkF-vAoie"
   },
   "outputs": [],
   "source": [
    "pantip_train_text = pantip_text[: int(len(pantip_text) * 0.8)]\n",
    "pantip_test_text = pantip_text[int(len(pantip_text) * 0.8) :]\n",
    "\n",
    "pam_train_text = pra_apai_manee_data[\n",
    "    : int(len(pra_apai_manee_data) * 0.8)\n",
    "]  # pam = pra_apai_manee\n",
    "pam_test_text = pra_apai_manee_data[int(len(pra_apai_manee_data) * 0.8) :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BhwcH0Aot1XI"
   },
   "source": [
    "## Run tokenizer training\n",
    "\n",
    "The Python wrapper provides multiple APIs for training our tokenizers\n",
    "\n",
    "1. `spm.SentencePieceTrainer.train(input='input.txt', model_prefix='m', vocab_size=vocab_size, model_type=model_type)`\n",
    "   <br> This will output the tokenizer files `m.model` and `m.vocab` that can be later loaded into `SentencePieceProcessor`.\n",
    "   <br><br>\n",
    "2. `spm.SentencePieceTrainer.train(sentence_iterator=iterator, model_writer=obj_with_write_method, vocab_size=vocab_size, model_type=model_type)`\n",
    "   <br> This method will require a file object e.g. `obj_with_write_method = io.BytesIO()`. The advantage of this method is you can run sentencepiece on environments that have limited access to the local file system. But you will still have to save the model file if you want to re-use the model else you will have to train it again.\n",
    "   <br><br>\n",
    "3. `spm.SentencePieceTrainer.train('--input=input.txt --model_prefix=m --vocab_size=vocab_size --model_type=model_type')`\n",
    "   <br> Same as no.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c3XeFFYw-T_0"
   },
   "source": [
    "### Unigram tokenizer\n",
    "\n",
    "We are going to start with training a unigram tokenizer. You can use any method of training one. Make sure to set vocab_size to 1000.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = pantip_train_text + pam_train_text\n",
    "test_text = pantip_test_text + pam_test_text\n",
    "\n",
    "train_corpus = \"\\n\".join(train_text)\n",
    "test_corpus = \"\\n\".join(test_text)\n",
    "\n",
    "with open(\"train_corpus.txt\", \"w\") as f:\n",
    "    f.write(train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus_pam = \"\\n\".join(pam_train_text)\n",
    "test_corpus_pam = \"\\n\".join(pam_test_text)\n",
    "\n",
    "with open(\"train_corpus_pam.txt\", \"w\") as f:\n",
    "    f.write(train_corpus_pam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: train_corpus_pam.txt\n",
      "  input_format: \n",
      "  model_prefix: unigram_pam\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 1000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  seed_sentencepieces_file: \n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(353) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(185) LOG(INFO) Loading corpus: train_corpus_pam.txt\n",
      "trainer_interface.cc(409) LOG(INFO) Loaded all 16314 sentences\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(430) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(539) LOG(INFO) all chars count=885139\n",
      "trainer_interface.cc(550) LOG(INFO) Done: 99.954% characters are covered.\n",
      "trainer_interface.cc(560) LOG(INFO) Alphabet size=63\n",
      "trainer_interface.cc(561) LOG(INFO) Final character coverage=0.99954\n",
      "trainer_interface.cc(592) LOG(INFO) Done! preprocessed 16314 sentences.\n",
      "unigram_model_trainer.cc(265) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(269) LOG(INFO) Extracting frequent sub strings... node_num=411778\n",
      "unigram_model_trainer.cc(312) LOG(INFO) Initialized 275348 seed sentencepieces\n",
      "trainer_interface.cc(598) LOG(INFO) Tokenizing input sentences with whitespace: 16314\n",
      "trainer_interface.cc(609) LOG(INFO) Done! 32181\n",
      "unigram_model_trainer.cc(602) LOG(INFO) Using 32181 sentences for EM training\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=49394 obj=42.2355 num_tokens=128673 num_tokens/piece=2.60503\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=40979 obj=36.7371 num_tokens=130046 num_tokens/piece=3.17348\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=30367 obj=36.9771 num_tokens=139359 num_tokens/piece=4.58916\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=29880 obj=36.5016 num_tokens=139582 num_tokens/piece=4.67142\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=22205 obj=37.6771 num_tokens=149629 num_tokens/piece=6.73853\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=22104 obj=37.2684 num_tokens=149717 num_tokens/piece=6.7733\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=16512 obj=38.7389 num_tokens=161069 num_tokens/piece=9.75466\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=16473 obj=38.3341 num_tokens=161183 num_tokens/piece=9.78468\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=12338 obj=40.0409 num_tokens=172981 num_tokens/piece=14.0202\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=12331 obj=39.6638 num_tokens=172997 num_tokens/piece=14.0294\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=9245 obj=41.4482 num_tokens=185092 num_tokens/piece=20.0208\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=9242 obj=41.1146 num_tokens=185096 num_tokens/piece=20.0277\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=6930 obj=43.0791 num_tokens=198272 num_tokens/piece=28.6107\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=6930 obj=42.7435 num_tokens=198274 num_tokens/piece=28.611\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=5196 obj=44.8072 num_tokens=211985 num_tokens/piece=40.7977\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=5196 obj=44.4723 num_tokens=211972 num_tokens/piece=40.7952\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=3897 obj=46.7216 num_tokens=226813 num_tokens/piece=58.202\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=3897 obj=46.3429 num_tokens=226820 num_tokens/piece=58.2037\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=2922 obj=48.8639 num_tokens=244481 num_tokens/piece=83.6691\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=2922 obj=48.4277 num_tokens=244676 num_tokens/piece=83.7358\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=2191 obj=51.2638 num_tokens=265878 num_tokens/piece=121.35\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=2191 obj=50.7382 num_tokens=265883 num_tokens/piece=121.352\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=1643 obj=53.8622 num_tokens=291545 num_tokens/piece=177.447\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=1643 obj=53.2395 num_tokens=291545 num_tokens/piece=177.447\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=1232 obj=56.564 num_tokens=320433 num_tokens/piece=260.092\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=1232 obj=55.8787 num_tokens=320433 num_tokens/piece=260.092\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=1100 obj=57.1231 num_tokens=332377 num_tokens/piece=302.161\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=1100 obj=56.8968 num_tokens=332377 num_tokens/piece=302.161\n",
      "trainer_interface.cc(687) LOG(INFO) Saving model: unigram_pam.model\n",
      "trainer_interface.cc(699) LOG(INFO) Saving vocabs: unigram_pam.vocab\n"
     ]
    }
   ],
   "source": [
    "## Train\n",
    "spm.SentencePieceTrainer.train(\n",
    "    input=\"train_corpus_pam.txt\",\n",
    "    model_prefix=\"unigram_pam\",\n",
    "    vocab_size=1000,\n",
    "    model_type=\"unigram\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gdXPaoW3_v2T"
   },
   "source": [
    "### Q1 MCV\n",
    "\n",
    "How many tokens did you get when tokenizing the following sentence with your unigram tokenizer: <br>\n",
    "'อรุณสวัสดิ์ ฉันเอามเหสีมาหาม สวัสดี ประเทศไทยสบายดีไหม'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_pam_tokenizer = spm.SentencePieceProcessor(model_file='unigram_pam.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "J1bO3s-z-PLb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unigram_pam_tokenizer.encode(\"อรุณสวัสดิ์ ฉันเอามเหสีมาหาม สวัสดี ประเทศไทยสบายดีไหม\", out_type=str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tKkc1D-hAFxl"
   },
   "source": [
    "### BPE Tokenizer\n",
    "\n",
    "Now try training a BPE tokenizer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "AiXj57rh-PIv"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: train_corpus_pam.txt\n",
      "  input_format: \n",
      "  model_prefix: bpe_pam\n",
      "  model_type: BPE\n",
      "  vocab_size: 1000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  seed_sentencepieces_file: \n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(353) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(185) LOG(INFO) Loading corpus: train_corpus_pam.txt\n",
      "trainer_interface.cc(409) LOG(INFO) Loaded all 16314 sentences\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(430) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(539) LOG(INFO) all chars count=885139\n",
      "trainer_interface.cc(550) LOG(INFO) Done: 99.954% characters are covered.\n",
      "trainer_interface.cc(560) LOG(INFO) Alphabet size=63\n",
      "trainer_interface.cc(561) LOG(INFO) Final character coverage=0.99954\n",
      "trainer_interface.cc(592) LOG(INFO) Done! preprocessed 16314 sentences.\n",
      "trainer_interface.cc(598) LOG(INFO) Tokenizing input sentences with whitespace: 16314\n",
      "trainer_interface.cc(609) LOG(INFO) Done! 32181\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=8839 min_freq=120\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3834 size=20 all=3652 active=2394 piece=ให\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2412 size=40 all=5419 active=4161 piece=้อง\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1781 size=60 all=7328 active=6070 piece=ได\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1469 size=80 all=9357 active=8099 piece=▁พระ\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1191 size=100 all=11534 active=10276 piece=าว\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1168 min_freq=139\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1002 size=120 all=13824 active=3191 piece=ูก\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=876 size=140 all=16549 active=5916 piece=เม\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=748 size=160 all=19242 active=8609 piece=ความ\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=677 size=180 all=21716 active=11083 piece=กํา\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=626 size=200 all=24479 active=13846 piece=สาร\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=623 min_freq=85\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=566 size=220 all=26945 active=3535 piece=ขึ้น\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=509 size=240 all=29932 active=6522 piece=รบ\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=470 size=260 all=32718 active=9308 piece=แล\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=436 size=280 all=35246 active=11836 piece=้ํา\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=404 size=300 all=37519 active=14109 piece=ฝ้า\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=404 min_freq=48\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=382 size=320 all=39880 active=4139 piece=น้อย\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=356 size=340 all=42278 active=6537 piece=นึก\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=336 size=360 all=44997 active=9256 piece=แท\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=320 size=380 all=47070 active=11329 piece=ขัด\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=301 size=400 all=49390 active=13649 piece=ตรา\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=300 min_freq=33\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=285 size=420 all=51579 active=4541 piece=พู\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=269 size=440 all=53523 active=6485 piece=เลี้ยง\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=257 size=460 all=55855 active=8817 piece=่าว\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=244 size=480 all=57964 active=10926 piece=▁ก็\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=234 size=500 all=60309 active=13271 piece=ียก\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=234 min_freq=25\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=224 size=520 all=62342 active=4958 piece=าะ\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=205 size=540 all=64337 active=6953 piece=รุ\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=199 size=560 all=66395 active=9011 piece=วาท\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=194 size=580 all=68294 active=10910 piece=อ่อน\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=186 size=600 all=70205 active=12821 piece=ชน\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=186 min_freq=20\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=178 size=620 all=71920 active=5149 piece=▁ซึ่ง\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=171 size=640 all=73659 active=6888 piece=พักตร์\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=164 size=660 all=75411 active=8640 piece=▁ขึ้น\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=159 size=680 all=77310 active=10539 piece=พรั่ง\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=155 size=700 all=79085 active=12314 piece=อื้น\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=155 min_freq=17\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=149 size=720 all=80846 active=5691 piece=สัก\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=144 size=740 all=82546 active=7391 piece=เชษฐา\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=140 size=760 all=84297 active=9142 piece=▁กระ\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=136 size=780 all=85826 active=10671 piece=กําปั่น\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=132 size=800 all=87264 active=12109 piece=▁ศรีสุวรรณ\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=131 min_freq=15\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=128 size=820 all=88742 active=5808 piece=สบาย\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=123 size=840 all=90098 active=7164 piece=ไหล\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=119 size=860 all=91598 active=8664 piece=ชาติ\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=115 size=880 all=93143 active=10209 piece=ไท\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=113 size=900 all=94526 active=11592 piece=คํานับ\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=113 min_freq=13\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=108 size=920 all=95958 active=6087 piece=แป\n",
      "trainer_interface.cc(687) LOG(INFO) Saving model: bpe_pam.model\n",
      "trainer_interface.cc(699) LOG(INFO) Saving vocabs: bpe_pam.vocab\n"
     ]
    }
   ],
   "source": [
    "## Train\n",
    "spm.SentencePieceTrainer.train(\n",
    "    input=\"train_corpus_pam.txt\",\n",
    "    model_prefix=\"bpe_pam\",\n",
    "    vocab_size=1000,\n",
    "    model_type=\"bpe\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nrQwGmL5AMXc"
   },
   "source": [
    "### Q2 MCV\n",
    "\n",
    "How many tokens did you get when tokenizing the following sentence with your BPE tokenizer: <br>\n",
    "'อรุณสวัสดิ์ ฉันเอามเหสีมาหาม สวัสดี ประเทศไทยสบายดีไหม'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpe_pam_tokenizer = spm.SentencePieceProcessor(model_file='bpe_pam.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "0AXuzyaN-PEr"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bpe_pam_tokenizer.encode(\"อรุณสวัสดิ์ ฉันเอามเหสีมาหาม สวัสดี ประเทศไทยสบายดีไหม\", out_type=str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rbb6C6-IS_Ly"
   },
   "source": [
    "These are some of your vocabs. Note that you will see \"▁\" (U+2581) in every type of tokenizer in SentencePiece since it makes it possible to perform detokenization \\(unsplit your sentences\\) without relying on language-specific resources.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Aa9j6XrTKjyA"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<unk> | <s> | </s> | ▁ | า | เ | น | ม | ย | ก | ร | ว | ด | ส | ง | บ | ค | มา | อ | ล | จะ | ท | ให้ | ห | ไป | ไม่ | แ | ว่า | พ | ุ | ี | ๏ | ฯ | ข | ช | เป็น | พระ | โ | ที่ | ใจ | ▁จะ | จ | ะ | ิ | ต | ก็ | อยู่ | ป | ได้ | ่ | ไ | เข้า | ู | ▁พระ | ้า | ตาม | ใน | ้ | ▁แล้ว | เหมือน | รา | ศ | เจ้า | เห็น | ลา | กัน | ั | หา | นาง | ทรง | ประ | ์ | ยา | ัก | ํา | ซ | าน | ัง | ฉ | องค์ | ัด | แล้ว | อน | ดู | ถ | ด้วย | มี | ▁จึง | นี้ | ่า | ผ | น้อง | แต่ | ทํา | ▁นาง | ▁ให้ | รัก | พี่ | คิด | ลูก | พา | รู้ | การ | กับ | ัน | หน้า | กระ | วน | ออก | ่อ | เขา | ถึง | ระ | ข้า | ับ | พล | นั่ง | ทั้ง | หน | รับ | ษ | กล | วง | ลง | ฝ | กร | พร | ความ | เสีย | ดี | ขึ้น | อง | ่ง | ธ | ▁แต่ | คน | กลับ | ▁ฝ่าย | ้น | อด | ภ | หรือ | ตร | ือ | ฟัง | แม่ | ▁ไม่ | ไว้ | ยัง | ▁เห็น | นา | ขอ | มิ | น้ํา | หล | ดัง | ▁พอ | ▁ทั้ง | ช่วย | สม | นั้น | ริ | ทัพ | ต้อง | วัน | อา | น้อย | รบ | ิน | อย่า | เอา | จน | เรา | สุด | เสียง | ข้าง | หลัง | ตี | ตัว | ละ | สุ | วัง | ทุก | ่น | ึก | นึก | เฝ้า | นาย | ฝรั่ง | ทูล | เส | วิ | ปล | ▁ถึง | ตาย | ใคร | อก | อั | ตา | เรือ | จึง | แล | ี่ | ั่ง | แสน | สอง | ของ | ็ | ลี | ี้ | จิต | หมาย | ้ม | แจ้ง | ั่น | สั่ง | ราช | พิ | เห | หาย | ้อง | เมือง | เหลือ | กลาง | กษัตริย์ | ยิ่ง | ตรัส | ึง | เลย | เล่า | ทาง | ุด | ศรี | เคย | ไหน | สาม | หนี | ณ | มัน | ื้อ | ค่อย | ชาย | พราหมณ์ | ▁อย่า | ญ | ที | นิ | น่า | สิ้น | ฉัน | กาย | ลังกา | ▁ด้วย | คอย | บอก | สิ | ฟ | สงสาร | พ่อ | ยง | จริง | ชาว | ถาม | ไร | ทหาร | ตั้ง | ▁อัน | เที่ยว | ปร | ผู้ | พวก | สาร | ชม | ศึก | คํา | ▁เป็น | ทอง | อบ | ใหญ่ | ถือ | สาว | พระอภัย | จง | สา | จับ | ั้น | พลาง | ▁มา | ยก | ▁บ้าง | ไพร่ | ลม | ล้วน | ▁ต่าง | ร้อย | พบ | งาม | แกล้ง | อาย | จะได้ | เคียง | อย่าง | เครื่อง | กลัว | ลาย | จํา | ต่าง | สินสมุทร | ▁พวก | ม้า | ลํา | นี่ | ผา | แก้ว | เพราะ | ▁ครั้น | ▁จน | ▁แม้น | สาย | พัน | พระองค์ | พร้อม | วาย | ชิง | ห้อง | ร้อง | สู้ | ▁จง | ลิ | ราย | ล่อ | จาก | ้ว | ท่าน | รอง | เดิน | เรียก | ขัด | เหล่า | กุมาร | ผล | ป่า | ู่ | คู่ | รูป | กิน | พอ | ร่ํา | โฉม | ▁ถ้า | คง | ่าย | ใช้ | ตอบ | หลง | ไล่ | จัด | ดับ | ▁เมื่อ | บน | อ่อน | แสง | คืน | ใส่ | แค้น | รถ | ตรง | แต่ง | แน่ | เชิญ | ชื่น | ถวาย | โห | จร | มิได้ | นอน | ุก | ชวน | เมีย | อาลัย | ้อม | ลับ | ไหว | ▁แม้ | บิดา | หญิง | หลับ | ดอก | กล้า | ขาด | จัก | ไม่มี | บาท | เสนา | ย์ | ช่าง | โศก | วาง | ติด | เสร็จ | ร้อน | คุณ | ผัว | นัก | ความตาม | พักตร์ | หน่อ | ้อย | ▁ซึ่ง | ตะ | ห้าม | พราย | ฟ้า | ไฉน | ใ | ตก | เมื่อ | ยศ | ชล | ดํา | หนึ่ง | ผัน | ใด | สัก | ร้าย | วิ่ง | แก้ | ยาม | ศรีสุวรรณ | ปืน | ฆ่า | ขับ | ขวา | ไฟ | พูด | หมอง | ก็ไม่ | กําลัง | รักษา | เช่น | ุ่ม | ผี | หาญ | เล่น | เนื้อ | รีบ | ถูก | ชัย | บุตรี | ฟัน | บ้าง | เอ๋ย | สงสัย | ผิด | นิ่ง | ชื่อ | เถิด | ผ่อน | หลาน | สี่ | ชาติ | อี | ปาก | ช้า | ึ | แตก | ตรา | รณ | ลอง | ปี | หมอ | เจ้าพราหมณ์ | พี่เลี้ยง | ต่อ | พลอย | โฉมยง | เนตร | หัก | กอด | เชย | ทั้งสอง | ยิ้ม | ค่ํา | นอก | ขวัญ | ซ้ํา | อารมณ์ | ทุกข์ | แขก | เย็น | หนักหนา | ั้ง | ปิด | โปรด | ้ง | กําปั่น | เรียง | แรง | สิ่ง | เศร้า'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_vocabs = [unigram_pam_tokenizer.id_to_piece(id) for id in range(unigram_pam_tokenizer.get_piece_size())]\n",
    "\" | \".join(unigram_vocabs[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "2TsXA0UqN5LN"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<unk> | <s> | </s> | ้า | ่า | อง | ระ | ํา | รา | อย | ่ง | มา | จะ | ัง | ัน | ▁เ | าย | ้ว | ับ | ี่ | ม่ | อน | ให | าม | ้น | ็น | พระ | ีย | าง | กล | ้ง | ัก | หน | ให้ | ไม่ | หล | ่น | ึง | ▁แ | ทั | ตร | าร | ้อง | ไป | ิด | ข้า | ว่า | หม | คร | ือ | ล้ว | เป | เส | ประ | าน | ั่ง | ▁๏ | ▁ฯ | ที่ | อก | เล | ิน | ได | พล | ทร | ัด | นาง | ึก | ได้ | ู่ | ▁จะ | ค์ | ี้ | พร | เป็น | สุ | ทั้ง | อม | ัย | เร | ห็น | ▁จ | ▁พระ | ก็ | ใจ | อา | ื่ | ่าง | ต่ | กร | ิง | วง | วน | ือน | เจ | ู้ | ียง | อยู่ | รร | ตาม | ▁พ | ้วย | าว | ถึง | คล | ั้น | รี | เข | ด้วย | สม | องค์ | สน | าก | ▁แล้ว | เช | ัว | ย์ | ใน | คว | น้ | หมือน | ▁ส | ูก | อบ | กระ | เจ้า | ทรง | ลา | กัน | มี | ่าย | พรา | ิ่ง | เข้า | เห็น | ิต | สง | อด | ณ์ | วย | ้ม | คิด | เม | เก | เด | ▁นาง | วา | ุก | ▁ให้ | ดู | หา | ▁อ | ▁จึง | ทํา | ลง | รัก | เค | แล้ว | ่าน | พี่ | เหมือน | ั่น | ความ | ยง | อย่า | หร | มิ | ืน | ช่ | การ | ัญ | ▁ไม่ | ฝ่าย | ศรี | ้าง | วก | ้อม | ือง | น้อง | ยว | พา | แก | กํา | ่อน | ื่น | หน้า | ยา | ดี | ั้ง | ▁ทั้ง | ปรา | คน | เน | หว | รับ | แต่ | ้าย | ัส | เหล | ดา | สํา | นี้ | สาร | กับ | ลูก | ละ | ▁ต | รู้ | ื่อ | ▁ฝ่าย | ึ่ง | ลัง | าด | ื้ | กา | ขึ | นั่ง | เท | ▁เห็น | ฟัง | ้อย | ไร | ขึ้น | เสีย | ▁แต่ | บุ | สา | ไว | ทุก | กลับ | สุด | ัต | ใคร | น้ํา | ชา | ุด | ทัพ | วัน | สอง | นา | หย | ตา | รบ | ▁มา | ่อ | หรือ | ทู | ยัง | รง | จร | ปร | ▁บ | ไว้ | ดัง | วิ | ช่วย | ปล | ออก | ัตร | เพ | สิ | แจ | แล | ็จ | ิย์ | ▁พอ | มาร | ค่ | วรร | หมณ์ | คํา | เขา | นั้น | กษ | เย | ข้าง | หมา | เว | ไพร | หลัง | จิต | พราหมณ์ | ้ํา | ▁ถึง | ขอ | ทูล | สาม | ื้อ | วาย | อภ | ทาง | ▁แม | วัง | โฉ | ่ม | จน | ▁เป | ัตริย์ | ื่อง | สั่ง | แม่ | ▁ช | ฝ้า | โฉม | ราช | ฝร | ▁ถ | ฝรั่ง | ิ์ | ลม | แต | ▁เป็น | หาร | ื้น | เห | ้อน | ตาย | ุ่ง | ตัว | อย่าง | ลี | ผู้ | น้อย | ฉัน | ตรี | กุ | ษา | ุทร | ถาม | ของ | พร้อม | ชี | สร | เอ | ุง | พลาง | ตี | สมุทร | หาย | ที | วรรณ | เลี้ | นึก | จึง | หมาย | ▁ด้วย | ขว | ียน | ศึก | ่อง | ต้อง | ลัย | บา | พิ | อุ | สุวรรณ | โย | เรา | กลาง | เฝ้า | กษัตริย์ | สะ | แท | สัย | แจ้ง | หญ | ▁อย่า | รํา | ตรัส | อภัย | ผล | เลย | ียว | ไหน | ้าว | แน | ิดา | ริ | สาว | ิ้ม | เมือง | เล่า | ขัด | ค่อย | ภา | โอ | ่ํา | มัน | ชม | ห์ | ชาย | ัล | นาย | ▁เจ | เสียง | ยิ่ง | รู | ๋ย | เปล | เอา | ▁เส | คง | ตรา | ห้า | ินสมุทร | คอย | หญิง | หนี | ้าน | ญา | คุ | บรร | ▁ประ | กาย | ทหาร | ▁อัน | สิ้น | ทธ | ทอง | ักษ | ลังกา | นิ | พู | ศ์ | ่ว | จา | ใหญ | ที่ยว | มน | ไล | จริง | ▁เจ้า | จํา | ▁บ้าง | บอก | ▁ต่าง | ติ | ▁เข้า | ไม | ศร | อั | เคย | เลี้ยง | กรา | แสน | ▁จน | จับ | พบ | ครั้น | จง | พวก | สี | ไข | ษฐ | เกล | คา | รม | พัก | พัน | ซึ่ง | หนัก | นี | ่าว | กรุง | กล้ง | ▁เหมือน | ครา | เคร | ท้าว | ใส | ▁พวก | ตั้ง | หลง | ล้วน | ▁ไป | ผี | ลํา | นัก | ร้อง | ▁จง | ทรา | หนา | ▁ก็ | กลัว | ▁ที่ | เคียง | อาย | เรือ | ▁แม้น | เต | แค | ยก | พราะ | ใหญ่ | ▁ครั้น | ▁น | แก้ว | ถือ | ▁ได้ | เหลือ'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpe_vocabs = [bpe_pam_tokenizer.id_to_piece(id) for id in range(bpe_pam_tokenizer.get_piece_size())]\n",
    "\" | \".join(bpe_vocabs[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eu6QnnRfQyFj"
   },
   "source": [
    "### User-defined symbols\n",
    "\n",
    "Another important concept to know of is User-defined symbols. These special symbols are reserved for a special purpose \\(e.g.\\, the \\<MASK\\> token used in BERT) and will always be tokenized into one token.\n",
    "\n",
    "Refer to the documentation for ways to add these special tokens to your tokenizer.\n",
    "\n",
    "https://github.com/google/sentencepiece/blob/master/python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QEFOj62ZEdzT"
   },
   "source": [
    "## Train another tokenizer on another domain\n",
    "\n",
    "Now try training another unigram tokenizer on `pantip_text` and we will use it to compare with the unigram tokenizer we trained earlier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus_pantip = \"\\n\".join(pantip_train_text)\n",
    "test_corpus_pantip = \"\\n\".join(pantip_test_text)\n",
    "\n",
    "with open(\"train_corpus_pantip.txt\", \"w\") as f:\n",
    "    f.write(train_corpus_pantip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "O7-QkA1eMZFf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: train_corpus_pantip.txt\n",
      "  input_format: \n",
      "  model_prefix: unigram_pantip\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 1000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  seed_sentencepieces_file: \n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(353) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(185) LOG(INFO) Loading corpus: train_corpus_pantip.txt\n",
      "trainer_interface.cc(380) LOG(WARNING) Found too long line (7271 > 4192).\n",
      "trainer_interface.cc(382) LOG(WARNING) Too long lines are skipped in the training.\n",
      "trainer_interface.cc(383) LOG(WARNING) The maximum length can be changed with --max_sentence_length=<size> flag.\n",
      "trainer_interface.cc(409) LOG(INFO) Loaded all 9475 sentences\n",
      "trainer_interface.cc(416) LOG(INFO) Skipped 20 too long sentences.\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(430) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(539) LOG(INFO) all chars count=795024\n",
      "trainer_interface.cc(550) LOG(INFO) Done: 99.9506% characters are covered.\n",
      "trainer_interface.cc(560) LOG(INFO) Alphabet size=185\n",
      "trainer_interface.cc(561) LOG(INFO) Final character coverage=0.999506\n",
      "trainer_interface.cc(592) LOG(INFO) Done! preprocessed 8875 sentences.\n",
      "unigram_model_trainer.cc(265) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(269) LOG(INFO) Extracting frequent sub strings... node_num=344183\n",
      "unigram_model_trainer.cc(312) LOG(INFO) Initialized 202602 seed sentencepieces\n",
      "trainer_interface.cc(598) LOG(INFO) Tokenizing input sentences with whitespace: 8875\n",
      "trainer_interface.cc(609) LOG(INFO) Done! 28564\n",
      "unigram_model_trainer.cc(602) LOG(INFO) Using 28564 sentences for EM training\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=41593 obj=36.7304 num_tokens=117107 num_tokens/piece=2.81555\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=35185 obj=31.7493 num_tokens=118246 num_tokens/piece=3.36069\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=26169 obj=31.928 num_tokens=126191 num_tokens/piece=4.82216\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=25868 obj=31.5765 num_tokens=126408 num_tokens/piece=4.88666\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=19278 obj=32.403 num_tokens=135618 num_tokens/piece=7.03486\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=19222 obj=32.081 num_tokens=135912 num_tokens/piece=7.07065\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=14375 obj=33.0697 num_tokens=145771 num_tokens/piece=10.1406\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=14365 obj=32.7542 num_tokens=145994 num_tokens/piece=10.1632\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=10770 obj=33.8919 num_tokens=156025 num_tokens/piece=14.487\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=10766 obj=33.5958 num_tokens=156169 num_tokens/piece=14.5058\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=8071 obj=34.8705 num_tokens=166979 num_tokens/piece=20.6888\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=8071 obj=34.5957 num_tokens=167077 num_tokens/piece=20.7009\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=6053 obj=35.9697 num_tokens=178378 num_tokens/piece=29.4694\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=6053 obj=35.6866 num_tokens=178906 num_tokens/piece=29.5566\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=4538 obj=37.2058 num_tokens=190787 num_tokens/piece=42.0421\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=4538 obj=36.9041 num_tokens=191139 num_tokens/piece=42.1197\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=3403 obj=38.5838 num_tokens=204169 num_tokens/piece=59.9968\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=3403 obj=38.2589 num_tokens=204177 num_tokens/piece=59.9991\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=2552 obj=40.1566 num_tokens=218658 num_tokens/piece=85.681\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=2552 obj=39.7848 num_tokens=218876 num_tokens/piece=85.7665\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=1914 obj=41.8605 num_tokens=234410 num_tokens/piece=122.471\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=1914 obj=41.4363 num_tokens=234410 num_tokens/piece=122.471\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=1435 obj=43.7577 num_tokens=252316 num_tokens/piece=175.83\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=1435 obj=43.2646 num_tokens=252333 num_tokens/piece=175.842\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=1100 obj=45.6164 num_tokens=272438 num_tokens/piece=247.671\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=1100 obj=45.0553 num_tokens=272438 num_tokens/piece=247.671\n",
      "trainer_interface.cc(687) LOG(INFO) Saving model: unigram_pantip.model\n",
      "trainer_interface.cc(699) LOG(INFO) Saving vocabs: unigram_pantip.vocab\n"
     ]
    }
   ],
   "source": [
    "## Train\n",
    "spm.SentencePieceTrainer.train(\n",
    "    input=\"train_corpus_pantip.txt\",\n",
    "    model_prefix=\"unigram_pantip\",\n",
    "    vocab_size=1000,\n",
    "    model_type=\"unigram\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R5WOVMbONnYv"
   },
   "source": [
    "## Analyse top tokens on different datasets\n",
    "\n",
    "Use your tokenizers to tokenize the datasets and analyse your most common vocabularies (try 300-400 vocabs with len>1). Hint: tokenize your data and count the tokens.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_pantip_tokenizer = spm.SentencePieceProcessor(model_file='unigram_pantip.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "wbfkGcsUrPYS"
   },
   "outputs": [],
   "source": [
    "tokens_pam = defaultdict(lambda: 0.0)\n",
    "for sent in pam_test_text:\n",
    "    tokens = unigram_pam_tokenizer.encode(sent, out_type=str)\n",
    "    for token in tokens:\n",
    "        tokens_pam[token] += 1\n",
    "\n",
    "top_tokens_pam = sorted(tokens_pam.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "tokens_pantip = defaultdict(lambda: 0.0)\n",
    "for sent in pantip_test_text:\n",
    "    tokens = unigram_pantip_tokenizer.encode(sent, out_type=str)\n",
    "    for token in tokens:\n",
    "        tokens_pantip[token] += 1\n",
    "\n",
    "top_tokens_pantip = sorted(tokens_pantip.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('▁', 7822.0),\n",
       " ('ที่', 1137.0),\n",
       " ('น', 991.0),\n",
       " ('ก', 966.0),\n",
       " ('ร', 939.0),\n",
       " ('ม', 868.0),\n",
       " ('ล', 828.0),\n",
       " ('ด', 818.0),\n",
       " ('ส', 807.0),\n",
       " ('ย', 796.0),\n",
       " ('า', 762.0),\n",
       " ('ง', 761.0),\n",
       " ('ว', 755.0),\n",
       " ('ค', 751.0),\n",
       " ('ได้', 666.0),\n",
       " ('ไป', 659.0),\n",
       " ('บ', 657.0),\n",
       " ('มา', 656.0),\n",
       " ('จะ', 633.0),\n",
       " ('ก็', 628.0),\n",
       " ('เรา', 602.0),\n",
       " ('ท', 599.0),\n",
       " ('อ', 594.0),\n",
       " ('ต', 586.0),\n",
       " ('ว่า', 568.0),\n",
       " ('เ', 563.0),\n",
       " ('มี', 550.0),\n",
       " ('.', 545.0),\n",
       " ('ไม่', 536.0),\n",
       " ('เป็น', 522.0),\n",
       " ('แ', 505.0),\n",
       " ('e', 485.0),\n",
       " ('ๆ', 473.0),\n",
       " ('ิ', 467.0),\n",
       " ('ุ', 449.0),\n",
       " ('ห', 448.0),\n",
       " ('การ', 440.0),\n",
       " ('s', 432.0),\n",
       " ('ป', 430.0),\n",
       " ('ช', 424.0),\n",
       " ('ให้', 405.0),\n",
       " ('พ', 403.0),\n",
       " ('ของ', 397.0),\n",
       " ('้า', 396.0),\n",
       " ('t', 389.0),\n",
       " ('เลย', 385.0),\n",
       " ('จ', 379.0),\n",
       " ('ใน', 379.0),\n",
       " ('o', 372.0),\n",
       " ('แล้ว', 366.0),\n",
       " ('ค่ะ', 343.0),\n",
       " ('้', 342.0),\n",
       " ('์', 341.0),\n",
       " ('นี้', 338.0),\n",
       " ('โ', 337.0),\n",
       " ('ั', 331.0),\n",
       " ('ครับ', 323.0),\n",
       " ('ข', 319.0),\n",
       " ('a', 314.0),\n",
       " ('i', 304.0),\n",
       " ('กัน', 296.0),\n",
       " ('-', 291.0),\n",
       " ('กับ', 289.0),\n",
       " ('่', 289.0),\n",
       " ('ดี', 284.0),\n",
       " ('คน', 273.0),\n",
       " ('มัน', 269.0),\n",
       " ('ซ', 268.0),\n",
       " ('เขา', 260.0),\n",
       " ('▁แต่', 260.0),\n",
       " ('p', 256.0),\n",
       " ('จาก', 246.0),\n",
       " ('3', 245.0),\n",
       " ('มาก', 244.0),\n",
       " ('อยู่', 244.0),\n",
       " ('ะ', 239.0),\n",
       " ('/', 230.0),\n",
       " (')', 228.0),\n",
       " ('c', 221.0),\n",
       " ('่า', 219.0),\n",
       " ('▁เรา', 213.0),\n",
       " ('ต้อง', 209.0),\n",
       " ('u', 208.0),\n",
       " ('ทํา', 206.0),\n",
       " ('ใช้', 206.0),\n",
       " ('ไ', 205.0),\n",
       " ('ํา', 198.0),\n",
       " ('ด้วย', 197.0),\n",
       " ('ถึง', 190.0),\n",
       " ('แต่', 188.0),\n",
       " ('ู', 184.0),\n",
       " ('4', 181.0),\n",
       " ('▁และ', 180.0),\n",
       " ('ดู', 179.0),\n",
       " ('ความ', 179.0),\n",
       " ('และ', 179.0),\n",
       " ('ับ', 176.0),\n",
       " ('m', 173.0),\n",
       " ('หา', 173.0),\n",
       " ('เข้า', 172.0),\n",
       " ('l', 171.0),\n",
       " ('k', 170.0),\n",
       " ('อะไร', 169.0),\n",
       " ('เรื่อง', 167.0),\n",
       " ('ไม่ได้', 166.0),\n",
       " ('d', 164.0),\n",
       " ('ี', 164.0),\n",
       " ('A', 162.0),\n",
       " ('6', 162.0),\n",
       " ('พอ', 160.0),\n",
       " ('h', 158.0),\n",
       " ('5', 158.0),\n",
       " ('คือ', 158.0),\n",
       " ('เงิน', 155.0),\n",
       " ('ยา', 155.0),\n",
       " ('แบบ', 155.0),\n",
       " ('ใจ', 154.0),\n",
       " ('ผ', 152.0),\n",
       " ('นั้น', 152.0),\n",
       " ('2', 150.0),\n",
       " ('1', 149.0),\n",
       " ('▁(', 149.0),\n",
       " ('ตัว', 149.0),\n",
       " ('ผม', 149.0),\n",
       " ('▁แล้ว', 148.0),\n",
       " ('ต่อ', 146.0),\n",
       " ('ขึ้น', 146.0),\n",
       " ('ัง', 146.0),\n",
       " ('ีย', 145.0),\n",
       " ('w', 144.0),\n",
       " ('b', 144.0),\n",
       " ('็', 144.0),\n",
       " ('เมื่อ', 140.0),\n",
       " ('g', 138.0),\n",
       " ('น้ํา', 134.0),\n",
       " ('ปี', 134.0),\n",
       " ('บ้าง', 133.0),\n",
       " ('อยาก', 132.0),\n",
       " ('ัน', 132.0),\n",
       " ('รับ', 130.0),\n",
       " ('ยัง', 130.0),\n",
       " ('ิน', 130.0),\n",
       " ('อีก', 129.0),\n",
       " ('ไหน', 129.0),\n",
       " ('7', 128.0),\n",
       " ('T', 128.0),\n",
       " ('อน', 128.0),\n",
       " ('▁2', 127.0),\n",
       " ('ที', 127.0),\n",
       " ('▁1', 126.0),\n",
       " ('วัน', 126.0),\n",
       " ('ตอน', 124.0),\n",
       " (':', 123.0),\n",
       " ('▁คือ', 123.0),\n",
       " ('เท', 123.0),\n",
       " ('f', 122.0),\n",
       " ('B', 122.0),\n",
       " ('บ้าน', 121.0),\n",
       " ('ฟ', 121.0),\n",
       " ('ณ', 120.0),\n",
       " ('ตาม', 119.0),\n",
       " ('เวลา', 118.0),\n",
       " ('งาน', 117.0),\n",
       " ('ซื้อ', 114.0),\n",
       " ('่อ', 114.0),\n",
       " ('ละ', 113.0),\n",
       " ('y', 112.0),\n",
       " ('8', 112.0),\n",
       " ('ศ', 111.0),\n",
       " ('คะ', 110.0),\n",
       " ('นะคะ', 109.0),\n",
       " ('เหมือน', 109.0),\n",
       " ('ทั้ง', 107.0),\n",
       " ('หน้า', 106.0),\n",
       " ('ทาง', 105.0),\n",
       " ('อย่าง', 105.0),\n",
       " ('หน่อย', 105.0),\n",
       " ('ประ', 105.0),\n",
       " ('▁หรือ', 104.0),\n",
       " ('หรือ', 104.0),\n",
       " ('00', 103.0),\n",
       " ('?', 102.0),\n",
       " ('จน', 102.0),\n",
       " ('ั้น', 102.0),\n",
       " ('ไว้', 101.0),\n",
       " ('ตอนนี้', 101.0),\n",
       " ('ถ', 101.0),\n",
       " ('P', 100.0),\n",
       " ('on', 100.0),\n",
       " ('ขอ', 100.0),\n",
       " ('เพื่อน', 100.0),\n",
       " ('ก่อน', 99.0),\n",
       " ('ัด', 99.0),\n",
       " ('รถ', 99.0),\n",
       " ('นา', 98.0),\n",
       " ('ลง', 98.0),\n",
       " ('ไม่มี', 98.0),\n",
       " ('นะ', 98.0),\n",
       " ('0', 97.0),\n",
       " ('ออก', 97.0),\n",
       " ('เอา', 97.0),\n",
       " ('ช่วย', 97.0),\n",
       " ('ัก', 97.0),\n",
       " ('ญ', 96.0),\n",
       " ('รา', 96.0),\n",
       " ('ชอบ', 96.0),\n",
       " ('รู้สึก', 95.0),\n",
       " ('โดย', 95.0),\n",
       " ('ผู้', 94.0),\n",
       " ('n', 94.0),\n",
       " ('รูป', 94.0),\n",
       " ('เห็น', 94.0),\n",
       " ('ริ', 94.0),\n",
       " ('้น', 93.0),\n",
       " ('ติด', 92.0),\n",
       " ('I', 92.0),\n",
       " ('ใคร', 92.0),\n",
       " ('20', 92.0),\n",
       " ('ติ', 92.0),\n",
       " ('สามารถ', 92.0),\n",
       " ('บอก', 91.0),\n",
       " ('อม', 91.0),\n",
       " ('ครั้ง', 90.0),\n",
       " ('ลา', 89.0),\n",
       " ('แม่', 89.0),\n",
       " ('ิ่ง', 89.0),\n",
       " ('่ง', 89.0),\n",
       " ('9', 88.0),\n",
       " ('▁เพราะ', 88.0),\n",
       " ('v', 87.0),\n",
       " ('ี่', 87.0),\n",
       " ('รู้', 86.0),\n",
       " (';', 86.0),\n",
       " ('กระ', 86.0),\n",
       " ('เห', 86.0),\n",
       " ('เราก็', 85.0),\n",
       " ('ร์', 85.0),\n",
       " ('เส', 84.0),\n",
       " ('re', 84.0),\n",
       " ('ค่า', 84.0),\n",
       " ('ชา', 84.0),\n",
       " ('ช่วง', 84.0),\n",
       " ('แค่', 84.0),\n",
       " ('แฟน', 84.0),\n",
       " ('ร้าน', 84.0),\n",
       " ('เรียน', 84.0),\n",
       " ('\"', 83.0),\n",
       " ('▁S', 83.0),\n",
       " ('กว่า', 83.0),\n",
       " ('ผล', 83.0),\n",
       " ('ทําให้', 82.0),\n",
       " ('อา', 82.0),\n",
       " ('▁ผม', 82.0),\n",
       " ('๊', 82.0),\n",
       " ('วง', 82.0),\n",
       " ('เยอะ', 82.0),\n",
       " ('ษ', 82.0),\n",
       " ('O', 81.0),\n",
       " ('เคย', 80.0),\n",
       " ('in', 80.0),\n",
       " ('#', 80.0),\n",
       " ('or', 80.0),\n",
       " ('ลูก', 80.0),\n",
       " ('รี', 80.0),\n",
       " ('▁C', 79.0),\n",
       " ('ทุก', 79.0),\n",
       " ('ควร', 78.0),\n",
       " ('ฝ', 78.0),\n",
       " ('ข้อความ', 77.0),\n",
       " ('R', 77.0),\n",
       " ('ไหม', 77.0),\n",
       " ('ทํางาน', 76.0),\n",
       " ('ถ้า', 76.0),\n",
       " ('er', 75.0),\n",
       " ('เจอ', 75.0),\n",
       " ('เดียว', 75.0),\n",
       " ('ฉ', 75.0),\n",
       " ('แรก', 75.0),\n",
       " ('รอง', 74.0),\n",
       " ('เพื่อ', 74.0),\n",
       " ('N', 74.0),\n",
       " ('ใหม่', 74.0),\n",
       " ('กําลัง', 74.0),\n",
       " ('อง', 74.0),\n",
       " ('เล', 74.0),\n",
       " ('อย', 72.0),\n",
       " ('ระ', 72.0),\n",
       " ('เม', 72.0),\n",
       " ('▁ซึ่ง', 72.0),\n",
       " ('▁ถ้า', 72.0),\n",
       " ('กิน', 72.0),\n",
       " ('เริ่ม', 71.0),\n",
       " ('(', 71.0),\n",
       " ('เค', 71.0),\n",
       " ('พระ', 70.0),\n",
       " ('E', 69.0),\n",
       " ('S', 69.0),\n",
       " ('บาง', 69.0),\n",
       " ('ถูก', 69.0),\n",
       " ('เก', 69.0),\n",
       " ('ึ', 69.0),\n",
       " ('นิ', 69.0),\n",
       " ('คิด', 68.0),\n",
       " ('คํา', 68.0),\n",
       " ('นอน', 68.0),\n",
       " ('อด', 68.0),\n",
       " ('แนะนํา', 68.0),\n",
       " ('://', 68.0),\n",
       " ('จะมี', 68.0),\n",
       " ('หลัง', 67.0),\n",
       " ('ยังไง', 67.0),\n",
       " ('อร์', 67.0),\n",
       " ('เค้า', 67.0),\n",
       " ('F', 66.0),\n",
       " ('น้อง', 66.0),\n",
       " ('ใส่', 66.0),\n",
       " ('วิ', 66.0),\n",
       " ('ู่', 66.0),\n",
       " ('**', 65.0),\n",
       " ('r', 65.0),\n",
       " ('เอง', 65.0),\n",
       " ('ส่วน', 65.0),\n",
       " ('ัย', 65.0),\n",
       " ('▁แก้ไข', 64.0),\n",
       " ('C', 64.0),\n",
       " ('เลือก', 64.0),\n",
       " ('ตั้ง', 64.0),\n",
       " ('ธ', 64.0),\n",
       " ('ar', 63.0),\n",
       " ('แบบนี้', 63.0),\n",
       " ('น่า', 63.0),\n",
       " ('หนึ่ง', 63.0),\n",
       " ('ต้น', 62.0),\n",
       " ('ชื่อ', 62.0),\n",
       " ('ไทย', 62.0),\n",
       " ('เบ', 61.0),\n",
       " ('ผ่าน', 61.0),\n",
       " ('ื่อ', 61.0),\n",
       " ('ราคา', 60.0),\n",
       " ('อก', 60.0),\n",
       " ('หมด', 60.0),\n",
       " ('เพราะ', 60.0),\n",
       " ('ทําไม', 60.0),\n",
       " ('กร', 60.0),\n",
       " ('▁อยาก', 59.0),\n",
       " ('คุย', 59.0),\n",
       " ('ธนาคาร', 59.0),\n",
       " ('al', 58.0),\n",
       " ('ี้', 58.0),\n",
       " ('เเ', 58.0),\n",
       " ('เสีย', 58.0),\n",
       " ('ฮ', 58.0),\n",
       " ('ใหญ่', 58.0),\n",
       " ('นึง', 57.0),\n",
       " ('ไม่รู้', 57.0),\n",
       " ('ลอง', 57.0),\n",
       " ('เล่น', 57.0),\n",
       " ('สุด', 57.0),\n",
       " ('เดือน', 57.0),\n",
       " ('D', 56.0),\n",
       " ('10', 56.0),\n",
       " ('เป', 56.0),\n",
       " ('หนัก', 56.0),\n",
       " ('com', 56.0),\n",
       " ('ภาพ', 56.0),\n",
       " ('ภ', 56.0),\n",
       " ('พี่', 55.0),\n",
       " ('เด', 55.0),\n",
       " ('นี่', 55.0),\n",
       " ('มากๆ', 55.0),\n",
       " ('วน', 55.0),\n",
       " ('an', 54.0),\n",
       " ('ส่ง', 54.0),\n",
       " ('ตลอด', 54.0),\n",
       " ('H', 54.0),\n",
       " ('ถาม', 54.0),\n",
       " ('หลาย', 54.0),\n",
       " ('คืน', 53.0),\n",
       " ('ขอบคุณ', 53.0),\n",
       " ('เปลี่ยน', 53.0),\n",
       " ('ตา', 53.0),\n",
       " ('กระทู้', 53.0),\n",
       " ('ขาย', 53.0),\n",
       " ('เปิด', 53.0),\n",
       " ('ตรง', 53.0),\n",
       " ('▁M', 52.0),\n",
       " ('จริง', 52.0),\n",
       " ('บุ', 52.0),\n",
       " ('ตอบ', 52.0),\n",
       " ('ไหมครับ', 52.0),\n",
       " ('งค์', 52.0),\n",
       " ('สม', 52.0),\n",
       " ('ยังไม่', 51.0),\n",
       " ('L', 50.0),\n",
       " ('มือ', 50.0),\n",
       " ('คนที่', 50.0),\n",
       " ('คุณ', 50.0),\n",
       " ('นาน', 50.0),\n",
       " ('▁http', 50.0),\n",
       " ('จ่าย', 50.0),\n",
       " ('ื', 50.0),\n",
       " ('รอบ', 50.0),\n",
       " ('หาย', 50.0),\n",
       " ('as', 50.0),\n",
       " ('รัก', 49.0),\n",
       " ('ประมาณ', 49.0),\n",
       " ('ราย', 49.0),\n",
       " ('วิธี', 49.0),\n",
       " ('จบ', 49.0),\n",
       " ('^', 48.0),\n",
       " ('ra', 48.0),\n",
       " ('st', 48.0),\n",
       " ('บอกว่า', 48.0),\n",
       " ('ผิด', 48.0),\n",
       " ('เว', 48.0),\n",
       " (',', 47.0),\n",
       " ('ปัญหา', 47.0),\n",
       " ('เกิด', 47.0),\n",
       " ('ตร', 47.0),\n",
       " ('ย์', 47.0),\n",
       " ('G', 46.0),\n",
       " ('ปกติ', 46.0),\n",
       " ('มั้ย', 46.0),\n",
       " ('ไฟ', 46.0),\n",
       " ('ถ่าย', 46.0),\n",
       " (\"'\", 46.0),\n",
       " ('....', 45.0),\n",
       " ('ตัวเอง', 45.0),\n",
       " ('ไร', 45.0),\n",
       " ('พัก', 45.0),\n",
       " ('ื่น', 45.0),\n",
       " ('รุ', 45.0),\n",
       " ('พล', 45.0),\n",
       " ('พูด', 45.0),\n",
       " ('แน่', 45.0),\n",
       " ('M', 44.0),\n",
       " ('&', 44.0),\n",
       " ('ื้อ', 44.0),\n",
       " ('z', 44.0),\n",
       " ('เอ', 44.0),\n",
       " ('นํา', 44.0),\n",
       " ('เจ้า', 44.0),\n",
       " ('ต่าง', 44.0),\n",
       " ('le', 43.0),\n",
       " ('พ่อ', 43.0),\n",
       " ('โดน', 43.0),\n",
       " ('x', 43.0),\n",
       " ('ขนาด', 43.0),\n",
       " ('เที่ยว', 43.0),\n",
       " ('อัน', 43.0),\n",
       " ('K', 43.0),\n",
       " ('รัฐ', 43.0),\n",
       " ('บาท', 42.0),\n",
       " ('สอบถาม', 42.0),\n",
       " ('สาย', 42.0),\n",
       " ('หรอ', 42.0),\n",
       " ('สิ', 42.0),\n",
       " ('อะ', 42.0),\n",
       " ('am', 41.0),\n",
       " ('V', 41.0),\n",
       " ('en', 41.0),\n",
       " ('เล็ก', 41.0),\n",
       " ('ช่อง', 41.0),\n",
       " ('ู้', 41.0),\n",
       " ('ถือ', 40.0),\n",
       " ('รุ่น', 40.0),\n",
       " ('สูง', 40.0),\n",
       " ('กลับ', 40.0),\n",
       " ('เดิน', 40.0),\n",
       " ('หมอ', 40.0),\n",
       " ('ออกมา', 40.0),\n",
       " ('ic', 40.0),\n",
       " ('il', 39.0),\n",
       " ('...', 39.0),\n",
       " ('เข้าใจ', 39.0),\n",
       " ('ประเทศ', 39.0),\n",
       " ('นะครับ', 39.0),\n",
       " ('ไม่ค่อย', 39.0),\n",
       " ('เร็ว', 39.0),\n",
       " ('เช่น', 39.0),\n",
       " ('ไหมคะ', 39.0),\n",
       " ('จริงๆ', 39.0),\n",
       " ('ั่น', 38.0),\n",
       " ('it', 38.0),\n",
       " ('หัว', 38.0),\n",
       " ('ือ', 38.0),\n",
       " ('โลก', 38.0),\n",
       " ('๋', 38.0),\n",
       " ('ใช่', 38.0),\n",
       " ('นัก', 38.0),\n",
       " ('เลยค่ะ', 38.0),\n",
       " ('คิดว่า', 38.0),\n",
       " ('วันที่', 38.0),\n",
       " ('รวม', 37.0),\n",
       " ('มีความ', 37.0),\n",
       " ('ข้าง', 37.0),\n",
       " ('มอง', 37.0),\n",
       " ('ธรรม', 37.0),\n",
       " ('เหลือ', 36.0),\n",
       " ('นอก', 36.0),\n",
       " ('ห้อง', 36.0),\n",
       " ('อาหาร', 36.0),\n",
       " ('ตั้งแต่', 36.0),\n",
       " ('ด้าน', 35.0),\n",
       " ('เท่า', 35.0),\n",
       " ('ter', 35.0),\n",
       " ('สอง', 34.0),\n",
       " ('วันนี้', 34.0),\n",
       " ('แก้', 34.0),\n",
       " ('ใ', 34.0),\n",
       " ('อ่าน', 34.0),\n",
       " ('สี', 34.0),\n",
       " ('▁พอดี', 33.0),\n",
       " ('กลัว', 33.0),\n",
       " ('ไอ', 33.0),\n",
       " ('ั่ง', 33.0),\n",
       " ('ในการ', 33.0),\n",
       " ('ไม่ใช่', 33.0),\n",
       " ('ไม้', 33.0),\n",
       " ('นิด', 32.0),\n",
       " ('พวก', 32.0),\n",
       " ('สําหรับ', 32.0),\n",
       " ('ทราบ', 32.0),\n",
       " ('เตอร์', 32.0),\n",
       " ('เลิก', 32.0),\n",
       " ('หุ้น', 32.0),\n",
       " ('จึง', 32.0),\n",
       " ('เชื่อ', 32.0),\n",
       " ('เดิม', 32.0),\n",
       " ('J', 31.0),\n",
       " ('ad', 31.0),\n",
       " ('เด็ก', 31.0),\n",
       " ('สัก', 31.0),\n",
       " ('กลับมา', 31.0),\n",
       " ('ชีวิต', 31.0),\n",
       " ('j', 30.0),\n",
       " ('เป็นคน', 30.0),\n",
       " ('น้อย', 30.0),\n",
       " ('อื่น', 30.0),\n",
       " ('เกิน', 30.0),\n",
       " ('เมือง', 30.0),\n",
       " ('จัด', 30.0),\n",
       " ('el', 30.0),\n",
       " ('U', 29.0),\n",
       " ('[', 29.0),\n",
       " (']', 29.0),\n",
       " ('25', 29.0),\n",
       " ('ข้อ', 29.0),\n",
       " ('ก้', 29.0),\n",
       " ('เครื่อง', 29.0),\n",
       " ('นั่ง', 29.0),\n",
       " ('จํา', 29.0),\n",
       " ('คง', 29.0),\n",
       " ('อายุ', 29.0),\n",
       " ('gt', 29.0),\n",
       " ('ข้อมูล', 29.0),\n",
       " ('เย็น', 29.0),\n",
       " ('กี่', 28.0),\n",
       " ('ทํายังไง', 28.0),\n",
       " ('“', 28.0),\n",
       " ('มากกว่า', 28.0),\n",
       " ('หมาย', 28.0),\n",
       " ('ผิว', 28.0),\n",
       " ('แพ', 28.0),\n",
       " ('หลัก', 28.0),\n",
       " ('สินค้า', 28.0),\n",
       " ('เพิ่ง', 28.0),\n",
       " ('un', 28.0),\n",
       " ('มีใคร', 27.0),\n",
       " ('เก่า', 27.0),\n",
       " ('รบกวน', 27.0),\n",
       " ('สนใจ', 27.0),\n",
       " ('to', 27.0),\n",
       " ('co', 27.0),\n",
       " ('เก็บ', 27.0),\n",
       " ('19', 27.0),\n",
       " ('สั่ง', 27.0),\n",
       " ('ro', 27.0),\n",
       " ('ทุน', 27.0),\n",
       " ('Y', 26.0),\n",
       " ('▁1.', 26.0),\n",
       " ('!!', 26.0),\n",
       " ('เกือบ', 26.0),\n",
       " ('ชาติ', 26.0),\n",
       " ('ลูกค้า', 26.0),\n",
       " ('พื้น', 26.0),\n",
       " ('ใบ', 26.0),\n",
       " ('ww', 26.0),\n",
       " ('ึก', 26.0),\n",
       " ('แรง', 26.0),\n",
       " ('เพิ่ม', 25.0),\n",
       " ('ll', 25.0),\n",
       " ('ch', 25.0),\n",
       " ('”', 25.0),\n",
       " ('หนัง', 25.0),\n",
       " ('ฝาก', 25.0),\n",
       " ('W', 25.0),\n",
       " ('99', 25.0),\n",
       " ('ส่วนตัว', 25.0),\n",
       " ('สอบ', 25.0),\n",
       " ('ทะเล', 25.0),\n",
       " ('ข้าว', 25.0),\n",
       " ('เนื่องจาก', 25.0),\n",
       " ('แห่ง', 25.0),\n",
       " ('30', 25.0),\n",
       " ('บัตร', 25.0),\n",
       " ('โอกาส', 25.0),\n",
       " ('โปร', 24.0),\n",
       " ('ed', 24.0),\n",
       " ('จุด', 24.0),\n",
       " ('เเล้ว', 24.0),\n",
       " ('!', 24.0),\n",
       " ('พร้อม', 24.0),\n",
       " ('เนื้อ', 24.0),\n",
       " ('ฤ', 24.0),\n",
       " ('สาร', 24.0),\n",
       " ('ใด', 24.0),\n",
       " ('เสียง', 24.0),\n",
       " ('กลาง', 24.0),\n",
       " ('ประชาชน', 24.0),\n",
       " ('ri', 23.0),\n",
       " ('มั้ยคะ', 23.0),\n",
       " ('รีวิว', 23.0),\n",
       " ('อยากรู้ว่า', 23.0),\n",
       " ('is', 23.0),\n",
       " ('ทุกคน', 23.0),\n",
       " ('น่าจะ', 23.0),\n",
       " ('อยากให้', 23.0),\n",
       " ('ฒ', 23.0),\n",
       " ('พยายาม', 23.0),\n",
       " ('เกี่ยวกับ', 23.0),\n",
       " ('เรียก', 23.0),\n",
       " ('50', 23.0),\n",
       " ('ประสบการณ์', 23.0),\n",
       " ('0%', 22.0),\n",
       " ('*', 22.0),\n",
       " ('ปรึกษา', 22.0),\n",
       " ('สําคัญ', 22.0),\n",
       " ('ง่าย', 22.0),\n",
       " ('สงสัย', 22.0),\n",
       " ('นาง', 22.0),\n",
       " ('อ่ะ', 22.0),\n",
       " ('เพียง', 22.0),\n",
       " ('16', 21.0),\n",
       " ('สร้าง', 21.0),\n",
       " ('จีน', 21.0),\n",
       " ('ระหว่าง', 21.0),\n",
       " ('ปล่อย', 21.0),\n",
       " ('เต็ม', 21.0),\n",
       " ('กลุ่ม', 21.0),\n",
       " ('มีปัญหา', 21.0),\n",
       " ('เจ็บ', 21.0),\n",
       " ('คนอื่น', 21.0),\n",
       " ('ไม่เคย', 21.0),\n",
       " ('อย่างไร', 21.0),\n",
       " ('ต่างๆ', 21.0),\n",
       " ('ฯ', 21.0),\n",
       " ('th', 21.0),\n",
       " ('ครอบครัว', 20.0),\n",
       " ('=', 20.0),\n",
       " ('เเต่', 20.0),\n",
       " ('เน็ต', 20.0),\n",
       " ('ปิด', 20.0),\n",
       " ('ฆ', 20.0),\n",
       " ('ใกล้', 20.0),\n",
       " ('ตรวจ', 20.0),\n",
       " ('จังหวัด', 20.0),\n",
       " ('ตัด', 20.0),\n",
       " ('บ่อย', 20.0),\n",
       " ('ั่ว', 20.0),\n",
       " ('เช้า', 20.0),\n",
       " ('ระบบ', 20.0),\n",
       " ('สาว', 20.0),\n",
       " (',000', 20.0),\n",
       " ('บัญชี', 20.0),\n",
       " ('หวัง', 19.0),\n",
       " ('อาจจะ', 19.0),\n",
       " ('พนักงาน', 19.0),\n",
       " ('เท่าไหร่', 19.0),\n",
       " ('ผู้หญิง', 19.0),\n",
       " ('ภาค', 19.0),\n",
       " ('รักษา', 19.0),\n",
       " ('เกาหลี', 19.0),\n",
       " ('ร่วม', 19.0),\n",
       " ('กองทุน', 19.0),\n",
       " ('ing', 18.0),\n",
       " ('ปัจจุบัน', 18.0),\n",
       " ('me', 18.0),\n",
       " ('%', 18.0),\n",
       " ('โทร', 18.0),\n",
       " ('ระดับ', 18.0),\n",
       " ('opic', 18.0),\n",
       " ('ค่อนข้าง', 18.0),\n",
       " ('เสร็จ', 18.0),\n",
       " ('โรงเรียน', 18.0),\n",
       " ('สิทธิ', 18.0),\n",
       " ('อยากทราบว่า', 18.0),\n",
       " ('pantip', 18.0),\n",
       " ('and', 18.0),\n",
       " ('แย่', 18.0),\n",
       " ('ฟัง', 18.0),\n",
       " ('X', 17.0),\n",
       " ('12', 17.0),\n",
       " ('ฐาน', 17.0),\n",
       " ('หยุด', 17.0),\n",
       " ('ฏ', 17.0),\n",
       " ('แจ้ง', 17.0),\n",
       " ('เพลง', 17.0),\n",
       " ('เบอร์', 17.0),\n",
       " ('ประจํา', 17.0),\n",
       " ('แสดง', 17.0),\n",
       " ('หาก', 17.0),\n",
       " ('ธุรกิจ', 17.0),\n",
       " ('_', 16.0),\n",
       " ('🙏', 16.0),\n",
       " ('+', 16.0),\n",
       " ('สวย', 16.0),\n",
       " ('ผู้ชาย', 16.0),\n",
       " ('แหละ', 16.0),\n",
       " ('▁สวัสดีค่ะ', 16.0),\n",
       " ('ย้าย', 16.0),\n",
       " ('อาทิตย์', 16.0),\n",
       " ('แม้', 16.0),\n",
       " ('ซึ่ง', 16.0),\n",
       " ('ท่าน', 16.0),\n",
       " ('อยู่ใน', 16.0),\n",
       " ('{', 16.0),\n",
       " ('}', 16.0),\n",
       " ('ฟัน', 16.0),\n",
       " ('15', 15.0),\n",
       " ('กรรม', 15.0),\n",
       " ('สาม', 15.0),\n",
       " ('ปันผล', 15.0),\n",
       " ('ร้องไห้', 15.0),\n",
       " ('สังเกต', 15.0),\n",
       " ('บริษัท', 15.0),\n",
       " ('แทน', 15.0),\n",
       " ('น้ําตาล', 15.0),\n",
       " ('แก้ไข', 15.0),\n",
       " ('ร้อน', 14.0),\n",
       " ('พึ่ง', 14.0),\n",
       " ('▁2.', 14.0),\n",
       " ('เกม', 14.0),\n",
       " ('เฉพาะ', 14.0),\n",
       " ('อย่า', 14.0),\n",
       " ('เติม', 14.0),\n",
       " ('สัญญา', 14.0),\n",
       " ('ขณะ', 14.0),\n",
       " ('อนาคต', 14.0),\n",
       " ('ตลาด', 14.0),\n",
       " ('ร้อง', 14.0),\n",
       " ('สมัคร', 14.0),\n",
       " ('ระยะ', 14.0),\n",
       " ('▁บาท', 14.0),\n",
       " ('สิ่งที่', 14.0),\n",
       " ('รู้จัก', 14.0),\n",
       " ('$', 14.0),\n",
       " ('review', 14.0),\n",
       " ('แถม', 13.0),\n",
       " ('▁3.', 13.0),\n",
       " ('เหนื่อย', 13.0),\n",
       " ('น่ะ', 13.0),\n",
       " ('facebook', 13.0),\n",
       " ('ข้าม', 13.0),\n",
       " ('เลี้ยง', 13.0),\n",
       " ('ศาสตร์', 13.0),\n",
       " ('เดินทาง', 13.0),\n",
       " ('ญี่ปุ่น', 13.0),\n",
       " ('ห้าม', 13.0),\n",
       " ('สบาย', 13.0),\n",
       " ('สนิท', 12.0),\n",
       " ('เลือด', 12.0),\n",
       " ('ฝ่าย', 12.0),\n",
       " ('ใต้', 12.0),\n",
       " ('ประโยชน์', 12.0),\n",
       " ('เรื่อยๆ', 12.0),\n",
       " ('โควิด', 12.0),\n",
       " ('5555', 12.0),\n",
       " ('555', 12.0),\n",
       " ('หนังสือ', 12.0),\n",
       " ('กล้อง', 12.0),\n",
       " ('ลําดับ', 12.0),\n",
       " ('คลิก', 11.0),\n",
       " ('เครียด', 11.0),\n",
       " ('▁หลังจาก', 11.0),\n",
       " ('ชั่วโมง', 11.0),\n",
       " ('เขียน', 11.0),\n",
       " ('เท่านั้น', 11.0),\n",
       " ('ฎ', 11.0),\n",
       " ('แผ่น', 11.0),\n",
       " ('ล่วงหน้า', 11.0),\n",
       " ('ออนไลน์', 11.0),\n",
       " ('เธอ', 11.0),\n",
       " ('แดง', 11.0),\n",
       " ('ศึกษา', 11.0),\n",
       " ('โทรศัพท์', 11.0),\n",
       " ('แอบ', 11.0),\n",
       " ('ความรู้', 11.0),\n",
       " ('แปล', 11.0),\n",
       " ('สถาน', 11.0),\n",
       " ('เนื้อหา', 11.0),\n",
       " ('เรีย', 11.0),\n",
       " ('ปรากฏ', 11.0),\n",
       " ('เหตุผล', 11.0),\n",
       " ('รายละเอียด', 11.0),\n",
       " ('เทียบ', 11.0),\n",
       " ('ประกาศ', 11.0),\n",
       " ('ไหว', 11.0),\n",
       " ('ส่วนใหญ่', 11.0),\n",
       " ('ight', 11.0),\n",
       " ('ment', 11.0),\n",
       " ('คะแนน', 11.0),\n",
       " ('กรณี', 11.0),\n",
       " ('บริหาร', 11.0),\n",
       " ('📌', 11.0),\n",
       " ('แนว', 10.0),\n",
       " ('ภาษาอังกฤษ', 10.0),\n",
       " ('ประกอบ', 10.0),\n",
       " ('จํากัด', 10.0),\n",
       " ('ข่าว', 10.0),\n",
       " ('เเบบ', 10.0),\n",
       " ('แข็ง', 10.0),\n",
       " ('ํ', 10.0),\n",
       " ('เรือน', 10.0),\n",
       " ('ทําไงดี', 10.0),\n",
       " ('ซ่อม', 10.0),\n",
       " ('หนู', 10.0),\n",
       " ('เชื้อ', 10.0),\n",
       " ('Z', 9.0),\n",
       " ('ir', 9.0),\n",
       " ('age', 9.0),\n",
       " ('เพิ่มเติม', 9.0),\n",
       " ('ฬ', 9.0),\n",
       " ('ขอคําแนะนํา', 9.0),\n",
       " ('บริเวณ', 9.0),\n",
       " ('ยอมรับ', 9.0),\n",
       " ('ฐ', 9.0),\n",
       " ('เช็ค', 9.0),\n",
       " ('กรุงเทพ', 9.0),\n",
       " ('แยก', 9.0),\n",
       " ('ขาว', 9.0),\n",
       " ('สุดท้าย', 9.0),\n",
       " ('ภัย', 9.0),\n",
       " ('พลาด', 9.0),\n",
       " ('คําถาม', 9.0),\n",
       " ('️', 9.0),\n",
       " ('฿', 9.0),\n",
       " ('สถานการณ์', 9.0),\n",
       " ('----------------', 9.0),\n",
       " ('ปาก', 8.0),\n",
       " ('รึเปล่า', 8.0),\n",
       " ('ตามหัวข้อเลย', 8.0),\n",
       " ('ละเอียด', 8.0),\n",
       " ('หรือเปล่า', 8.0),\n",
       " ('กลิ่น', 8.0),\n",
       " ('กล่อง', 8.0),\n",
       " ('ทั่วไป', 8.0),\n",
       " ('ร้าย', 8.0),\n",
       " ('ตัดสินใจ', 8.0),\n",
       " ('ภายใน', 8.0),\n",
       " ('ร้อย', 8.0),\n",
       " ('หญิง', 8.0),\n",
       " ('พิมพ์', 8.0),\n",
       " ('จํานวน', 8.0),\n",
       " ('พาณิชย์', 8.0),\n",
       " ('ประเภท', 8.0),\n",
       " ('แพทย์', 8.0),\n",
       " ('ฉัน', 8.0),\n",
       " ('มิถุนายน', 8.0),\n",
       " ('เจ้าหน้าที่', 8.0),\n",
       " ('ลืม', 7.0),\n",
       " ('🏻', 7.0),\n",
       " ('พิเศษ', 7.0),\n",
       " ('q', 7.0),\n",
       " ('net', 7.0),\n",
       " ('ขอโทษ', 7.0),\n",
       " ('ราชการ', 7.0),\n",
       " ('😭', 7.0),\n",
       " ('สังคม', 7.0),\n",
       " ('อธิบาย', 7.0),\n",
       " ('|', 7.0),\n",
       " ('กังวล', 7.0),\n",
       " ('บริการ', 7.0),\n",
       " ('อํานาจ', 7.0),\n",
       " ('สัมพันธ์', 6.0),\n",
       " ('เศรษฐกิจ', 6.0),\n",
       " ('คุ้ม', 6.0),\n",
       " ('ไลน์', 6.0),\n",
       " ('สาขา', 6.0),\n",
       " ('▁the', 6.0),\n",
       " ('shop', 6.0),\n",
       " ('แบงค์', 6.0),\n",
       " ('@', 6.0),\n",
       " ('ละคร', 6.0),\n",
       " ('นโยบาย', 6.0),\n",
       " ('ภูมิ', 5.0),\n",
       " ('เกาะ', 5.0),\n",
       " ('อากาศ', 5.0),\n",
       " ('’', 5.0),\n",
       " ('เรือ', 5.0),\n",
       " ('เตรียม', 5.0),\n",
       " ('???', 5.0),\n",
       " ('อาชีพ', 5.0),\n",
       " ('ไฟฟ้า', 5.0),\n",
       " ('สูตร', 5.0),\n",
       " ('▁4.', 5.0),\n",
       " ('เทคนิค', 5.0),\n",
       " ('ล่าสุด', 5.0),\n",
       " ('ทุกท่าน', 4.0),\n",
       " ('~', 4.0),\n",
       " ('วิทยา', 4.0),\n",
       " ('สัปดาห์', 4.0),\n",
       " ('การบิน', 4.0),\n",
       " ('เหตุการณ์', 4.0),\n",
       " ('ชุด', 4.0),\n",
       " ('😂', 4.0),\n",
       " ('ฑ', 4.0),\n",
       " ('ความคิดเห็น', 4.0),\n",
       " ('ศูนย์', 4.0),\n",
       " ('>', 4.0),\n",
       " ('ทะเบียน', 4.0),\n",
       " ('⭐', 4.0),\n",
       " ('ภาษา', 4.0),\n",
       " ('บํารุง', 4.0),\n",
       " ('▁Line', 3.0),\n",
       " ('▁ไม่ว่าจะเป็น', 3.0),\n",
       " ('หน่วย', 3.0),\n",
       " ('เฉย', 3.0),\n",
       " ('คลิป', 3.0),\n",
       " ('▁โดยเฉพาะ', 3.0),\n",
       " ('Q', 3.0),\n",
       " ('พระเอก', 3.0),\n",
       " ('•', 3.0),\n",
       " ('‘', 3.0),\n",
       " ('ᴊᴀᴘᴀɴ', 3.0),\n",
       " ('🔸', 3.0),\n",
       " ('▁กรม', 3.0),\n",
       " ('🌼', 3.0),\n",
       " ('ซิม', 2.0),\n",
       " ('–', 2.0),\n",
       " ('❤', 2.0),\n",
       " ('ココア', 2.0),\n",
       " ('カフェ', 2.0),\n",
       " ('พัสดุ', 2.0),\n",
       " ('สนุก', 2.0),\n",
       " ('เล่ม', 2.0),\n",
       " ('æ', 2.0),\n",
       " ('ᴇᴠᴇɴᴛᴇᴇɴ', 2.0),\n",
       " ('ᴏғғɪᴄɪᴀʟ', 2.0),\n",
       " ('2-3', 2.0),\n",
       " ('✨', 2.0),\n",
       " ('🌿', 2.0),\n",
       " ('😊', 1.0),\n",
       " ('♡ᅲᅳᅲ', 1.0),\n",
       " ('😕', 1.0),\n",
       " ('😀', 1.0),\n",
       " ('ಥ‿ಥ', 1.0),\n",
       " ('😅', 1.0),\n",
       " ('😢', 1.0),\n",
       " ('💕💕💕💕💕', 1.0),\n",
       " ('จัดส่ง', 1.0),\n",
       " ('▁วันทําการ', 1.0),\n",
       " ('😞', 1.0),\n",
       " ('😞👉👈', 1.0),\n",
       " ('😄', 1.0),\n",
       " ('😊😊', 1.0),\n",
       " ('「', 1.0),\n",
       " ('」', 1.0),\n",
       " ('<<', 1.0),\n",
       " ('🍉', 1.0),\n",
       " ('หน่วยงานราชการ', 1.0),\n",
       " ('พักผ่อน', 1.0),\n",
       " ('🗺', 1.0),\n",
       " ('🎎🎏🎐🎆', 1.0),\n",
       " ('😠😠😠😠', 1.0),\n",
       " ('🤨🤨', 1.0),\n",
       " ('😓', 1.0),\n",
       " ('ᅲ', 1.0),\n",
       " ('ᅮ', 1.0),\n",
       " ('🌈', 1.0),\n",
       " ('—', 1.0),\n",
       " ('📒✨', 1.0),\n",
       " ('📒', 1.0),\n",
       " ('헹가래', 1.0),\n",
       " ('🏝', 1.0),\n",
       " ('⛵', 1.0),\n",
       " ('ɪᴛᴇ', 1.0),\n",
       " ('ɪᴛᴇᴛᴡɪᴛᴛᴇʀ', 1.0),\n",
       " ('ᴛᴡɪᴛᴛᴇʀ', 1.0),\n",
       " ('ғᴀᴄᴇʙᴏᴏᴋ', 1.0),\n",
       " ('ɪɴ', 1.0),\n",
       " ('ᴛᴀɢʀᴀᴍᴡᴇɪʙᴏ', 1.0),\n",
       " ('ᴄᴀғᴇ', 1.0),\n",
       " ('ᴅᴀᴜᴍ', 1.0),\n",
       " ('ᴠ', 1.0),\n",
       " ('ᴀᴘᴘ', 1.0),\n",
       " ('ᴏᴜɴᴅᴄʟᴏᴜᴅʏᴏᴜᴛᴜʙᴇ', 1.0),\n",
       " ('ʏᴏᴜᴛᴜʙᴇ', 1.0),\n",
       " ('ᴡᴇᴠᴇʀ', 1.0),\n",
       " ('ᴇᴛɪᴋᴛᴏᴋ', 1.0),\n",
       " ...]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_tokens_pantip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('▁', 5197.0),\n",
       " ('เ', 1775.0),\n",
       " ('ก', 1425.0),\n",
       " ('า', 1417.0),\n",
       " ('น', 1373.0),\n",
       " ('ม', 1307.0),\n",
       " ('ย', 1211.0),\n",
       " ('ร', 1127.0),\n",
       " ('ว', 1066.0),\n",
       " ('ด', 1043.0),\n",
       " ('บ', 1040.0),\n",
       " ('ส', 1024.0),\n",
       " ('ง', 915.0),\n",
       " ('ห', 824.0),\n",
       " ('ค', 806.0),\n",
       " ('ี', 737.0),\n",
       " ('ล', 734.0),\n",
       " ('อ', 701.0),\n",
       " ('ท', 687.0),\n",
       " ('มา', 666.0),\n",
       " ('ุ', 662.0),\n",
       " ('ไป', 657.0),\n",
       " ('ให้', 650.0),\n",
       " ('จะ', 622.0),\n",
       " ('ช', 582.0),\n",
       " ('์', 569.0),\n",
       " ('ข', 544.0),\n",
       " ('แ', 541.0),\n",
       " ('ไม่', 536.0),\n",
       " ('ว่า', 520.0),\n",
       " ('พ', 516.0),\n",
       " ('โ', 475.0),\n",
       " ('พระ', 462.0),\n",
       " ('ฯ', 455.0),\n",
       " ('๏', 454.0),\n",
       " ('▁จะ', 421.0),\n",
       " ('ที่', 417.0),\n",
       " ('ิ', 399.0),\n",
       " ('เป็น', 387.0),\n",
       " ('ต', 382.0),\n",
       " ('ั', 379.0),\n",
       " ('ไ', 368.0),\n",
       " ('ป', 366.0),\n",
       " ('จ', 357.0),\n",
       " ('ู', 352.0),\n",
       " ('ะ', 350.0),\n",
       " ('ศ', 330.0),\n",
       " ('รา', 326.0),\n",
       " ('ยา', 321.0),\n",
       " ('อยู่', 314.0),\n",
       " ('ใจ', 313.0),\n",
       " ('เข้า', 297.0),\n",
       " ('คน', 295.0),\n",
       " ('่', 292.0),\n",
       " ('ได้', 288.0),\n",
       " ('ถ', 287.0),\n",
       " ('ลา', 282.0),\n",
       " ('ตาม', 280.0),\n",
       " ('ก็', 278.0),\n",
       " ('ษ', 277.0),\n",
       " ('ธ', 269.0),\n",
       " ('้', 267.0),\n",
       " ('่า', 257.0),\n",
       " ('าน', 254.0),\n",
       " ('กัน', 253.0),\n",
       " ('▁แล้ว', 251.0),\n",
       " ('▁ให้', 251.0),\n",
       " ('มี', 245.0),\n",
       " ('อน', 245.0),\n",
       " ('เหมือน', 245.0),\n",
       " ('▁พระ', 238.0),\n",
       " ('ประ', 238.0),\n",
       " ('ตร', 236.0),\n",
       " ('ใน', 235.0),\n",
       " ('เจ้า', 235.0),\n",
       " ('ํา', 234.0),\n",
       " ('▁นาง', 231.0),\n",
       " ('้า', 231.0),\n",
       " ('พล', 230.0),\n",
       " ('น้อง', 227.0),\n",
       " ('ดี', 223.0),\n",
       " ('ฉ', 218.0),\n",
       " ('ทํา', 217.0),\n",
       " ('องค์', 216.0),\n",
       " ('ับ', 214.0),\n",
       " ('พี่', 213.0),\n",
       " ('ัด', 209.0),\n",
       " ('ซ', 208.0),\n",
       " ('▁ฝ่าย', 208.0),\n",
       " ('คิด', 206.0),\n",
       " ('กับ', 206.0),\n",
       " ('พา', 204.0),\n",
       " ('ด้วย', 203.0),\n",
       " ('นาย', 203.0),\n",
       " ('่อ', 203.0),\n",
       " ('เห็น', 200.0),\n",
       " ('นาง', 199.0),\n",
       " ('▁ไม่', 197.0),\n",
       " ('รัก', 194.0),\n",
       " ('รู้', 193.0),\n",
       " ('ัง', 193.0),\n",
       " ('ผ', 192.0),\n",
       " ('หน้า', 187.0),\n",
       " ('ทั้ง', 187.0),\n",
       " ('ภ', 187.0),\n",
       " ('วง', 184.0),\n",
       " ('ถือ', 184.0),\n",
       " ('สาว', 182.0),\n",
       " ('หา', 179.0),\n",
       " ('ื', 178.0),\n",
       " ('นี้', 175.0),\n",
       " ('ดู', 174.0),\n",
       " ('กลับ', 172.0),\n",
       " ('ออก', 170.0),\n",
       " ('การ', 170.0),\n",
       " ('รับ', 170.0),\n",
       " ('▁จึง', 167.0),\n",
       " ('ัก', 167.0),\n",
       " ('ลี', 164.0),\n",
       " ('ทรง', 164.0),\n",
       " ('▁ทั้ง', 164.0),\n",
       " ('หน', 163.0),\n",
       " ('เสีย', 162.0),\n",
       " ('ลูก', 161.0),\n",
       " ('ทัพ', 161.0),\n",
       " ('ณ', 159.0),\n",
       " ('วิ', 158.0),\n",
       " ('ปร', 157.0),\n",
       " ('ัน', 156.0),\n",
       " ('อั', 156.0),\n",
       " ('กร', 154.0),\n",
       " ('กระ', 154.0),\n",
       " ('ญ', 153.0),\n",
       " ('่ง', 152.0),\n",
       " ('ตัว', 151.0),\n",
       " ('กล', 150.0),\n",
       " ('ถึง', 150.0),\n",
       " ('ขอ', 150.0),\n",
       " ('รบ', 150.0),\n",
       " ('ความ', 149.0),\n",
       " ('ข้า', 149.0),\n",
       " ('ตี', 149.0),\n",
       " ('ิน', 146.0),\n",
       " ('▁แต่', 145.0),\n",
       " ('ตาย', 143.0),\n",
       " ('▁มา', 142.0),\n",
       " ('อด', 142.0),\n",
       " ('แล้ว', 141.0),\n",
       " ('ช่วย', 141.0),\n",
       " ('แต่', 141.0),\n",
       " ('พร', 140.0),\n",
       " ('มิ', 140.0),\n",
       " ('เรา', 139.0),\n",
       " ('ฝ', 138.0),\n",
       " ('ริ', 138.0),\n",
       " ('หล', 138.0),\n",
       " ('▁ต่าง', 137.0),\n",
       " ('วน', 136.0),\n",
       " ('ด่าน', 135.0),\n",
       " ('ระ', 133.0),\n",
       " ('ือ', 133.0),\n",
       " ('▁เห็น', 133.0),\n",
       " ('ที', 130.0),\n",
       " ('ฤ', 130.0),\n",
       " ('ึก', 129.0),\n",
       " ('ไว้', 128.0),\n",
       " ('เส', 128.0),\n",
       " ('เขา', 127.0),\n",
       " ('ลง', 127.0),\n",
       " ('เสียง', 126.0),\n",
       " ('นา', 126.0),\n",
       " ('ขึ้น', 126.0),\n",
       " ('นั่ง', 125.0),\n",
       " ('หลัง', 124.0),\n",
       " ('กษัตริย์', 123.0),\n",
       " ('ไพร่', 122.0),\n",
       " ('ยก', 121.0),\n",
       " ('ฟัง', 119.0),\n",
       " ('เมือง', 118.0),\n",
       " ('นั้น', 117.0),\n",
       " ('สิ้น', 117.0),\n",
       " ('ต้อง', 117.0),\n",
       " ('่น', 117.0),\n",
       " ('▁พอ', 116.0),\n",
       " ('สม', 115.0),\n",
       " ('พวก', 114.0),\n",
       " ('ละ', 113.0),\n",
       " ('สอง', 113.0),\n",
       " ('ผู้', 112.0),\n",
       " ('้น', 110.0),\n",
       " ('ทูล', 109.0),\n",
       " ('พร้อม', 109.0),\n",
       " ('ยัง', 109.0),\n",
       " ('▁พวก', 109.0),\n",
       " ('มัน', 109.0),\n",
       " ('ฝรั่ง', 109.0),\n",
       " ('อง', 109.0),\n",
       " ('ึง', 108.0),\n",
       " ('▁เป็น', 108.0),\n",
       " ('หรือ', 108.0),\n",
       " ('ใคร', 107.0),\n",
       " ('วัง', 107.0),\n",
       " ('วัน', 106.0),\n",
       " ('ี่', 106.0),\n",
       " ('อบ', 106.0),\n",
       " ('อก', 105.0),\n",
       " ('สุ', 105.0),\n",
       " ('ๅ', 103.0),\n",
       " ('สั่ง', 102.0),\n",
       " ('้อง', 101.0),\n",
       " ('สู้', 100.0),\n",
       " ('เห', 99.0),\n",
       " ('จับ', 99.0),\n",
       " ('ชาว', 99.0),\n",
       " ('เอา', 98.0),\n",
       " ('ทุก', 98.0),\n",
       " ('ฆ่า', 98.0),\n",
       " ('จน', 98.0),\n",
       " ('สุด', 97.0),\n",
       " ('อย่า', 96.0),\n",
       " ('หนี', 96.0),\n",
       " ('คอย', 93.0),\n",
       " ('แม่', 93.0),\n",
       " ('ราช', 93.0),\n",
       " ('ื้อ', 93.0),\n",
       " ('็', 92.0),\n",
       " ('ของ', 91.0),\n",
       " ('▁ถึง', 91.0),\n",
       " ('น้อย', 91.0),\n",
       " ('ยง', 91.0),\n",
       " ('กลัว', 90.0),\n",
       " ('ข้าง', 89.0),\n",
       " ('ขับ', 89.0),\n",
       " ('ทาง', 88.0),\n",
       " ('ปล', 87.0),\n",
       " ('ย์', 87.0),\n",
       " ('นิ', 87.0),\n",
       " ('จํา', 86.0),\n",
       " ('วาย', 86.0),\n",
       " ('ุด', 86.0),\n",
       " ('ทหาร', 86.0),\n",
       " ('เฝ้า', 85.0),\n",
       " ('ผัว', 85.0),\n",
       " ('หมาย', 85.0),\n",
       " ('▁แม้', 84.0),\n",
       " ('นึก', 84.0),\n",
       " ('สิ', 84.0),\n",
       " ('เพราะ', 84.0),\n",
       " ('ไล่', 83.0),\n",
       " ('ลังกา', 83.0),\n",
       " ('เคย', 82.0),\n",
       " ('ฟัน', 82.0),\n",
       " ('้ม', 81.0),\n",
       " ('บอก', 80.0),\n",
       " ('จริง', 80.0),\n",
       " ('พิ', 79.0),\n",
       " ('▁ด้วย', 79.0),\n",
       " ('ศรี', 79.0),\n",
       " ('ดัง', 78.0),\n",
       " ('หญิง', 78.0),\n",
       " ('จึง', 77.0),\n",
       " ('รอง', 77.0),\n",
       " ('ต่าง', 77.0),\n",
       " ('โห', 77.0),\n",
       " ('ตั้ง', 76.0),\n",
       " ('หาย', 76.0),\n",
       " ('สาม', 76.0),\n",
       " ('ตรัส', 75.0),\n",
       " ('ี้', 75.0),\n",
       " ('เหลือ', 75.0),\n",
       " ('ห้าม', 74.0),\n",
       " ('่าย', 74.0),\n",
       " ('แสน', 74.0),\n",
       " ('สา', 74.0),\n",
       " ('รถ', 74.0),\n",
       " ('▁อย่า', 73.0),\n",
       " ('ผิด', 73.0),\n",
       " ('เลย', 72.0),\n",
       " ('บน', 72.0),\n",
       " ('น้ํา', 72.0),\n",
       " ('เคียง', 71.0),\n",
       " ('ชม', 71.0),\n",
       " ('แจ้ง', 70.0),\n",
       " ('อา', 70.0),\n",
       " ('ชาย', 70.0),\n",
       " ('ั่น', 70.0),\n",
       " ('▁บ้าง', 70.0),\n",
       " ('ท่าน', 68.0),\n",
       " ('วงศ์', 66.0),\n",
       " ('ยิ่ง', 66.0),\n",
       " ('▁อัน', 65.0),\n",
       " ('อี', 65.0),\n",
       " ('้อม', 65.0),\n",
       " ('จะได้', 64.0),\n",
       " ('ไหว', 64.0),\n",
       " ('อาย', 64.0),\n",
       " ('พบ', 64.0),\n",
       " ('โทษ', 63.0),\n",
       " ('ลม', 63.0),\n",
       " ('ฐ', 63.0),\n",
       " ('ราย', 63.0),\n",
       " ('ผา', 63.0),\n",
       " ('ไหน', 63.0),\n",
       " ('เหล่า', 62.0),\n",
       " ('▁จน', 62.0),\n",
       " ('ฆ', 62.0),\n",
       " ('ล่อ', 61.0),\n",
       " ('คุณ', 61.0),\n",
       " ('ลอง', 61.0),\n",
       " ('เที่ยว', 60.0),\n",
       " ('ขัด', 60.0),\n",
       " ('ยศ', 60.0),\n",
       " ('ค่อย', 60.0),\n",
       " ('สุดสาคร', 60.0),\n",
       " ('พัน', 60.0),\n",
       " ('ฟ', 60.0),\n",
       " ('ร้อง', 60.0),\n",
       " ('มิได้', 60.0),\n",
       " ('แกล้ง', 60.0),\n",
       " ('ดอก', 59.0),\n",
       " ('ลาย', 59.0),\n",
       " ('เล่า', 59.0),\n",
       " ('ั้น', 59.0),\n",
       " ('ใส่', 59.0),\n",
       " ('โศก', 59.0),\n",
       " ('จัด', 59.0),\n",
       " ('ชิง', 58.0),\n",
       " ('ท้าว', 58.0),\n",
       " ('สงสาร', 58.0),\n",
       " ('▁จง', 58.0),\n",
       " ('ผล', 58.0),\n",
       " ('ทั้งสอง', 57.0),\n",
       " ('พราหมณ์', 57.0),\n",
       " ('พงศ์', 57.0),\n",
       " ('ห้อง', 57.0),\n",
       " ('โปรด', 57.0),\n",
       " ('เดิน', 56.0),\n",
       " ('เมีย', 56.0),\n",
       " ('ไร', 56.0),\n",
       " ('ั่ง', 56.0),\n",
       " ('แต่ง', 56.0),\n",
       " ('กลาง', 56.0),\n",
       " ('▁ครั้น', 56.0),\n",
       " ('ู่', 56.0),\n",
       " ('เรือ', 56.0),\n",
       " ('เชิญ', 55.0),\n",
       " ('นี่', 55.0),\n",
       " ('ตา', 55.0),\n",
       " ('ใช้', 55.0),\n",
       " ('นอก', 54.0),\n",
       " ('วิ่ง', 54.0),\n",
       " ('ศึก', 53.0),\n",
       " ('แค้น', 53.0),\n",
       " ('ชาติ', 53.0),\n",
       " ('วัณฬา', 53.0),\n",
       " ('ทอง', 53.0),\n",
       " ('เครื่อง', 53.0),\n",
       " ('ม้า', 53.0),\n",
       " ('เกรง', 53.0),\n",
       " ('ใ', 53.0),\n",
       " ('จาก', 53.0),\n",
       " ('้ว', 53.0),\n",
       " ('พลับพลา', 52.0),\n",
       " ('เหตุ', 52.0),\n",
       " ('สาร', 52.0),\n",
       " ('ล้อม', 52.0),\n",
       " ('น่า', 51.0),\n",
       " ('แล', 51.0),\n",
       " ('พลาง', 51.0),\n",
       " ('พระองค์', 51.0),\n",
       " ('จิต', 51.0),\n",
       " ('หมอ', 51.0),\n",
       " ('ตรง', 50.0),\n",
       " ('เคือง', 50.0),\n",
       " ('หลับ', 50.0),\n",
       " ('สัตย์', 50.0),\n",
       " ('ป่า', 50.0),\n",
       " ('คง', 49.0),\n",
       " ('คู่', 49.0),\n",
       " ('สินสมุทร', 49.0),\n",
       " ('หลาน', 49.0),\n",
       " ('อ่อน', 49.0),\n",
       " ('ล้วน', 49.0),\n",
       " ('พระอภัย', 49.0),\n",
       " ('ใหญ่', 49.0),\n",
       " ('ร้อย', 49.0),\n",
       " ('▁เมื่อ', 48.0),\n",
       " ('กองทัพ', 48.0),\n",
       " ('หมอง', 48.0),\n",
       " ('จง', 47.0),\n",
       " ('เพชร', 47.0),\n",
       " ('ชื่น', 47.0),\n",
       " ('สาย', 47.0),\n",
       " ('ฉัน', 47.0),\n",
       " ('ั้ง', 47.0),\n",
       " ('ขวา', 47.0),\n",
       " ('ตรา', 46.0),\n",
       " ('ติ', 46.0),\n",
       " ('ไม่มี', 46.0),\n",
       " ('นอน', 46.0),\n",
       " ('สี่', 45.0),\n",
       " ('กราบ', 45.0),\n",
       " ('ุก', 45.0),\n",
       " ('ไฉน', 45.0),\n",
       " ('ลับ', 45.0),\n",
       " ('เรียก', 45.0),\n",
       " ('รําภา', 45.0),\n",
       " ('หลีก', 45.0),\n",
       " ('มือ', 44.0),\n",
       " ('ดับ', 44.0),\n",
       " ('คํา', 44.0),\n",
       " ('ผัน', 44.0),\n",
       " ('ตก', 44.0),\n",
       " ('นัก', 44.0),\n",
       " ('เล่น', 44.0),\n",
       " ('โยธา', 44.0),\n",
       " ('กิน', 43.0),\n",
       " ('ทุกข์', 43.0),\n",
       " ('แก้', 43.0),\n",
       " ('ตัด', 43.0),\n",
       " ('▁ซึ่ง', 43.0),\n",
       " ('พลอย', 43.0),\n",
       " ('นิ่ง', 42.0),\n",
       " ('แก้ว', 42.0),\n",
       " ('ึ', 42.0),\n",
       " ('หมด', 42.0),\n",
       " ('กรรม', 42.0),\n",
       " ('ยาม', 42.0),\n",
       " ('เสร็จ', 41.0),\n",
       " ('ผ่อน', 41.0),\n",
       " ('แสง', 41.0),\n",
       " ('เช่น', 41.0),\n",
       " ('เศร้า', 41.0),\n",
       " ('บุญ', 41.0),\n",
       " ('ท้าวทศวงศ์', 40.0),\n",
       " ('สะอื้น', 40.0),\n",
       " ('ฆ้อง', 40.0),\n",
       " ('พูด', 40.0),\n",
       " ('ร่วม', 40.0),\n",
       " ('กล้า', 40.0),\n",
       " ('หยุด', 40.0),\n",
       " ('ติด', 40.0),\n",
       " ('อย่าง', 40.0),\n",
       " ('พอ', 40.0),\n",
       " ('โกรธ', 40.0),\n",
       " ('ครั้ง', 40.0),\n",
       " ('ตะ', 40.0),\n",
       " ('ทิ้ง', 40.0),\n",
       " ('ปิด', 39.0),\n",
       " ('แก้ไข', 39.0),\n",
       " ('เรื่อง', 39.0),\n",
       " ('สัก', 39.0),\n",
       " ('หนึ่ง', 39.0),\n",
       " ('เวลา', 39.0),\n",
       " ('พักตร์', 39.0),\n",
       " ('หลวง', 39.0),\n",
       " ('เลี้ยง', 39.0),\n",
       " ('อาลัย', 39.0),\n",
       " ('มเหสี', 39.0),\n",
       " ('ยิง', 39.0),\n",
       " ('ปี', 39.0),\n",
       " ('ถาม', 38.0),\n",
       " ('กาย', 38.0),\n",
       " ('ร่ํา', 38.0),\n",
       " ('ถวาย', 38.0),\n",
       " ('ชื่อ', 38.0),\n",
       " ('ตอบ', 38.0),\n",
       " ('บรร', 38.0),\n",
       " ('เสนา', 38.0),\n",
       " ('ความตาม', 37.0),\n",
       " ('ต่อ', 37.0),\n",
       " ('ลิ', 37.0),\n",
       " ('อารมณ์', 37.0),\n",
       " ('หัก', 37.0),\n",
       " ('ร้อน', 37.0),\n",
       " ('เฒ่า', 37.0),\n",
       " ('สบาย', 37.0),\n",
       " ('เชษฐา', 37.0),\n",
       " ('จร', 37.0),\n",
       " ('หน่อ', 37.0),\n",
       " ('ผู้หญิง', 37.0),\n",
       " ('ลํา', 37.0),\n",
       " ('เช้า', 37.0),\n",
       " ('หนังสือ', 37.0),\n",
       " ('ฝ่าย', 37.0),\n",
       " ('ฑ', 37.0),\n",
       " ('ียว', 37.0),\n",
       " ('เมื่อ', 36.0),\n",
       " ('เดี๋ยวนี้', 36.0),\n",
       " ('หาญ', 36.0),\n",
       " ('ร้าย', 36.0),\n",
       " ('ฟ้า', 36.0),\n",
       " ('พี่เลี้ยง', 36.0),\n",
       " ('ฏ', 36.0),\n",
       " ('ศักดิ์', 36.0),\n",
       " ('บุตรี', 36.0),\n",
       " ('รีบ', 36.0),\n",
       " ('ฌ', 36.0),\n",
       " ('แน่', 36.0),\n",
       " ('ชีวิต', 36.0),\n",
       " ('รณ', 36.0),\n",
       " ('ธรรม', 36.0),\n",
       " ('้อย', 35.0),\n",
       " ('มนต์', 35.0),\n",
       " ('ควร', 35.0),\n",
       " ('ถูก', 35.0),\n",
       " ('คืน', 35.0),\n",
       " ('จัก', 35.0),\n",
       " ('ุ่ม', 35.0),\n",
       " ('ช้า', 35.0),\n",
       " ('ซ้ํา', 35.0),\n",
       " ('ซื่อ', 35.0),\n",
       " ('พราย', 34.0),\n",
       " ('รักษา', 34.0),\n",
       " ('ชั้น', 34.0),\n",
       " ('ใด', 34.0),\n",
       " ('ชัย', 34.0),\n",
       " ('สิ่ง', 34.0),\n",
       " ('ส่ง', 34.0),\n",
       " ('หนักหนา', 33.0),\n",
       " ('ชอบ', 33.0),\n",
       " ('ผี', 33.0),\n",
       " ('ไม้', 33.0),\n",
       " ('งค์', 33.0),\n",
       " ('เร่ง', 33.0),\n",
       " ('ภัย', 33.0),\n",
       " ('ขาด', 33.0),\n",
       " ('ไฟ', 33.0),\n",
       " ('เลี้ยว', 33.0),\n",
       " ('บาท', 32.0),\n",
       " ('เถิด', 32.0),\n",
       " ('ทั้งหลาย', 32.0),\n",
       " ('สําราญ', 32.0),\n",
       " ('้ง', 32.0),\n",
       " ('เตรียม', 32.0),\n",
       " ('ปาก', 32.0),\n",
       " ('บุรี', 32.0),\n",
       " ('ญาติ', 31.0),\n",
       " ('รับสั่ง', 31.0),\n",
       " ('หลง', 31.0),\n",
       " ('คํานับ', 31.0),\n",
       " ('ชวน', 31.0),\n",
       " ('กอด', 31.0),\n",
       " ('หมื่น', 31.0),\n",
       " ('ม้วย', 31.0),\n",
       " ('ัณฑ์', 31.0),\n",
       " ('แทง', 31.0),\n",
       " ('หลาย', 30.0),\n",
       " ('ทั้งซ้ายขวา', 30.0),\n",
       " ('กล่าว', 30.0),\n",
       " ('เย็น', 30.0),\n",
       " ('ไหล', 30.0),\n",
       " ('บรรลัย', 30.0),\n",
       " ('ท้าวเจ้า', 30.0),\n",
       " ('วิสัย', 30.0),\n",
       " ('ก่อน', 29.0),\n",
       " ('โฉม', 29.0),\n",
       " ('เรียง', 29.0),\n",
       " ('เกิด', 29.0),\n",
       " ('ยุพา', 29.0),\n",
       " ('ดํา', 29.0),\n",
       " ('แท่น', 29.0),\n",
       " ('ชล', 29.0),\n",
       " ('เนื้อ', 29.0),\n",
       " ('ต้น', 29.0),\n",
       " ('ครึ', 29.0),\n",
       " ('หม่อม', 29.0),\n",
       " ('ทราบ', 28.0),\n",
       " ('ขัน', 28.0),\n",
       " ('เดือน', 28.0),\n",
       " ('ปี่', 28.0),\n",
       " ('ผูก', 28.0),\n",
       " ('สําหรับ', 28.0),\n",
       " ('สนอง', 28.0),\n",
       " ('ก็ไม่', 28.0),\n",
       " ('ทั่ว', 28.0),\n",
       " ('ประสา', 28.0),\n",
       " ('ินทร์', 28.0),\n",
       " ('หวัง', 28.0),\n",
       " ('สุวรรณ', 28.0),\n",
       " ('สวัสดิ์', 28.0),\n",
       " ('ปืน', 28.0),\n",
       " ('เสด็จ', 27.0),\n",
       " ('่ํา', 27.0),\n",
       " ('ทัน', 27.0),\n",
       " ('ช่าง', 27.0),\n",
       " ('พ่อ', 27.0),\n",
       " ('แรง', 27.0),\n",
       " ('ชิด', 27.0),\n",
       " ('พึ่ง', 27.0),\n",
       " ('สนิท', 27.0),\n",
       " ('โอรส', 27.0),\n",
       " ('ลั่น', 27.0),\n",
       " ('ฬ', 27.0),\n",
       " ('มารศรี', 26.0),\n",
       " ('ประคอง', 26.0),\n",
       " ('ใกล้', 26.0),\n",
       " ('สัย', 26.0),\n",
       " ('มัว', 26.0),\n",
       " ('ครื้น', 26.0),\n",
       " ('แตก', 26.0),\n",
       " ('เสวย', 26.0),\n",
       " ('จัดแจง', 26.0),\n",
       " ('ผ้า', 26.0),\n",
       " ('พลัด', 26.0),\n",
       " ('มิให้', 25.0),\n",
       " ('เพียง', 25.0),\n",
       " ('รําคาญ', 25.0),\n",
       " ('แทน', 25.0),\n",
       " ('น้ําตา', 25.0),\n",
       " ('เวียน', 25.0),\n",
       " ('อ่าน', 25.0),\n",
       " ('เสียดาย', 25.0),\n",
       " ('ฤทธิ์', 25.0),\n",
       " ('เชื้อ', 25.0),\n",
       " ('เพื่อน', 25.0),\n",
       " ('เกณฑ์', 25.0),\n",
       " ('เชย', 25.0),\n",
       " ('ยิ้ม', 25.0),\n",
       " ('บ้าง', 25.0),\n",
       " ('โฉมยง', 25.0),\n",
       " ('บ้าน', 25.0),\n",
       " ('เนิน', 25.0),\n",
       " ('ซึ่ง', 24.0),\n",
       " ('เกษรา', 24.0),\n",
       " ('เธอ', 24.0),\n",
       " ('สรง', 24.0),\n",
       " ('จะใคร่', 24.0),\n",
       " ('งาม', 24.0),\n",
       " ('ปราศรัย', 24.0),\n",
       " ('ศรีสุวรรณ', 24.0),\n",
       " ('ขวัญ', 24.0),\n",
       " ('บรรดา', 24.0),\n",
       " ('บุตร', 24.0),\n",
       " ('นุช', 24.0),\n",
       " ('เขต', 24.0),\n",
       " ('อัคเรศ', 24.0),\n",
       " ('ครู', 23.0),\n",
       " ('แก่', 23.0),\n",
       " ('พร้อมพรั่ง', 23.0),\n",
       " ('ป้องกัน', 23.0),\n",
       " ('วาง', 23.0),\n",
       " ('สรรพ', 23.0),\n",
       " ('บิดา', 23.0),\n",
       " ('คุม', 23.0),\n",
       " ('กระไร', 23.0),\n",
       " ('โรค', 23.0),\n",
       " ('เพลง', 23.0),\n",
       " ('รุ่ง', 23.0),\n",
       " ('ฮ', 23.0),\n",
       " ('ห่าง', 22.0),\n",
       " ('ฤกษ์', 22.0),\n",
       " ('▁ถ้า', 22.0),\n",
       " ('เศษ', 22.0),\n",
       " ('ธิดา', 22.0),\n",
       " ('บังคม', 22.0),\n",
       " ('▁โอ้', 22.0),\n",
       " ('ปลอบ', 22.0),\n",
       " ('สวรรค์', 22.0),\n",
       " ('กําลัง', 22.0),\n",
       " ('ป้อม', 22.0),\n",
       " ('ถอย', 22.0),\n",
       " ('สมทบ', 22.0),\n",
       " ('สนม', 22.0),\n",
       " ('ธานี', 22.0),\n",
       " ('มาถึง', 21.0),\n",
       " ('แผ่นดิน', 21.0),\n",
       " ('เกศ', 21.0),\n",
       " ('หนัก', 21.0),\n",
       " ('หยิบ', 21.0),\n",
       " ('พระทัย', 21.0),\n",
       " ('ประณต', 21.0),\n",
       " ('ลูบ', 21.0),\n",
       " ('จอม', 21.0),\n",
       " ('ขืน', 21.0),\n",
       " ('รบพุ่ง', 21.0),\n",
       " ('แห่', 21.0),\n",
       " ('ฤทัย', 21.0),\n",
       " ('ทรวง', 21.0),\n",
       " ('เลีย', 20.0),\n",
       " ('ว่าขาน', 20.0),\n",
       " ('ประทับ', 20.0),\n",
       " ('สุวรรณมาลี', 20.0),\n",
       " ('เขียน', 20.0),\n",
       " ('สว่าง', 20.0),\n",
       " ('คลาด', 20.0),\n",
       " ('ไกล', 20.0),\n",
       " ('ค่ํา', 20.0),\n",
       " ('ลุก', 20.0),\n",
       " ('เพลิง', 20.0),\n",
       " ('บูรี', 20.0),\n",
       " ('ประเทศ', 20.0),\n",
       " ('โยธี', 20.0),\n",
       " ('สําเร็จ', 19.0),\n",
       " ('ลืม', 19.0),\n",
       " ('พระเชษฐา', 19.0),\n",
       " ('บัลลังก์', 19.0),\n",
       " ('เจ็บ', 19.0),\n",
       " ('พาที', 19.0),\n",
       " ('กรุงศรี', 19.0),\n",
       " ('หัว', 19.0),\n",
       " ('อาสัญ', 19.0),\n",
       " ('ทะเล', 19.0),\n",
       " ('เท่า', 19.0),\n",
       " ('ร้าง', 19.0),\n",
       " ('เคราะห์', 18.0),\n",
       " ('สรวล', 18.0),\n",
       " ('ร่าง', 18.0),\n",
       " ('อ้าย', 18.0),\n",
       " ('อาสน์', 18.0),\n",
       " ('ผ่อง', 18.0),\n",
       " ('อื่น', 18.0),\n",
       " ('อย่างไร', 18.0),\n",
       " ('ฎ', 18.0),\n",
       " ('เดียว', 18.0),\n",
       " ('ทํานอง', 18.0),\n",
       " ('แปลง', 18.0),\n",
       " ('จันทร์', 18.0),\n",
       " ('เสือ', 18.0),\n",
       " ('เนตร', 18.0),\n",
       " ('นาม', 17.0),\n",
       " ('ประตู', 17.0),\n",
       " ('▁ส่วน', 17.0),\n",
       " ('ชั่ว', 17.0),\n",
       " ('ราตรี', 17.0),\n",
       " ('ถิ่น', 17.0),\n",
       " ('คลาไคล', 17.0),\n",
       " ('หวั่น', 17.0),\n",
       " ('แล่น', 17.0),\n",
       " ('ชนนี', 17.0),\n",
       " ('วุ่น', 17.0),\n",
       " ('พูดจา', 17.0),\n",
       " ('แถลงไข', 17.0),\n",
       " ('ชีวี', 17.0),\n",
       " ('บํารุง', 17.0),\n",
       " ('ประสงค์', 17.0),\n",
       " ('กําสรด', 17.0),\n",
       " ('พระอนุชา', 17.0),\n",
       " ('ุ้ง', 17.0),\n",
       " ('ขัดขวาง', 17.0),\n",
       " ('แคล้ว', 17.0),\n",
       " ('ผลึก', 17.0),\n",
       " ('ประจัญ', 17.0),\n",
       " ('สังเกต', 17.0),\n",
       " ('คลอ', 17.0),\n",
       " ('เปล่า', 17.0),\n",
       " ('รัตน์', 17.0),\n",
       " ('เกี้ยว', 17.0),\n",
       " ('นงลักษณ์', 17.0),\n",
       " ('เปรียบ', 16.0),\n",
       " ('▁หน่อกษัตริย์', 16.0),\n",
       " ('ฒ', 16.0),\n",
       " ('พี่น้องสอง', 16.0),\n",
       " ('กลืน', 16.0),\n",
       " ('เคลื่อน', 16.0),\n",
       " ('ฝาก', 16.0),\n",
       " ('ตรวจ', 16.0),\n",
       " ('▁ฝ่ายโฉมยงองค์', 16.0),\n",
       " ('ปรึกษา', 16.0),\n",
       " ('ผลาญ', 16.0),\n",
       " ('ท้าย', 16.0),\n",
       " ('สมบัติ', 16.0),\n",
       " ('ชีวา', 16.0),\n",
       " ('ประการใด', 16.0),\n",
       " ('กรุงไกร', 16.0),\n",
       " ('อาวุธ', 16.0),\n",
       " ('กลุ้ม', 16.0),\n",
       " ('รมจักร', 16.0),\n",
       " ('แข็ง', 16.0),\n",
       " ('เมิน', 16.0),\n",
       " ('ไมตรี', 16.0),\n",
       " ('ลักษณ์', 16.0),\n",
       " ('สารพัด', 15.0),\n",
       " ('ปัญญา', 15.0),\n",
       " ('๊', 15.0),\n",
       " ('สงสัย', 15.0),\n",
       " ('สําคัญ', 15.0),\n",
       " ('หัตถ์', 15.0),\n",
       " ('ทั้งสาม', 15.0),\n",
       " ('รื่น', 15.0),\n",
       " ('ดวง', 15.0),\n",
       " ('ลัย', 15.0),\n",
       " ('สงคราม', 15.0),\n",
       " ('ประทาน', 15.0),\n",
       " ('ยืน', 15.0),\n",
       " ('ชาญ', 14.0),\n",
       " ('ขัดข้อง', 14.0),\n",
       " ('สูญ', 14.0),\n",
       " ('ล่วง', 14.0),\n",
       " ('บรรทม', 14.0),\n",
       " ('ปิ่น', 14.0),\n",
       " ('รูป', 14.0),\n",
       " ('เยื้อง', 14.0),\n",
       " ('อดสู', 14.0),\n",
       " ('ครัน', 14.0),\n",
       " ('สําเนียง', 14.0),\n",
       " ('เหลียว', 14.0),\n",
       " ('๋', 14.0),\n",
       " ('เลี่ยง', 14.0),\n",
       " ('กระบวน', 14.0),\n",
       " ('ใบ', 14.0),\n",
       " ('ลอย', 13.0),\n",
       " ('ตรึกตรา', 13.0),\n",
       " ('อาจารย์', 13.0),\n",
       " ('ครวญ', 13.0),\n",
       " ('พรุ่งนี้', 13.0),\n",
       " ('ล้ํา', 13.0),\n",
       " ('เทว', 13.0),\n",
       " ('รักใคร่', 13.0),\n",
       " ('นารี', 13.0),\n",
       " ('ฮึก', 13.0),\n",
       " ('หวาน', 13.0),\n",
       " ('เด็ก', 13.0),\n",
       " ('ปรานี', 13.0),\n",
       " ('แคลง', 13.0),\n",
       " ('แฝง', 13.0),\n",
       " ('ประหลาด', 13.0),\n",
       " ('ชีวัน', 13.0),\n",
       " ('กรุง', 13.0),\n",
       " ('ยุทธ์', 13.0),\n",
       " ('ปราสาท', 13.0),\n",
       " ('สัญญา', 13.0),\n",
       " ('▁แม้น', 13.0),\n",
       " ('เภตรา', 13.0),\n",
       " ('เจ็ด', 12.0),\n",
       " ('เอ๋ย', 12.0),\n",
       " ('ขุนนาง', 12.0),\n",
       " ('หม่อมฉัน', 12.0),\n",
       " ('เลือด', 12.0),\n",
       " ('อะไร', 12.0),\n",
       " ('ไต่ถาม', 12.0),\n",
       " ('โปรดปราน', 12.0),\n",
       " ('บาทหลวง', 12.0),\n",
       " ('ย่องตอด', 12.0),\n",
       " ('ตื่น', 12.0),\n",
       " ('ชู้', 12.0),\n",
       " ('ท่วงที', 12.0),\n",
       " ('ปรางค์', 12.0),\n",
       " ('กระจาย', 12.0),\n",
       " ('แย้ม', 12.0),\n",
       " ('เจียว', 12.0),\n",
       " ('ประโลม', 12.0),\n",
       " ('สวาท', 12.0),\n",
       " ('เบือน', 12.0),\n",
       " ('รําลึก', 12.0),\n",
       " ('คลื่น', 12.0),\n",
       " ('คิดอ่าน', 11.0),\n",
       " ('ประชวร', 11.0),\n",
       " ('รู้สึก', 11.0),\n",
       " ('ฟื้น', 11.0),\n",
       " ('เล็ก', 11.0),\n",
       " ('แถลง', 11.0),\n",
       " ('อาวรณ์', 11.0),\n",
       " ('ละออง', 11.0),\n",
       " ('บิตุเรศ', 11.0),\n",
       " ('ข้าศึก', 11.0),\n",
       " ('เมตตา', 11.0),\n",
       " ('สิงหล', 11.0),\n",
       " ('ธุระ', 11.0),\n",
       " ('ภาษา', 11.0),\n",
       " ('ล่ห์', 11.0),\n",
       " ('นวล', 11.0),\n",
       " ('สนั่น', 11.0),\n",
       " ('เข็ญ', 11.0),\n",
       " ('ยินดี', 11.0),\n",
       " ('ตลบ', 11.0),\n",
       " ('ข่าว', 11.0),\n",
       " ('กระจ่าง', 11.0),\n",
       " ('วิญญาณ์', 11.0),\n",
       " ('สถาน', 11.0),\n",
       " ('จิตคิด', 11.0),\n",
       " ('ว่าถ้า', 11.0),\n",
       " ('สําเภา', 11.0),\n",
       " ('นัดดา', 11.0),\n",
       " ('อาศัย', 10.0),\n",
       " ('มารดา', 10.0),\n",
       " ('▁นางฟังคํา', 10.0),\n",
       " ('กลิ่น', 10.0),\n",
       " ('จูบ', 10.0),\n",
       " ('กําปั่น', 10.0),\n",
       " ('ยับยั้ง', 10.0),\n",
       " ('กําแพง', 10.0),\n",
       " ('ฟาด', 10.0),\n",
       " ('ตรึกตรอง', 10.0),\n",
       " ('หรรษา', 10.0),\n",
       " ('เหนื่อย', 10.0),\n",
       " ('เปลี่ยว', 10.0),\n",
       " ('นิเวศน์', 10.0),\n",
       " ('โบราณ', 10.0),\n",
       " ('เบื่อ', 10.0),\n",
       " ('เตือน', 10.0),\n",
       " ('ถนอม', 10.0),\n",
       " ('ทูต', 10.0),\n",
       " ('เจริญ', 9.0),\n",
       " ('ตํารา', 9.0),\n",
       " ('ภูวไนย', 9.0),\n",
       " ('หน่วง', 9.0),\n",
       " ('คลั่ง', 9.0),\n",
       " ('กลิ้ง', 9.0),\n",
       " ('ทรงธรรม์', 9.0),\n",
       " ('อภิวาท', 9.0),\n",
       " ('พลางทาง', 9.0),\n",
       " ('แขก', 9.0),\n",
       " ('เกาะ', 9.0),\n",
       " ('โยคี', 9.0),\n",
       " ('ละเวงวัณฬา', 9.0),\n",
       " ('เขม้น', 9.0),\n",
       " ('ปรารถนา', 9.0),\n",
       " ('เรียน', 9.0),\n",
       " ('มิใช่', 9.0),\n",
       " ('พรั่งพร้อม', 9.0),\n",
       " ('สุรางค์นาง', 9.0),\n",
       " ('เจ้าพราหมณ์', 9.0),\n",
       " ('สิงขร', 9.0),\n",
       " ('วิเชียร', 9.0),\n",
       " ('แผ่น', 9.0),\n",
       " ('เพลิน', 9.0),\n",
       " ('สมุทร', 9.0),\n",
       " ('ฉลาด', 8.0),\n",
       " ('กุมาร', 8.0),\n",
       " ('เหน็บ', 8.0),\n",
       " ('ไสว', 8.0),\n",
       " ('บิตุรงค์', 8.0),\n",
       " ('ทั้งไพร่นาย', 8.0),\n",
       " ('สุริย์', 8.0),\n",
       " ('พหลพล', 8.0),\n",
       " ('ฉวย', 8.0),\n",
       " ('คงคา', 8.0),\n",
       " ('หยิก', 8.0),\n",
       " ('แจ่ม', 8.0),\n",
       " ('อํามาตย์', 8.0),\n",
       " ('วิชา', 7.0),\n",
       " ('รอรั้ง', 7.0),\n",
       " ('เคลิ้ม', 7.0),\n",
       " ('ไม้เท้า', 7.0),\n",
       " ('ผ่านเกล้า', 7.0),\n",
       " ('เต็ม', 7.0),\n",
       " ('สาวสุรางค์', 7.0),\n",
       " ('เรียบ', 7.0),\n",
       " ('รอบขอบ', 7.0),\n",
       " ('หัวร่อ', 7.0),\n",
       " ('หลงใหล', 7.0),\n",
       " ('พิสมัย', 7.0),\n",
       " ('ชําเลือง', 7.0),\n",
       " ('จริต', 7.0),\n",
       " ('นิจจาเอ๋ย', 6.0),\n",
       " ('สําอาง', 6.0),\n",
       " ('สังวาล', 6.0),\n",
       " ('กิจจา', 6.0),\n",
       " ('ตะลึง', 6.0),\n",
       " ('ร้องไห้', 6.0),\n",
       " ('ได้ยิน', 6.0),\n",
       " ('หยุดยั้ง', 6.0),\n",
       " ('กษัตรา', 6.0),\n",
       " ('พลิก', 6.0),\n",
       " ('▁ศรีสุวรรณนั้น', 6.0),\n",
       " ('ชํานาญ', 6.0),\n",
       " ('เปลื้อง', 6.0),\n",
       " ('บัดสี', 5.0),\n",
       " ('เอ็นดู', 5.0),\n",
       " ('ละห้อย', 5.0),\n",
       " ('หน่อนาถ', 5.0),\n",
       " ('หวาด', 5.0),\n",
       " ('พระธิดา', 5.0),\n",
       " ('ประมาณ', 5.0),\n",
       " ('แสร้ง', 5.0),\n",
       " ('เขนย', 5.0),\n",
       " ('ลําบาก', 5.0),\n",
       " ('สมเด็จ', 5.0),\n",
       " ('กํานัล', 5.0),\n",
       " ('เลือก', 5.0),\n",
       " ('จํารัส', 5.0),\n",
       " ('อุ้ม', 5.0),\n",
       " ('▁สินสมุทรสุด', 5.0),\n",
       " ('มารดร', 4.0),\n",
       " ('พระอภัยมณี', 4.0),\n",
       " ('จํานรรจา', 4.0),\n",
       " ('เจียน', 4.0),\n",
       " ('แอบแนบ', 4.0),\n",
       " ('คะนึง', 4.0),\n",
       " ('อิ่ม', 4.0),\n",
       " ('ใหม่', 4.0),\n",
       " ('ยิ้มพริ้ม', 4.0),\n",
       " ('ณรงค์', 4.0),\n",
       " ('หัวเราะ', 3.0),\n",
       " ('ไสยาสน์', 3.0),\n",
       " ('ฦๅ', 3.0),\n",
       " ('ใต้', 3.0),\n",
       " ('มนุษย์', 3.0),\n",
       " ('สุคนธ์', 3.0),\n",
       " ('เงือก', 3.0),\n",
       " ('เคล้า', 2.0),\n",
       " ('คล้าย', 2.0),\n",
       " ('นักหนา', 1.0),\n",
       " ('บิดร', 1.0),\n",
       " ('กระดาษ', 1.0),\n",
       " ('มัจฉา', 1.0)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_tokens_pam "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qz0GdZ-5YYM9"
   },
   "source": [
    "### To answer\n",
    "\n",
    "What are some notable differences you see between the two vocabs?\n",
    "\n",
    "Write your answer below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QxxYr0QLbDoU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ipjO87HPYl4N"
   },
   "source": [
    "## Using tokenizer across domains\n",
    "\n",
    "One problem you may face is your dataset is very specialized. In that case the tokenizer trained on a general domain may not perform as good as it should when used on your dataset.\n",
    "\n",
    "Next you will try using tokenizers trained on one general domain (on Pantip) and use it on a specialized domain (พระอภัยมณี) and vice versa.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I4_6JG_l5BXh"
   },
   "source": [
    "### Q3 MCV\n",
    "\n",
    "What percentage increase do you observe when tokenizing the whole พระอภัยมณี dataset with a tokenizer trained on Pantip compared to the one trained on พระอภัยมณี.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3tCh1RaZrTAM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "duaCJRO96SX1"
   },
   "source": [
    "### Q4 MCV\n",
    "\n",
    "What percentage increase do you observe when tokenizing the whole Pantip dataset with a tokenizer trained on พระอภัยมณี compared to the one trained on Pantip.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "axk9gOIgrTYd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yZYKuamv7-wI"
   },
   "source": [
    "### To answer\n",
    "\n",
    "Why do you think the number of tokens tokenized by the general tokenizer (the one trained on Pantip) has a higher percentage increase compared to the number of tokens tokenized by the specialized tokenizer? (Hint: we fixed vocab size.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gh9a6d7Q8ivJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O7j_Cc0p9-5S"
   },
   "source": [
    "## The effect on language models\n",
    "\n",
    "Next, we will see the effect of using \"cross-domain\" tokenizers on Language models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KiWztANvohhn"
   },
   "source": [
    "### Setup\n",
    "\n",
    "We are going to reuse the code from the last assignment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7pVtSbmVpwOo"
   },
   "outputs": [],
   "source": [
    "!pip install lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JMt5GzLrW4x3"
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import lightning as L\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0OIs_VS_oo1M"
   },
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, seq_len=128):\n",
    "\n",
    "        token_ids = [tokenizer.encode(d, add_bos=True, add_eos=True) for d in data]\n",
    "        flatten_token_ids = list(itertools.chain(*token_ids))\n",
    "        encoded = torch.LongTensor(flatten_token_ids)\n",
    "\n",
    "        left_over = len(encoded) % seq_len\n",
    "        encoded = encoded[: len(encoded) - left_over]\n",
    "        self.encoded = encoded.view(-1, seq_len)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.encoded[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hk6vEPiMq34n"
   },
   "outputs": [],
   "source": [
    "class LSTM(L.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size,\n",
    "        embedding_dim,\n",
    "        hidden_dim,\n",
    "        num_layers,\n",
    "        dropout_rate,\n",
    "        learning_rate,\n",
    "        criterion,\n",
    "    ):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(\n",
    "            embedding_dim,\n",
    "            hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout_rate,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "        self.learning_rate = learning_rate\n",
    "        self.criterion = criterion\n",
    "\n",
    "    def forward(self, src):\n",
    "        pass\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "\n",
    "        src = batch[:, :-1]\n",
    "        target = batch[:, 1:]\n",
    "        prediction = self(src)\n",
    "        prediction = prediction.reshape(-1, self.vocab_size)\n",
    "        target = target.reshape(-1)\n",
    "        loss = self.criterion(prediction, target)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "\n",
    "        src = batch[:, :-1]\n",
    "        target = batch[:, 1:]\n",
    "        with torch.no_grad():\n",
    "            prediction = self(src)\n",
    "        prediction = prediction.reshape(-1, self.vocab_size)\n",
    "        target = target.reshape(-1)\n",
    "        loss = self.criterion(prediction, target)\n",
    "        self.log(\"test_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.parameters(), lr=self.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oKhuOygixndB"
   },
   "outputs": [],
   "source": [
    "vocab_size = sp_pam.get_piece_size()\n",
    "embedding_dim = 200\n",
    "hidden_dim = 512\n",
    "num_layers = 3\n",
    "dropout_rate = 0.2\n",
    "lr = 1e-3\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "train_batch_size = 64\n",
    "test_batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kOtOE7mr-heY"
   },
   "source": [
    "### Training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g8-x9HiPDcpE"
   },
   "source": [
    "<a name=\"no1\"></a>\n",
    "\n",
    "#### 1. Training on Pantip data with Pantip tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oUv_A4MTx0Ob"
   },
   "outputs": [],
   "source": [
    "trainer = L.Trainer(max_epochs=10, deterministic=True)\n",
    "model = LSTM(\n",
    "    vocab_size, embedding_dim, hidden_dim, num_layers, dropout_rate, lr, criterion\n",
    ")\n",
    "\n",
    "pantip_train_dataset = TextDataset(pantip_train_text, sp_pantip)\n",
    "pantip_train_loader = DataLoader(\n",
    "    pantip_train_dataset, batch_size=train_batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "pantip_test_dataset = TextDataset(pantip_test_text, sp_pantip)\n",
    "pantip_test_loader = DataLoader(\n",
    "    pantip_test_dataset, batch_size=test_batch_size, shuffle=False\n",
    ")\n",
    "\n",
    "pam_train_dataset = TextDataset(pam_train_text, sp_pantip)\n",
    "pam_train_loader = DataLoader(\n",
    "    pam_train_dataset, batch_size=train_batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "pam_test_dataset = TextDataset(pam_test_text, sp_pantip)\n",
    "pam_test_loader = DataLoader(\n",
    "    pam_test_dataset, batch_size=test_batch_size, shuffle=False\n",
    ")\n",
    "\n",
    "trainer.fit(model, train_dataloaders=pantip_train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1e-Y1_GYy65g"
   },
   "outputs": [],
   "source": [
    "test_result = trainer.test(\n",
    "    model,\n",
    "    dataloaders=[\n",
    "        pantip_train_loader,\n",
    "        pam_train_loader,\n",
    "        pantip_test_loader,\n",
    "        pam_test_loader,\n",
    "    ],\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Perplexity on Pantip train set is:\\t{np.exp(test_result[0]['test_loss/dataloader_idx_0'])}\"\n",
    ")\n",
    "print(\n",
    "    f\"Perplexity on Pra apai manee train set is:\\t{np.exp(test_result[1]['test_loss/dataloader_idx_1'])}\"\n",
    ")\n",
    "print(\n",
    "    f\"Perplexity on Pantip test set is:\\t{np.exp(test_result[2]['test_loss/dataloader_idx_2'])}\"\n",
    ")\n",
    "print(\n",
    "    f\"Perplexity on Pra apai manee test set is:\\t{np.exp(test_result[3]['test_loss/dataloader_idx_3'])}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7s3AmE4nDjmL"
   },
   "source": [
    "<a name=\"no2\"></a>\n",
    "\n",
    "#### 2. Training on Pantip data with Pra apai manee tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vfRdW3m1Dmj_"
   },
   "outputs": [],
   "source": [
    "trainer = L.Trainer(max_epochs=10, deterministic=True)\n",
    "model = LSTM(\n",
    "    vocab_size, embedding_dim, hidden_dim, num_layers, dropout_rate, lr, criterion\n",
    ")\n",
    "\n",
    "pantip_train_dataset = TextDataset(pantip_train_text, sp_pam)\n",
    "pantip_train_loader = DataLoader(\n",
    "    pantip_train_dataset, batch_size=train_batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "pantip_test_dataset = TextDataset(pantip_test_text, sp_pam)\n",
    "pantip_test_loader = DataLoader(\n",
    "    pantip_test_dataset, batch_size=test_batch_size, shuffle=False\n",
    ")\n",
    "\n",
    "pam_train_dataset = TextDataset(pam_train_text, sp_pam)\n",
    "pam_train_loader = DataLoader(\n",
    "    pam_train_dataset, batch_size=train_batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "pam_test_dataset = TextDataset(pam_test_text, sp_pam)\n",
    "pam_test_loader = DataLoader(\n",
    "    pam_test_dataset, batch_size=test_batch_size, shuffle=False\n",
    ")\n",
    "\n",
    "trainer.fit(model, train_dataloaders=pantip_train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xwLN1IarD3g9"
   },
   "outputs": [],
   "source": [
    "test_result = trainer.test(\n",
    "    model,\n",
    "    dataloaders=[\n",
    "        pantip_train_loader,\n",
    "        pam_train_loader,\n",
    "        pantip_test_loader,\n",
    "        pam_test_loader,\n",
    "    ],\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Perplexity on Pantip train set is:\\t{np.exp(test_result[0]['test_loss/dataloader_idx_0'])}\"\n",
    ")\n",
    "print(\n",
    "    f\"Perplexity on Pra apai manee train set is:\\t{np.exp(test_result[1]['test_loss/dataloader_idx_1'])}\"\n",
    ")\n",
    "print(\n",
    "    f\"Perplexity on Pantip test set is:\\t{np.exp(test_result[2]['test_loss/dataloader_idx_2'])}\"\n",
    ")\n",
    "print(\n",
    "    f\"Perplexity on Pra apai manee test set is:\\t{np.exp(test_result[3]['test_loss/dataloader_idx_3'])}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NB8zqptTWcA6"
   },
   "source": [
    "#### To answer\n",
    "\n",
    "The perplexity numbers should indicate that:\n",
    "\n",
    "1. Training the LM with Pra apai manee tokenizer on Pantip (no. [2](#no2)) results in overfitting to Pantip and poor generalization to the Pra apai manee dataset.\n",
    "2. However using the Pantip tokenizer (no. [1](#no1)) results in a much better generalization.\n",
    "\n",
    "Try and come up with some reasons for the results above. <br>\n",
    "Hint:\n",
    "\n",
    "1. think about \"general\" vocabs and domain-specific vocabs.\n",
    "2. what do you think happens to the model when the token ids become longer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TmHGQf2saPj_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y8VPMm7pLdSl"
   },
   "source": [
    "<a name=\"no3\"></a>\n",
    "\n",
    "#### 3. Training on Pra apai manee data with Pantip tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oR5fp-YCLnnU"
   },
   "outputs": [],
   "source": [
    "trainer = L.Trainer(max_epochs=10, deterministic=True)\n",
    "model = LSTM(\n",
    "    vocab_size, embedding_dim, hidden_dim, num_layers, dropout_rate, lr, criterion\n",
    ")\n",
    "\n",
    "pantip_train_dataset = TextDataset(pantip_train_text, sp_pantip)\n",
    "pantip_train_loader = DataLoader(\n",
    "    pantip_train_dataset, batch_size=train_batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "pantip_test_dataset = TextDataset(pantip_test_text, sp_pantip)\n",
    "pantip_test_loader = DataLoader(\n",
    "    pantip_test_dataset, batch_size=test_batch_size, shuffle=False\n",
    ")\n",
    "\n",
    "pam_train_dataset = TextDataset(pam_train_text, sp_pantip)\n",
    "pam_train_loader = DataLoader(\n",
    "    pam_train_dataset, batch_size=train_batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "pam_test_dataset = TextDataset(pam_test_text, sp_pantip)\n",
    "pam_test_loader = DataLoader(\n",
    "    pam_test_dataset, batch_size=test_batch_size, shuffle=False\n",
    ")\n",
    "\n",
    "trainer.fit(model, train_dataloaders=pam_train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f_LhF7w7Lxwo"
   },
   "outputs": [],
   "source": [
    "test_result = trainer.test(\n",
    "    model,\n",
    "    dataloaders=[\n",
    "        pantip_train_loader,\n",
    "        pam_train_loader,\n",
    "        pantip_test_loader,\n",
    "        pam_test_loader,\n",
    "    ],\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Perplexity on Pantip train set is:\\t{np.exp(test_result[0]['test_loss/dataloader_idx_0'])}\"\n",
    ")\n",
    "print(\n",
    "    f\"Perplexity on Pra apai manee train set is:\\t{np.exp(test_result[1]['test_loss/dataloader_idx_1'])}\"\n",
    ")\n",
    "print(\n",
    "    f\"Perplexity on Pantip test set is:\\t{np.exp(test_result[2]['test_loss/dataloader_idx_2'])}\"\n",
    ")\n",
    "print(\n",
    "    f\"Perplexity on Pra apai manee test set is:\\t{np.exp(test_result[3]['test_loss/dataloader_idx_3'])}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "apk9crJjMLoW"
   },
   "source": [
    "<a name=\"no4\"></a>\n",
    "\n",
    "#### 4. Training on Pra apai manee data with Pra apai manee tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_G7GMBIKLzGK"
   },
   "outputs": [],
   "source": [
    "trainer = L.Trainer(max_epochs=10, deterministic=True)\n",
    "model = LSTM(\n",
    "    vocab_size, embedding_dim, hidden_dim, num_layers, dropout_rate, lr, criterion\n",
    ")\n",
    "\n",
    "pantip_train_dataset = TextDataset(pantip_train_text, sp_pam)\n",
    "pantip_train_loader = DataLoader(\n",
    "    pantip_train_dataset, batch_size=train_batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "pantip_test_dataset = TextDataset(pantip_test_text, sp_pam)\n",
    "pantip_test_loader = DataLoader(\n",
    "    pantip_test_dataset, batch_size=test_batch_size, shuffle=False\n",
    ")\n",
    "\n",
    "pam_train_dataset = TextDataset(pam_train_text, sp_pam)\n",
    "pam_train_loader = DataLoader(\n",
    "    pam_train_dataset, batch_size=train_batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "pam_test_dataset = TextDataset(pam_test_text, sp_pam)\n",
    "pam_test_loader = DataLoader(\n",
    "    pam_test_dataset, batch_size=test_batch_size, shuffle=False\n",
    ")\n",
    "\n",
    "trainer.fit(model, train_dataloaders=pam_train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9H753o_JMRFw"
   },
   "outputs": [],
   "source": [
    "test_result = trainer.test(\n",
    "    model,\n",
    "    dataloaders=[\n",
    "        pantip_train_loader,\n",
    "        pam_train_loader,\n",
    "        pantip_test_loader,\n",
    "        pam_test_loader,\n",
    "    ],\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Perplexity on Pantip train set is:\\t{np.exp(test_result[0]['test_loss/dataloader_idx_0'])}\"\n",
    ")\n",
    "print(\n",
    "    f\"Perplexity on Pra apai manee train set is:\\t{np.exp(test_result[1]['test_loss/dataloader_idx_1'])}\"\n",
    ")\n",
    "print(\n",
    "    f\"Perplexity on Pantip test set is:\\t{np.exp(test_result[2]['test_loss/dataloader_idx_2'])}\"\n",
    ")\n",
    "print(\n",
    "    f\"Perplexity on Pra apai manee test set is:\\t{np.exp(test_result[3]['test_loss/dataloader_idx_3'])}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "en9Lmmj4dZ-1"
   },
   "source": [
    "#### To answer\n",
    "\n",
    "The perplexity numbers should indicate that:\n",
    "\n",
    "1. Both LM overfits on Pra apai manee data and performs really bad on Pantip data.\n",
    "2. However using the Pra apai manee tokenizer (no. [4](#no4)) results in a better generalization than the Pantip tokenizer(no. [3](#no3)).\n",
    "\n",
    "Try and come up with some reasons for the results above. <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HlE-mWSMfbv3"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
